{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6fb30b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import MyLib.nlp as nlp\n",
    "import MyLib.HTML_prep as HTML_prep\n",
    "import MyLib.analysis as analysis \n",
    "from ipywidgets import interactive, interact\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "930f9fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_json(\"2023-06-06_Zotero_AI_nlp_en2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "168dba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "ChatGPT_Terms=\"ChatGPT, GPT3, GPT4, OpenAI, AI, LLM, A.I, GPT, Chatbot, technology, tool, app, Artificial Intelligence, Large Language Models\"\n",
    "\n",
    "Promise_terms=\"will, promise, definetly\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44fd5930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [],\n",
       " [],\n",
       " ['A healthy diet can help keep the body and mind healthy and extend the quality of life. A healthy diet and lifestyle are even more important for elderly people with care needs. Seniors often experience a decreased appetite, resulting in malnutrition. INtoEAT aims at development and implementation of innovative digital tools that can improve healthy eating habits and lifestyle in elderly as a nutrition aid. Specifically, a smart tray, a digital food coach, and a lifestyle app will be used for enabling personalised (remote) diet and lifestyle supervision and coaching, facilitating elderly to live longer independently and at home. Nutritionists also benefit a lot from the information in the app and can make better adjustments to patients diets. This, combined with intensive guidance from a nutrition coach, supports lifestyle and eating behaviour improvement.'],\n",
       " [],\n",
       " ['here has been a lot of speculation in recent years about the possibilities of AI, or artificial intelligence, the technique in which machines are enabled through algorithms to grow into self-learning systems. Will intelligent robots take over our jobs? Partly yes, thinks Ketelaar, but other types of jobs will be added. AI is not yet as far as some think, but it is a promising development that cannot be reversed. Ketelaar mentions the assertiveness app developed by professor of Communication Science and Artificial Intelligence Tibor Bosse, which you can use to learn to brush people off at the door. The app registers how people react to uninvited visitors and provides tips based on that.'],\n",
       " [],\n",
       " [\"One technology is more advanced than the other, says Ketelaar. Gamification is already being used regularly, but the possibilities of chatbots are still limited. Yet all four technologies are here to stay. Once a technology is invented, it will be hard to uninvent it, the Canadian philosopher Marshall McLuhan already stated in . We must make people media-savvy, so that they are able to appreciate communication techniques now and in the future. There will always be risks associated with new techniques and we should certainly look at those, but I believe in positive technology that helps people and I am convinced that we as humans will remain in the driver's seat.\"],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['By now, I have become accustomed to the fact that many people have no problem giving away their data to mostly American and Chinese companies that do not fall under European legislation. But I am still amazed at the ease with which many people once again trust a company that stores all data beyond the reach of Dutch legislation, thus helping to improve the system. In the foreseeable future, this system will probably become so good that the company will start charging money for it. In what way that will happen is not yet known will universities soon have to pay to check whether a text was created by AI and by whom? Will we soon have to pay to make our texts reliable, or unique? I guess well have to wait and see.'],\n",
       " ['What role will text-generating AI play in teaching and research? Those who have texts generated to avoid having to think for themselves or to have sufficient knowledge at their fingertips may be in for a rude awakening. After all, if you do not master a subject and have a text generated about it, you will hardly be in a position to properly assess the result for quality and reliability.'],\n",
       " ['Still, let me end on a more positive note. I think that most students and staff members will want to use this new technology safely, appropriately and fairly. Not to pretend that they created the AI-generated texts themselves, but to get support and improve their own skills by using this kind of system. If such a system should become available, I will gladly use it. It is bound to improve the readability of my columns!'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [\"AI can improve the quality of education, if only by reducing teachers' workload. But what is the need for, what really helps teachers and schools further? NOLAI will be searching for the next years, working closely with schools, companies and scientists. The art is to search for the question behind the question. So not: 'how do I create a dashboard', or 'how do I check texts for the use of ChatGPT', but questions such as: 'which student data do we want to monitor and why' and 'what do we want to prepare our students for'. Tricky questions that take time. As Annelies Wiggers puts it: 'Major issues require guts, and to start somewhere'. That's what we are going to do. NOLAI is starting to projects this school year in which these educational questions are central.\"],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['We will start by developing two motivational chatbots focused on health. This is not about short, one-off conversations. To enhance their impact, these chatbots will develop a connection with their users over a longer period of time, says Tibor Bosse. You can imagine this, for example, as a chatbot that encourages safe sex and enables communication on this topic. It can therefore hold conversations with both sex partners at the same time. The ultimate goal is to build a toolkit that is also available to other developers. This can enable organisations to develop their own chatbots for other purposes.\"'],\n",
       " [],\n",
       " ['ypically, chatbot developers have created different training phrases for certain intents. For example, a weather chatbot must learn to recognize that: What will the weather be like?, Is it going to rain soon? and Should I bring an umbrella today? all refer to the same intention (I want to know again). In addition, once recognized, the intent often needs to be supplemented with \"entities\", that is, additional information related to the intent. For example, a weather update needs an entity for location (from which place do you want to know the weather) and also a date and time entity. If the user already provides this information in the question, it can be taken into account immediately (e.g. Should I bring an umbrella at p.m. today?) and the system only needs one follow-up question to obtain the location. Typically, a chatbot developer creates a wide variety of example sentences, including instances with and without entities, and an algorithm learns to associate (classify) them with the correct intent, through machine learning.'],\n",
       " [],\n",
       " [],\n",
       " ['here are two types of chatbots. The first is pre-programmed to answer familiar consumer questions. If you have unknown questions, the chatbot will switch off and you will be transferred to a real employee. The second type is under development and there are not so many of them yet. This chatbot learns from every conversation and becomes smarter. Those conversations are taking on more and more human traits. When the chatbot passes the Turing test a test to map the intelligence of robots and computers a human cannot say whether he is having a conversation with a robot or a human.'],\n",
       " ['he research shows that a mix of rational and affective determinants has a positive effect on brand valuation. If the chatbot scores high on productivity in the eyes of consumers, provides actionable and useful answers, and meets their information needs, it is positive for the brand. It increases the chance that consumers will use the branded chatbot again in the future and recommend it to their friends. Read the research (paid).'],\n",
       " [],\n",
       " [],\n",
       " [\"Artificial intelligence is penetrating all walks of life. The public discussion will also be influenced by it. Marcel Becker critically discusses the ChatGPT chatbot using lessons from classical rhetoric. What is the system more than sweet talk? And in rhetoric, isn't it important who conveys the message?\"],\n",
       " ['\"What do you think of this answer?\" the student asked, giving the teacher a defiant look. The teacher quickly read through the three paragraphs on J.S. Mill, and said he had arranged the most important elements nicely. \"ChatGTP did...sir,\" was the reply in a tone that was both triumphant and derogatory. These kinds of conversations will have taken place in all kinds of social fields. But now that the initial amazement about the \\'smart\\' AI system has ebbed away, it is time for the fundamental questions. They are questions about current standards of good work, ChatGPT\\'s (in)ability to meet them, and the desirability of machines taking over tasks from people. It is high time to get to work with these questions, because the next version, which will certainly give rise to new \\'Oh\\'s and Ah\\'s\\', is on its way.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['ChatGPT places the arguments unquestioningly next to each other, and it is up to the reader to decide what is important. As Bender says, \"If it makes sense it is because you make sense of it.\"2 The system is honest about its inhuman communication; it explicitly indicates that it itself has no judgments or beliefs. Then there is no need for \\'pathos\\' and \\'ethos\\'. Because meanings and beliefs arise in dialogue between people, the chat partner is not a fully-fledged conversation partner. The modesty does not alter the fact that the system emanates a strong temptation, and that leads to a paradox. It is a useful tool, but only works well with people who are not afraid of the real conversation. In order to use the system in such a way that it strengthens our thinking, we will have to practice our conversational skills outside the system. The system works well if we can handle it well, but it should not undermine our ability to handle it well.'],\n",
       " [],\n",
       " [],\n",
       " ['Will ChatGPT fundamentally change our educational system? Will students get dumber because they dont have to think for themselves anymore? Some people compare ChatGPT to the calculator: when it was introduced, many people were afraid that this would lead to a deterioration of students math skills. According to Tamar Sharon, this comparison does not compute, as ChatGPT has different implications.'],\n",
       " ['Did you know that ChatGPT places an enormous burden on our environment? That it is produced in low income countries, but owned by a few billionaires in Silicon Valley? That your privacy is far from secured when you use it? That it tends to foster gender and race biases? That the business model is questionable: it might be for free now, but by the time we have become dependent on it we will probably have to pay for it. Tamar Sharon argues that we put this technology on hold, at least until we have clear European legislation. Program manager Nort Vlemmix is the moderator.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Will GPT-4 change everything? | Lecture by philosopher and cognitive scientist Anco Peeters, philosopher Jan Bransen and artificial intelligence ChatGPT (Lecture) - Radboud Reflects'],\n",
       " [],\n",
       " ['he internet is . In the beginning of , the company OpenAI will release the GPT-4 program. Expectations are high as GPT-3 and GPT-3.5 can already generate stunning human prose. What else will the next version be able to do? Where are the limits of artificial intelligence?'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['he rise of ChatGPT has sparked concern in academia that AI will soon take over the writing process. However, we believe that human creativity and critical thinking will always play an essential role in academic writing. In this workshop, we will explore how AI can complement and enhance your writing skills while ensuring that you remain in charge of your own text.'],\n",
       " ['he workshop will cover the latest AI tools and techniques for academic writing, including ChatGPT, and demonstrate how to effectively collaborate with AI to improve your writing productivity and quality. Whether you are a student, researcher, or teacher, this workshop will help you stay ahead of the curve and embrace the possibilities of AI in your future writing practice.'],\n",
       " [],\n",
       " [],\n",
       " ['We all know ChatGPT by now, but do you know how to use it in a way that helps with your studies? And did you know that there are many more useful AI tools out there? In this workshop, you will learn about these tools and engage in thought-provoking discussions as we collectively explore the integration of AI in education. Additionally, we will collaboratively compile our insights into an AI magazine of which you will receive a physical copy.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Should we punish people for crimes they commit in a VR world? Will ChatGPT force us to change our education system? How will Generation Z cope with the changes that rapid AI innovation will bring? These topics, and many more, were discussed at the Gen Z: A Glimpse in our Future event.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Large Language Models such as ChatGPT have undergone a meteoric rise. With a few short sentences, entire texts can be put together, from interviews to information to legal documents. And all that within seconds. This offers enormous opportunities, but also entails unexpected new risks for the practice lawyer or lawyer. Those who can formulate the right prompts will achieve the greatest benefits. In this extra long LLL, ICT lawyer Arnoud Engelfriet will work with you on the difficult subject of \"legal prompt engineering\": how do you write a good prompt, how do you make adjustments, what are the tips & tricks to achieve the best result? come?'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['In the project Low-Resource Chat-based Conversational Intelligence (LESSEN), scientists will develop this Dutch chatbot technology. Although Dutch is a relatively small language in terms of the number of speakers, it is a well-equipped language in terms of the technology and datasets needed to train AI models.'],\n",
       " [],\n",
       " ['However, this is not the case for the wide variety of topics that web stores and other service providers have to deal with. The LESSEN project is developing a practice-based AI technology that is adaptable to the topic and target audience of businesses. This will ultimately allow users to have a better conversation with apps, computers and the services they provide access to.'],\n",
       " ['From Leiden University, Suzan Verberne and Jan van Rijn are co-applicants. Verberne will work on adapting conversational models to new topics for which little data is available. Van Rijn will investigate how AI models can be trained as efficiently as possible and, moreover, communicate with customers in real time. Another important goal of the Leiden team is to make the developed technology transparent to customers and to ensure that the personal data of users is handled safely.'],\n",
       " [],\n",
       " [],\n",
       " ['Will AI dominate humans in the future? Van Duijn thinks not, but the technology is getting smarter. Van Duijn: Technologies are sometimes very intelligent, but they are mainly so in one domain. I think the number of domains will increase and overlap. Technology will certainly surprise us in the coming decade.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['We are in a real revolution, says Aske Plaat. Progress is fast. Just look at chatbot ChatGPT, a chatbot that writes an essay for you in less than a minute. It is important not to trust AI blindly. Plaat thinks that we will certainly make mistakes and that AI will often surprise us. But in the end, we decide for ourselves how we use AI.'],\n",
       " [],\n",
       " [],\n",
       " ['his event aims to explore the issue of gender and other biases in AI and how we can address them. Our expert panel will discuss the impact of biases in AI and share their insights on how to mitigate them. Our speakers will also highlight the importance of creating inclusive AI systems that take into account the needs and perspectives of diverse communities. This event is an opportunity for interested alumni to come together and discuss prejudice in AI, algorithms and the tech sector. We hope to spark meaningful conversations that inspire action for those using AI systems either profesionally or personally.'],\n",
       " [],\n",
       " ['On Thursday June, -4 pm in room Lipsius there will be a workshop on ChatGPT and writing education, given by prof.dr. Lieve de Wachter, Professor of Dutch Language Proficiency and Academic Dutch at KU Leuven.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [\"By all standards, ChatGPT is a linguistic miracle. The bot responds to queries with astonishing accuracy, flexibility, and fluency. Its potential raises the question what the bot knows about languages. In this talk, I will try and show that the answer to this question is paradoxical: the language machine is so convincingly good because its language model does not exhaust meaning, to put it mildly. Ironically, academic linguistics - a pillar of humanities - also tends to neglect propositional semantics. From a semantic point of view, then, ChatGPT and its likes meet the noble art of grammar in dark space: neither the bot (in the past decade) nor academic linguistics (in the past millennia) has been operating a solid model of sentence meaning. For academic linguistics, this is just another horizon to explore. For linguistic engineering, neglecting propositional meaning is both a blessing in disguise and an in-built weakness. ChatGPT cannot know - or account for, or represent, or verify, or ... - what it asserts, since grammar cannot tell you (yet?) what a sentence means, and the bot cannot compute it (yet?). But it seems that we taxpayers do not need a high degree of semantic scrutiny to be satisfied with, and even impressed by, the achievements of language engineering. Could it be, then, that ChapGPT's data-driven text manipulation approaches a semantic asymptote? Or alternatively: what would be the perspective for linguistic engineering if propositional meaning could be computed? Is the absence of a deep semantic component in ChatGPT artificial, or intelligent?\"],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['You cannot prevent it completely, because AI is in constant development. The following seven tips will help the student learn from their writing assignments and make it more difficult to use a program like ChatGPT.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Artificial intelligence will certainly play a greater role in society and science in the future. It offers great opportunities but also poses new challenges. Leiden University sees it as its task to teach students how to approach AI in a critical and responsible manner. We are committed to ensuring that education remains in line with this new development.'],\n",
       " [],\n",
       " [\"he other important reason why you should not use AI programmes for written assignments is that by doing so, you are hindering your academic development. After all, if you rely on artificial intelligence to write assignments, you will not develop the skills you need to graduate. For your bachelor's or master's thesis, you must demonstrate under intensive supervision that you are able to conduct research and write about it. If you have not developed these skills sufficiently, you will fall behind in your studies or fail to graduate.\"],\n",
       " [],\n",
       " ['ChatGPT and similar tools are on the rise. How can we deal with this as a university and faculty? There are concerns within the education sector about fraud by students. If they start relying on artificial intelligence, they will be unable to develop the skills they need to graduate. This affects not only education, but also other sections of the university and society. Besides looking at how we can prevent fraud, we are also exploring how in the long term we can actually work with applications like ChatGPT. Below, we explain what it is, when something is actually fraud, and, above all, how students can still develop their skills for written assignments.'],\n",
       " ['ChatGPT generates text in response to a prompt (a question or command given by a user) and based on a gigantic dataset of text material (originating from sources including e.g. the internet). Users can indicate how long the text should be and what form it should have. The program generates these texts by predicting (using statistics) what the next word in the text will most likely be. This prediction is based on a phrase or sentences that have been used before.'],\n",
       " [],\n",
       " [],\n",
       " ['We do not want teaching staff to rush to replace written assignments, take-home exams, and other types of assessments with a written exam on location. This is logistically impossible. Moreover, the method of assessment stated in the course description in the e-Prospectus is part of the Course and Examination Regulations (OER) of the current academic year. So it is not possible to simply change this once the academic year has started. As mentioned above, we will also be looking at opportunities for actually using such AI programs in our work.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['AI chatbots are the hot topic of the moment. Their impressive ability to generate human-like text has sparked many discussions focused on the the risk that students might use these new tools to cheat on assignments.At LLInC we acknowledge the challenges and weve shared ways to adjust assignments accordingly. At the same time, we see fantastic potential to use AI chatbots as support tools. With the right prompts, teachers, students, researchers and university staff can use them to work more efficiently and discover new perspectives on topics and tasks.To help you learn more, were sharing a hands-on exercise that will help you to quickly spot opportunities and limitations. The exercise was originally written for ChatGPT but can also help you to test out other AI chatbots.'],\n",
       " ['At LLInC we acknowledge the challenges and weve shared ways to adjust assignments accordingly. At the same time, we see fantastic potential to use AI chatbots as support tools. With the right prompts, teachers, students, researchers and university staff can use them to work more efficiently and discover new perspectives on topics and tasks.To help you learn more, were sharing a hands-on exercise that will help you to quickly spot opportunities and limitations. The exercise was originally written for ChatGPT but can also help you to test out other AI chatbots.'],\n",
       " ['o help you learn more, were sharing a hands-on exercise that will help you to quickly spot opportunities and limitations. The exercise was originally written for ChatGPT but can also help you to test out other AI chatbots.'],\n",
       " ['In this exercise youll play around with ChatGPT so that you better understand how it can be used in higher education. First youll try out some basic prompts with different end users in mind. Next, try ChatGPT as an assistant for your daily work tasks. Finally, have a free-form chat conversation on a topic that interests you.Before you dive into the exercises, navigate to Create an account if youre a new user. Because of the high interest in ChatGPT, it might be at full capacity when you try to access it. If so, simply try again later.Part : Try out prompts and explore use cases for different usersWeve created sample prompts for you. Use them to empathise with different perspectives and possible uses. If youre a teacher: do these prompts help you to see how ChatGPT could help students? Are you inspired to use ChatGPT in your courses?Play around with the prompts. Feel free to rephrase sentences to reflect your interests, or come up with your own prompts.Student Prompts: Explain the purpose [CONCEPT] in [FIELD] Provide examples of how [CONCEPT] is used Summarise main ideas behind [SUBJECT]/[CONCEPT] Describe how [CONCEPT1] and [CONCEPT2] are related Create a study plan for [SUBJECT] Summarise key points from [BOOK]/[PAPER] Generate practice problems and solutions for [CONCEPT]/[SUBJECT] Discuss the history and development of [CONCEPT] Provide a step-by-step plan to research [TOPIC] / write [ESSAY] / create [PROJECT] Create flash cards for [SUBJECT] Define all technical terms and definitions related to [SUBJECT] Generate examples of applications of [SUBJECT]/[CONCEPT] Provide detailed actions needed to solve [PROBLEM] Write the main resources needed for learning [SUBJECT] Rewrite [TEXT] such that it has the same tone and fix any mistakes Teacher Prompts: Propose assessments that are not affected by students using ChatGPT in [SUBJECT] Develop a list of prompts that students can send ChatGPT to learn about [SUBJECT] Generate a sample lesson for teaching [TOPIC] Create quiz/homework assignment/project for students to assess their understanding of [TOPIC]/[CONCEPT] Propose discussions questions for students on [TOPIC] Develop a list of recommended resources for [SUBJECT]/[TOPIC] Write slides for a presentation/lesson about [CONCEPT]/[TOPIC] Write a syllabus for [SUBJECT] class Generate a list of class readings for [SUBJECT] Identify main concepts that students have difficulty understanding in [TOPIC] Researcher Prompts: Generate a list of keywords related to [TOPIC] Provide an overview of current research on [TOPIC] Summarize key finding of [PAPER] Provide a list of relevant academic journal for publishing research on [TOPIC] Provide a list of related studies or research on [TOPIC] Write a literature review for [PAPER] Provide a list of relevant funding opportunities for research on [TOPIC] Generate a list of research question for a study on [TOPIC] Create a step-by-step plan to write a paper to answer [RESEARCH_QUESTION] Provide a list of tools and software that aid in researching [TOPIC] Create survey about [RESEARCH_QUESTION] Write a research proposal outline about [TOPIC] Provide a list of ethical consideration for a study about [TOPIC] Write abstract/introduction/conclusion about [RESEARCH] Create a research plan and timeline for [RESEARCH] Part : Use ChatGPT as your work assistantOn a regular work day, open ChatGPT on a second display for the whole day. Whenever you are performing a specific task, ask it for help. For example, you might ask: How can I do [TASK]? Write a [DETAILED/OVERVIEW/ETC] step-by-step instruction on how to perform [TASK] Provide different best options/best practices to perform [TASK] Even if you know how to perform the task, ChatGPT might provide different approaches or help you to do the task more efficiently. Part : Discuss a topic with ChatGPTHave a longer free-form chat with ChatGPT about something that interests you. You can also use it on your phone, so this might be a good task when you are commuting or waiting for an appointment. For example, you can ask it to tell you a joke or recommend a book based on your favourite authors or genres. You can also discuss philosophical or ethical questions with ChatGPT.Reflecting on your experienceNow lets take some time to reflect. Did ChatGPT give you new insights on the topics you asked it about? Are you inspired to integrate ChatGPT into your educational program, course or daily work? If so, how? What is your biggest doubt or concern?Wed love to hear your answers to these questions. You are welcome to share your thoughts anonymously in our WooClap. If we get enough replies, we will share them in a future blogpost. You might also discuss your ChatGPT experience with others. Do they have other interesting ideas for using ChatGPT? How do they see this type of technology being used within education?'],\n",
       " ['Before you dive into the exercises, navigate to Create an account if youre a new user. Because of the high interest in ChatGPT, it might be at full capacity when you try to access it. If so, simply try again later.Part : Try out prompts and explore use cases for different usersWeve created sample prompts for you. Use them to empathise with different perspectives and possible uses. If youre a teacher: do these prompts help you to see how ChatGPT could help students? Are you inspired to use ChatGPT in your courses?Play around with the prompts. Feel free to rephrase sentences to reflect your interests, or come up with your own prompts.Student Prompts: Explain the purpose [CONCEPT] in [FIELD] Provide examples of how [CONCEPT] is used Summarise main ideas behind [SUBJECT]/[CONCEPT] Describe how [CONCEPT1] and [CONCEPT2] are related Create a study plan for [SUBJECT] Summarise key points from [BOOK]/[PAPER] Generate practice problems and solutions for [CONCEPT]/[SUBJECT] Discuss the history and development of [CONCEPT] Provide a step-by-step plan to research [TOPIC] / write [ESSAY] / create [PROJECT] Create flash cards for [SUBJECT] Define all technical terms and definitions related to [SUBJECT] Generate examples of applications of [SUBJECT]/[CONCEPT] Provide detailed actions needed to solve [PROBLEM] Write the main resources needed for learning [SUBJECT] Rewrite [TEXT] such that it has the same tone and fix any mistakes Teacher Prompts: Propose assessments that are not affected by students using ChatGPT in [SUBJECT] Develop a list of prompts that students can send ChatGPT to learn about [SUBJECT] Generate a sample lesson for teaching [TOPIC] Create quiz/homework assignment/project for students to assess their understanding of [TOPIC]/[CONCEPT] Propose discussions questions for students on [TOPIC] Develop a list of recommended resources for [SUBJECT]/[TOPIC] Write slides for a presentation/lesson about [CONCEPT]/[TOPIC] Write a syllabus for [SUBJECT] class Generate a list of class readings for [SUBJECT] Identify main concepts that students have difficulty understanding in [TOPIC] Researcher Prompts: Generate a list of keywords related to [TOPIC] Provide an overview of current research on [TOPIC] Summarize key finding of [PAPER] Provide a list of relevant academic journal for publishing research on [TOPIC] Provide a list of related studies or research on [TOPIC] Write a literature review for [PAPER] Provide a list of relevant funding opportunities for research on [TOPIC] Generate a list of research question for a study on [TOPIC] Create a step-by-step plan to write a paper to answer [RESEARCH_QUESTION] Provide a list of tools and software that aid in researching [TOPIC] Create survey about [RESEARCH_QUESTION] Write a research proposal outline about [TOPIC] Provide a list of ethical consideration for a study about [TOPIC] Write abstract/introduction/conclusion about [RESEARCH] Create a research plan and timeline for [RESEARCH] Part : Use ChatGPT as your work assistantOn a regular work day, open ChatGPT on a second display for the whole day. Whenever you are performing a specific task, ask it for help. For example, you might ask: How can I do [TASK]? Write a [DETAILED/OVERVIEW/ETC] step-by-step instruction on how to perform [TASK] Provide different best options/best practices to perform [TASK] Even if you know how to perform the task, ChatGPT might provide different approaches or help you to do the task more efficiently. Part : Discuss a topic with ChatGPTHave a longer free-form chat with ChatGPT about something that interests you. You can also use it on your phone, so this might be a good task when you are commuting or waiting for an appointment. For example, you can ask it to tell you a joke or recommend a book based on your favourite authors or genres. You can also discuss philosophical or ethical questions with ChatGPT.Reflecting on your experienceNow lets take some time to reflect. Did ChatGPT give you new insights on the topics you asked it about? Are you inspired to integrate ChatGPT into your educational program, course or daily work? If so, how? What is your biggest doubt or concern?Wed love to hear your answers to these questions. You are welcome to share your thoughts anonymously in our WooClap. If we get enough replies, we will share them in a future blogpost. You might also discuss your ChatGPT experience with others. Do they have other interesting ideas for using ChatGPT? How do they see this type of technology being used within education?'],\n",
       " ['Weve created sample prompts for you. Use them to empathise with different perspectives and possible uses. If youre a teacher: do these prompts help you to see how ChatGPT could help students? Are you inspired to use ChatGPT in your courses?Play around with the prompts. Feel free to rephrase sentences to reflect your interests, or come up with your own prompts.Student Prompts: Explain the purpose [CONCEPT] in [FIELD] Provide examples of how [CONCEPT] is used Summarise main ideas behind [SUBJECT]/[CONCEPT] Describe how [CONCEPT1] and [CONCEPT2] are related Create a study plan for [SUBJECT] Summarise key points from [BOOK]/[PAPER] Generate practice problems and solutions for [CONCEPT]/[SUBJECT] Discuss the history and development of [CONCEPT] Provide a step-by-step plan to research [TOPIC] / write [ESSAY] / create [PROJECT] Create flash cards for [SUBJECT] Define all technical terms and definitions related to [SUBJECT] Generate examples of applications of [SUBJECT]/[CONCEPT] Provide detailed actions needed to solve [PROBLEM] Write the main resources needed for learning [SUBJECT] Rewrite [TEXT] such that it has the same tone and fix any mistakes Teacher Prompts: Propose assessments that are not affected by students using ChatGPT in [SUBJECT] Develop a list of prompts that students can send ChatGPT to learn about [SUBJECT] Generate a sample lesson for teaching [TOPIC] Create quiz/homework assignment/project for students to assess their understanding of [TOPIC]/[CONCEPT] Propose discussions questions for students on [TOPIC] Develop a list of recommended resources for [SUBJECT]/[TOPIC] Write slides for a presentation/lesson about [CONCEPT]/[TOPIC] Write a syllabus for [SUBJECT] class Generate a list of class readings for [SUBJECT] Identify main concepts that students have difficulty understanding in [TOPIC] Researcher Prompts: Generate a list of keywords related to [TOPIC] Provide an overview of current research on [TOPIC] Summarize key finding of [PAPER] Provide a list of relevant academic journal for publishing research on [TOPIC] Provide a list of related studies or research on [TOPIC] Write a literature review for [PAPER] Provide a list of relevant funding opportunities for research on [TOPIC] Generate a list of research question for a study on [TOPIC] Create a step-by-step plan to write a paper to answer [RESEARCH_QUESTION] Provide a list of tools and software that aid in researching [TOPIC] Create survey about [RESEARCH_QUESTION] Write a research proposal outline about [TOPIC] Provide a list of ethical consideration for a study about [TOPIC] Write abstract/introduction/conclusion about [RESEARCH] Create a research plan and timeline for [RESEARCH] Part : Use ChatGPT as your work assistantOn a regular work day, open ChatGPT on a second display for the whole day. Whenever you are performing a specific task, ask it for help. For example, you might ask: How can I do [TASK]? Write a [DETAILED/OVERVIEW/ETC] step-by-step instruction on how to perform [TASK] Provide different best options/best practices to perform [TASK] Even if you know how to perform the task, ChatGPT might provide different approaches or help you to do the task more efficiently. Part : Discuss a topic with ChatGPTHave a longer free-form chat with ChatGPT about something that interests you. You can also use it on your phone, so this might be a good task when you are commuting or waiting for an appointment. For example, you can ask it to tell you a joke or recommend a book based on your favourite authors or genres. You can also discuss philosophical or ethical questions with ChatGPT.Reflecting on your experienceNow lets take some time to reflect. Did ChatGPT give you new insights on the topics you asked it about? Are you inspired to integrate ChatGPT into your educational program, course or daily work? If so, how? What is your biggest doubt or concern?Wed love to hear your answers to these questions. You are welcome to share your thoughts anonymously in our WooClap. If we get enough replies, we will share them in a future blogpost. You might also discuss your ChatGPT experience with others. Do they have other interesting ideas for using ChatGPT? How do they see this type of technology being used within education?'],\n",
       " ['Play around with the prompts. Feel free to rephrase sentences to reflect your interests, or come up with your own prompts.Student Prompts: Explain the purpose [CONCEPT] in [FIELD] Provide examples of how [CONCEPT] is used Summarise main ideas behind [SUBJECT]/[CONCEPT] Describe how [CONCEPT1] and [CONCEPT2] are related Create a study plan for [SUBJECT] Summarise key points from [BOOK]/[PAPER] Generate practice problems and solutions for [CONCEPT]/[SUBJECT] Discuss the history and development of [CONCEPT] Provide a step-by-step plan to research [TOPIC] / write [ESSAY] / create [PROJECT] Create flash cards for [SUBJECT] Define all technical terms and definitions related to [SUBJECT] Generate examples of applications of [SUBJECT]/[CONCEPT] Provide detailed actions needed to solve [PROBLEM] Write the main resources needed for learning [SUBJECT] Rewrite [TEXT] such that it has the same tone and fix any mistakes Teacher Prompts: Propose assessments that are not affected by students using ChatGPT in [SUBJECT] Develop a list of prompts that students can send ChatGPT to learn about [SUBJECT] Generate a sample lesson for teaching [TOPIC] Create quiz/homework assignment/project for students to assess their understanding of [TOPIC]/[CONCEPT] Propose discussions questions for students on [TOPIC] Develop a list of recommended resources for [SUBJECT]/[TOPIC] Write slides for a presentation/lesson about [CONCEPT]/[TOPIC] Write a syllabus for [SUBJECT] class Generate a list of class readings for [SUBJECT] Identify main concepts that students have difficulty understanding in [TOPIC] Researcher Prompts: Generate a list of keywords related to [TOPIC] Provide an overview of current research on [TOPIC] Summarize key finding of [PAPER] Provide a list of relevant academic journal for publishing research on [TOPIC] Provide a list of related studies or research on [TOPIC] Write a literature review for [PAPER] Provide a list of relevant funding opportunities for research on [TOPIC] Generate a list of research question for a study on [TOPIC] Create a step-by-step plan to write a paper to answer [RESEARCH_QUESTION] Provide a list of tools and software that aid in researching [TOPIC] Create survey about [RESEARCH_QUESTION] Write a research proposal outline about [TOPIC] Provide a list of ethical consideration for a study about [TOPIC] Write abstract/introduction/conclusion about [RESEARCH] Create a research plan and timeline for [RESEARCH] Part : Use ChatGPT as your work assistantOn a regular work day, open ChatGPT on a second display for the whole day. Whenever you are performing a specific task, ask it for help. For example, you might ask: How can I do [TASK]? Write a [DETAILED/OVERVIEW/ETC] step-by-step instruction on how to perform [TASK] Provide different best options/best practices to perform [TASK] Even if you know how to perform the task, ChatGPT might provide different approaches or help you to do the task more efficiently. Part : Discuss a topic with ChatGPTHave a longer free-form chat with ChatGPT about something that interests you. You can also use it on your phone, so this might be a good task when you are commuting or waiting for an appointment. For example, you can ask it to tell you a joke or recommend a book based on your favourite authors or genres. You can also discuss philosophical or ethical questions with ChatGPT.Reflecting on your experienceNow lets take some time to reflect. Did ChatGPT give you new insights on the topics you asked it about? Are you inspired to integrate ChatGPT into your educational program, course or daily work? If so, how? What is your biggest doubt or concern?Wed love to hear your answers to these questions. You are welcome to share your thoughts anonymously in our WooClap. If we get enough replies, we will share them in a future blogpost. You might also discuss your ChatGPT experience with others. Do they have other interesting ideas for using ChatGPT? How do they see this type of technology being used within education?'],\n",
       " ['Student Prompts: Explain the purpose [CONCEPT] in [FIELD] Provide examples of how [CONCEPT] is used Summarise main ideas behind [SUBJECT]/[CONCEPT] Describe how [CONCEPT1] and [CONCEPT2] are related Create a study plan for [SUBJECT] Summarise key points from [BOOK]/[PAPER] Generate practice problems and solutions for [CONCEPT]/[SUBJECT] Discuss the history and development of [CONCEPT] Provide a step-by-step plan to research [TOPIC] / write [ESSAY] / create [PROJECT] Create flash cards for [SUBJECT] Define all technical terms and definitions related to [SUBJECT] Generate examples of applications of [SUBJECT]/[CONCEPT] Provide detailed actions needed to solve [PROBLEM] Write the main resources needed for learning [SUBJECT] Rewrite [TEXT] such that it has the same tone and fix any mistakes Teacher Prompts: Propose assessments that are not affected by students using ChatGPT in [SUBJECT] Develop a list of prompts that students can send ChatGPT to learn about [SUBJECT] Generate a sample lesson for teaching [TOPIC] Create quiz/homework assignment/project for students to assess their understanding of [TOPIC]/[CONCEPT] Propose discussions questions for students on [TOPIC] Develop a list of recommended resources for [SUBJECT]/[TOPIC] Write slides for a presentation/lesson about [CONCEPT]/[TOPIC] Write a syllabus for [SUBJECT] class Generate a list of class readings for [SUBJECT] Identify main concepts that students have difficulty understanding in [TOPIC] Researcher Prompts: Generate a list of keywords related to [TOPIC] Provide an overview of current research on [TOPIC] Summarize key finding of [PAPER] Provide a list of relevant academic journal for publishing research on [TOPIC] Provide a list of related studies or research on [TOPIC] Write a literature review for [PAPER] Provide a list of relevant funding opportunities for research on [TOPIC] Generate a list of research question for a study on [TOPIC] Create a step-by-step plan to write a paper to answer [RESEARCH_QUESTION] Provide a list of tools and software that aid in researching [TOPIC] Create survey about [RESEARCH_QUESTION] Write a research proposal outline about [TOPIC] Provide a list of ethical consideration for a study about [TOPIC] Write abstract/introduction/conclusion about [RESEARCH] Create a research plan and timeline for [RESEARCH] Part : Use ChatGPT as your work assistantOn a regular work day, open ChatGPT on a second display for the whole day. Whenever you are performing a specific task, ask it for help. For example, you might ask: How can I do [TASK]? Write a [DETAILED/OVERVIEW/ETC] step-by-step instruction on how to perform [TASK] Provide different best options/best practices to perform [TASK] Even if you know how to perform the task, ChatGPT might provide different approaches or help you to do the task more efficiently. Part : Discuss a topic with ChatGPTHave a longer free-form chat with ChatGPT about something that interests you. You can also use it on your phone, so this might be a good task when you are commuting or waiting for an appointment. For example, you can ask it to tell you a joke or recommend a book based on your favourite authors or genres. You can also discuss philosophical or ethical questions with ChatGPT.Reflecting on your experienceNow lets take some time to reflect. Did ChatGPT give you new insights on the topics you asked it about? Are you inspired to integrate ChatGPT into your educational program, course or daily work? If so, how? What is your biggest doubt or concern?Wed love to hear your answers to these questions. You are welcome to share your thoughts anonymously in our WooClap. If we get enough replies, we will share them in a future blogpost. You might also discuss your ChatGPT experience with others. Do they have other interesting ideas for using ChatGPT? How do they see this type of technology being used within education?'],\n",
       " ['eacher Prompts: Propose assessments that are not affected by students using ChatGPT in [SUBJECT] Develop a list of prompts that students can send ChatGPT to learn about [SUBJECT] Generate a sample lesson for teaching [TOPIC] Create quiz/homework assignment/project for students to assess their understanding of [TOPIC]/[CONCEPT] Propose discussions questions for students on [TOPIC] Develop a list of recommended resources for [SUBJECT]/[TOPIC] Write slides for a presentation/lesson about [CONCEPT]/[TOPIC] Write a syllabus for [SUBJECT] class Generate a list of class readings for [SUBJECT] Identify main concepts that students have difficulty understanding in [TOPIC] Researcher Prompts: Generate a list of keywords related to [TOPIC] Provide an overview of current research on [TOPIC] Summarize key finding of [PAPER] Provide a list of relevant academic journal for publishing research on [TOPIC] Provide a list of related studies or research on [TOPIC] Write a literature review for [PAPER] Provide a list of relevant funding opportunities for research on [TOPIC] Generate a list of research question for a study on [TOPIC] Create a step-by-step plan to write a paper to answer [RESEARCH_QUESTION] Provide a list of tools and software that aid in researching [TOPIC] Create survey about [RESEARCH_QUESTION] Write a research proposal outline about [TOPIC] Provide a list of ethical consideration for a study about [TOPIC] Write abstract/introduction/conclusion about [RESEARCH] Create a research plan and timeline for [RESEARCH] Part : Use ChatGPT as your work assistantOn a regular work day, open ChatGPT on a second display for the whole day. Whenever you are performing a specific task, ask it for help. For example, you might ask: How can I do [TASK]? Write a [DETAILED/OVERVIEW/ETC] step-by-step instruction on how to perform [TASK] Provide different best options/best practices to perform [TASK] Even if you know how to perform the task, ChatGPT might provide different approaches or help you to do the task more efficiently. Part : Discuss a topic with ChatGPTHave a longer free-form chat with ChatGPT about something that interests you. You can also use it on your phone, so this might be a good task when you are commuting or waiting for an appointment. For example, you can ask it to tell you a joke or recommend a book based on your favourite authors or genres. You can also discuss philosophical or ethical questions with ChatGPT.Reflecting on your experienceNow lets take some time to reflect. Did ChatGPT give you new insights on the topics you asked it about? Are you inspired to integrate ChatGPT into your educational program, course or daily work? If so, how? What is your biggest doubt or concern?Wed love to hear your answers to these questions. You are welcome to share your thoughts anonymously in our WooClap. If we get enough replies, we will share them in a future blogpost. You might also discuss your ChatGPT experience with others. Do they have other interesting ideas for using ChatGPT? How do they see this type of technology being used within education?'],\n",
       " ['esearcher Prompts: Generate a list of keywords related to [TOPIC] Provide an overview of current research on [TOPIC] Summarize key finding of [PAPER] Provide a list of relevant academic journal for publishing research on [TOPIC] Provide a list of related studies or research on [TOPIC] Write a literature review for [PAPER] Provide a list of relevant funding opportunities for research on [TOPIC] Generate a list of research question for a study on [TOPIC] Create a step-by-step plan to write a paper to answer [RESEARCH_QUESTION] Provide a list of tools and software that aid in researching [TOPIC] Create survey about [RESEARCH_QUESTION] Write a research proposal outline about [TOPIC] Provide a list of ethical consideration for a study about [TOPIC] Write abstract/introduction/conclusion about [RESEARCH] Create a research plan and timeline for [RESEARCH] Part : Use ChatGPT as your work assistantOn a regular work day, open ChatGPT on a second display for the whole day. Whenever you are performing a specific task, ask it for help. For example, you might ask: How can I do [TASK]? Write a [DETAILED/OVERVIEW/ETC] step-by-step instruction on how to perform [TASK] Provide different best options/best practices to perform [TASK] Even if you know how to perform the task, ChatGPT might provide different approaches or help you to do the task more efficiently. Part : Discuss a topic with ChatGPTHave a longer free-form chat with ChatGPT about something that interests you. You can also use it on your phone, so this might be a good task when you are commuting or waiting for an appointment. For example, you can ask it to tell you a joke or recommend a book based on your favourite authors or genres. You can also discuss philosophical or ethical questions with ChatGPT.Reflecting on your experienceNow lets take some time to reflect. Did ChatGPT give you new insights on the topics you asked it about? Are you inspired to integrate ChatGPT into your educational program, course or daily work? If so, how? What is your biggest doubt or concern?Wed love to hear your answers to these questions. You are welcome to share your thoughts anonymously in our WooClap. If we get enough replies, we will share them in a future blogpost. You might also discuss your ChatGPT experience with others. Do they have other interesting ideas for using ChatGPT? How do they see this type of technology being used within education?'],\n",
       " ['On a regular work day, open ChatGPT on a second display for the whole day. Whenever you are performing a specific task, ask it for help. For example, you might ask: How can I do [TASK]? Write a [DETAILED/OVERVIEW/ETC] step-by-step instruction on how to perform [TASK] Provide different best options/best practices to perform [TASK] Even if you know how to perform the task, ChatGPT might provide different approaches or help you to do the task more efficiently. Part : Discuss a topic with ChatGPTHave a longer free-form chat with ChatGPT about something that interests you. You can also use it on your phone, so this might be a good task when you are commuting or waiting for an appointment. For example, you can ask it to tell you a joke or recommend a book based on your favourite authors or genres. You can also discuss philosophical or ethical questions with ChatGPT.Reflecting on your experienceNow lets take some time to reflect. Did ChatGPT give you new insights on the topics you asked it about? Are you inspired to integrate ChatGPT into your educational program, course or daily work? If so, how? What is your biggest doubt or concern?Wed love to hear your answers to these questions. You are welcome to share your thoughts anonymously in our WooClap. If we get enough replies, we will share them in a future blogpost. You might also discuss your ChatGPT experience with others. Do they have other interesting ideas for using ChatGPT? How do they see this type of technology being used within education?'],\n",
       " ['Even if you know how to perform the task, ChatGPT might provide different approaches or help you to do the task more efficiently. Part : Discuss a topic with ChatGPTHave a longer free-form chat with ChatGPT about something that interests you. You can also use it on your phone, so this might be a good task when you are commuting or waiting for an appointment. For example, you can ask it to tell you a joke or recommend a book based on your favourite authors or genres. You can also discuss philosophical or ethical questions with ChatGPT.Reflecting on your experienceNow lets take some time to reflect. Did ChatGPT give you new insights on the topics you asked it about? Are you inspired to integrate ChatGPT into your educational program, course or daily work? If so, how? What is your biggest doubt or concern?Wed love to hear your answers to these questions. You are welcome to share your thoughts anonymously in our WooClap. If we get enough replies, we will share them in a future blogpost. You might also discuss your ChatGPT experience with others. Do they have other interesting ideas for using ChatGPT? How do they see this type of technology being used within education?'],\n",
       " ['Have a longer free-form chat with ChatGPT about something that interests you. You can also use it on your phone, so this might be a good task when you are commuting or waiting for an appointment. For example, you can ask it to tell you a joke or recommend a book based on your favourite authors or genres. You can also discuss philosophical or ethical questions with ChatGPT.Reflecting on your experienceNow lets take some time to reflect. Did ChatGPT give you new insights on the topics you asked it about? Are you inspired to integrate ChatGPT into your educational program, course or daily work? If so, how? What is your biggest doubt or concern?Wed love to hear your answers to these questions. You are welcome to share your thoughts anonymously in our WooClap. If we get enough replies, we will share them in a future blogpost. You might also discuss your ChatGPT experience with others. Do they have other interesting ideas for using ChatGPT? How do they see this type of technology being used within education?'],\n",
       " ['Now lets take some time to reflect. Did ChatGPT give you new insights on the topics you asked it about? Are you inspired to integrate ChatGPT into your educational program, course or daily work? If so, how? What is your biggest doubt or concern?Wed love to hear your answers to these questions. You are welcome to share your thoughts anonymously in our WooClap. If we get enough replies, we will share them in a future blogpost. You might also discuss your ChatGPT experience with others. Do they have other interesting ideas for using ChatGPT? How do they see this type of technology being used within education?'],\n",
       " ['Wed love to hear your answers to these questions. You are welcome to share your thoughts anonymously in our WooClap. If we get enough replies, we will share them in a future blogpost. You might also discuss your ChatGPT experience with others. Do they have other interesting ideas for using ChatGPT? How do they see this type of technology being used within education?'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['he first challenge that many teachers face is being able to tell if students have written a text themselves or automatically generated it using ChatGPT. There are currently no easy ways to detect machine-generated content. Assignments can, however, be adjusted to reflect this short-term challenge. For example, teachers can: Ask students for inline literature references. The current version of ChatGPT is unable to make such references. Flip the assignment. Ask ChatGPT to answer the original assignment and have students do a critical reflection on the output. This is especially effective if done in a classroom setting. Focus the assignments on things that ChatGPT does not or cannot, know. Think of reflections on things that happened in class, hypothetical case studies, things that happened very recently, or that are not well known outside of the Netherlands (or your local community). Switch to long-form assignments like projects or group work. ChatGPT has problems generating text that rely on multiple domains over prolonged periods of time. Ask students to explain how they came to their conclusions. This means that students explicitly answer questions about preparation, structuring ideas and working toward a conclusion (possibly through a presentation or oral discussion). The elaboration is as important as the outcome.We also recommend that teachers discuss ChatGPT specifically, and the use of AI in general, with their students the good and the bad. Using ChatGPT to write a complete essay assignment (and present it as their own original work) is considered fraud. It is acceptable to use ChatGPT as an aid, in the same way as we all use Google and spell-checkers. ChatGPT could, for example, be used as a tutor: providing examples and quizzes, creating learning plans, suggesting resources, and giving feedback to improve academic writing skills (to name a few of its potential uses)Long-term Opportunities Although disruptive now, ChatGPT offers a window into the future promise of AI in education. The possibilities seem endless. Already the LLInC team has explored ChatGPTs potential to support tasks such as generating ideas for mission/vision statements, generating an FAQ for a website, identifying angles of a problem that may have been missed, reviewing of excerpts of writing for style and language use, and writing poems for Sinterklaas a Dutch holiday during which gifts are traditionally accompanied by rhymes about the person receiving the present. For teachers, these generative AI tools can help to create slides and presentations, grade students assignments, plan courses and broadly improve the efficiency and quality of many other tasks that teachers perform. We expect generative AI models to become staple tools in many future workplaces. That being the case, tools like ChatGPT should not be banned. Rather, they need to be integrated into curriculums. Students should be taught the best methods and prompts for using these tools, and how to critically analyze the content produced, so that they are prepared for future roles at work and in society. Lets Experiment Adapting educational programmes wont happen overnight. Students, teachers and educational professionals will need to improve their skill levels. Models and courses will need to be revamped. Recommendations for how to use AI tools will need to evolve as the technologies themselves evolve and increase in their capabilities. This will take time. For the moment, we encourage everyone to experiment. By using these tools, we can increase our own understanding. This is beneficial for us as individuals, and a solid personal grasp of these technologies is certain to be useful as their role increases in our daily lives and society. If we share our experiences and knowledge with others, we can also help our networks and communities to adapt to this new reality, and to reveal ways of using the technology so that it benefits all of us.'],\n",
       " ['We also recommend that teachers discuss ChatGPT specifically, and the use of AI in general, with their students the good and the bad. Using ChatGPT to write a complete essay assignment (and present it as their own original work) is considered fraud. It is acceptable to use ChatGPT as an aid, in the same way as we all use Google and spell-checkers. ChatGPT could, for example, be used as a tutor: providing examples and quizzes, creating learning plans, suggesting resources, and giving feedback to improve academic writing skills (to name a few of its potential uses)Long-term Opportunities Although disruptive now, ChatGPT offers a window into the future promise of AI in education. The possibilities seem endless. Already the LLInC team has explored ChatGPTs potential to support tasks such as generating ideas for mission/vision statements, generating an FAQ for a website, identifying angles of a problem that may have been missed, reviewing of excerpts of writing for style and language use, and writing poems for Sinterklaas a Dutch holiday during which gifts are traditionally accompanied by rhymes about the person receiving the present. For teachers, these generative AI tools can help to create slides and presentations, grade students assignments, plan courses and broadly improve the efficiency and quality of many other tasks that teachers perform. We expect generative AI models to become staple tools in many future workplaces. That being the case, tools like ChatGPT should not be banned. Rather, they need to be integrated into curriculums. Students should be taught the best methods and prompts for using these tools, and how to critically analyze the content produced, so that they are prepared for future roles at work and in society. Lets Experiment Adapting educational programmes wont happen overnight. Students, teachers and educational professionals will need to improve their skill levels. Models and courses will need to be revamped. Recommendations for how to use AI tools will need to evolve as the technologies themselves evolve and increase in their capabilities. This will take time. For the moment, we encourage everyone to experiment. By using these tools, we can increase our own understanding. This is beneficial for us as individuals, and a solid personal grasp of these technologies is certain to be useful as their role increases in our daily lives and society. If we share our experiences and knowledge with others, we can also help our networks and communities to adapt to this new reality, and to reveal ways of using the technology so that it benefits all of us.'],\n",
       " ['Although disruptive now, ChatGPT offers a window into the future promise of AI in education. The possibilities seem endless. Already the LLInC team has explored ChatGPTs potential to support tasks such as generating ideas for mission/vision statements, generating an FAQ for a website, identifying angles of a problem that may have been missed, reviewing of excerpts of writing for style and language use, and writing poems for Sinterklaas a Dutch holiday during which gifts are traditionally accompanied by rhymes about the person receiving the present. For teachers, these generative AI tools can help to create slides and presentations, grade students assignments, plan courses and broadly improve the efficiency and quality of many other tasks that teachers perform. We expect generative AI models to become staple tools in many future workplaces. That being the case, tools like ChatGPT should not be banned. Rather, they need to be integrated into curriculums. Students should be taught the best methods and prompts for using these tools, and how to critically analyze the content produced, so that they are prepared for future roles at work and in society. Lets Experiment Adapting educational programmes wont happen overnight. Students, teachers and educational professionals will need to improve their skill levels. Models and courses will need to be revamped. Recommendations for how to use AI tools will need to evolve as the technologies themselves evolve and increase in their capabilities. This will take time. For the moment, we encourage everyone to experiment. By using these tools, we can increase our own understanding. This is beneficial for us as individuals, and a solid personal grasp of these technologies is certain to be useful as their role increases in our daily lives and society. If we share our experiences and knowledge with others, we can also help our networks and communities to adapt to this new reality, and to reveal ways of using the technology so that it benefits all of us.'],\n",
       " ['Already the LLInC team has explored ChatGPTs potential to support tasks such as generating ideas for mission/vision statements, generating an FAQ for a website, identifying angles of a problem that may have been missed, reviewing of excerpts of writing for style and language use, and writing poems for Sinterklaas a Dutch holiday during which gifts are traditionally accompanied by rhymes about the person receiving the present. For teachers, these generative AI tools can help to create slides and presentations, grade students assignments, plan courses and broadly improve the efficiency and quality of many other tasks that teachers perform. We expect generative AI models to become staple tools in many future workplaces. That being the case, tools like ChatGPT should not be banned. Rather, they need to be integrated into curriculums. Students should be taught the best methods and prompts for using these tools, and how to critically analyze the content produced, so that they are prepared for future roles at work and in society. Lets Experiment Adapting educational programmes wont happen overnight. Students, teachers and educational professionals will need to improve their skill levels. Models and courses will need to be revamped. Recommendations for how to use AI tools will need to evolve as the technologies themselves evolve and increase in their capabilities. This will take time. For the moment, we encourage everyone to experiment. By using these tools, we can increase our own understanding. This is beneficial for us as individuals, and a solid personal grasp of these technologies is certain to be useful as their role increases in our daily lives and society. If we share our experiences and knowledge with others, we can also help our networks and communities to adapt to this new reality, and to reveal ways of using the technology so that it benefits all of us.'],\n",
       " ['For teachers, these generative AI tools can help to create slides and presentations, grade students assignments, plan courses and broadly improve the efficiency and quality of many other tasks that teachers perform. We expect generative AI models to become staple tools in many future workplaces. That being the case, tools like ChatGPT should not be banned. Rather, they need to be integrated into curriculums. Students should be taught the best methods and prompts for using these tools, and how to critically analyze the content produced, so that they are prepared for future roles at work and in society. Lets Experiment Adapting educational programmes wont happen overnight. Students, teachers and educational professionals will need to improve their skill levels. Models and courses will need to be revamped. Recommendations for how to use AI tools will need to evolve as the technologies themselves evolve and increase in their capabilities. This will take time. For the moment, we encourage everyone to experiment. By using these tools, we can increase our own understanding. This is beneficial for us as individuals, and a solid personal grasp of these technologies is certain to be useful as their role increases in our daily lives and society. If we share our experiences and knowledge with others, we can also help our networks and communities to adapt to this new reality, and to reveal ways of using the technology so that it benefits all of us.'],\n",
       " ['We expect generative AI models to become staple tools in many future workplaces. That being the case, tools like ChatGPT should not be banned. Rather, they need to be integrated into curriculums. Students should be taught the best methods and prompts for using these tools, and how to critically analyze the content produced, so that they are prepared for future roles at work and in society. Lets Experiment Adapting educational programmes wont happen overnight. Students, teachers and educational professionals will need to improve their skill levels. Models and courses will need to be revamped. Recommendations for how to use AI tools will need to evolve as the technologies themselves evolve and increase in their capabilities. This will take time. For the moment, we encourage everyone to experiment. By using these tools, we can increase our own understanding. This is beneficial for us as individuals, and a solid personal grasp of these technologies is certain to be useful as their role increases in our daily lives and society. If we share our experiences and knowledge with others, we can also help our networks and communities to adapt to this new reality, and to reveal ways of using the technology so that it benefits all of us.'],\n",
       " ['Adapting educational programmes wont happen overnight. Students, teachers and educational professionals will need to improve their skill levels. Models and courses will need to be revamped. Recommendations for how to use AI tools will need to evolve as the technologies themselves evolve and increase in their capabilities. This will take time. For the moment, we encourage everyone to experiment. By using these tools, we can increase our own understanding. This is beneficial for us as individuals, and a solid personal grasp of these technologies is certain to be useful as their role increases in our daily lives and society. If we share our experiences and knowledge with others, we can also help our networks and communities to adapt to this new reality, and to reveal ways of using the technology so that it benefits all of us.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['he recent generative turn in Artificial Intelligence has struck many of us, both inside and outside the directly involved research fields. In the realm of natural language generation, OpenAIs ChatGPT has demonstrated striking abilities to engage in convincing conversations on virtually any topic. Over the past months, researchers have debated extensively to what degree this model understands things about the world, including the social-cognitive realm of beliefs, desires, intentions, etc. We conducted various experiments using standardised Theory of Mind tasks with GTP3 and, in parallel, with children aged -9. I will present some of the results an discuss what I think they mean, while placing them in the broader context of current discussions about emergent cognitive capacities in generative language models.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Ana Nio: Free Online Machine Translation (FOMT) vs. ChatGPT: what opportunities and challenges do these AI tools bring to the language teaching and learning context? This presentation starts with the realization of how AI tools such as FOMT and ChatGPT have revolutionized language learning and teaching from learning design to language practice, without forgetting assessment and feedback. Bearing in mind the principles for CALL evaluation (Chapelle, *), it will contrast FOMT against generative AI tools such as ChatGPT as potential CALL tools, drawing on the benefits they offer and their current limitations. Ultimately, some pedagogical suggestions for the use of these tools in the language class will be outlined, together with future directions to get adapted and embrace these omnipresent technologies.'],\n",
       " [\"here is no doubt that OpenAI's release of chatGPT in late was a watershed moment in the development and perception of AI. In this talk I will discuss what has been achieved (and what hasn't), and how this affects the AI research landscape. Questions that will pass the review include: What are chatGPT's most surprising capabilities? Has AI now passed the Turing test? Why is overconfidence a problem, and what can we do about it? And finally, where does this leave machine learning and AI research?\"],\n",
       " [],\n",
       " ['he question of which jobs will become redundant due to automation has occupied working people since the industrial revolution. In , the University of Oxford published a controversial study about professions that would soon disappear due to automation. Cashier, call center employee and secretary were high on the list. In particular, technological innovations such as AI, machine learning and blockchain were cited as the cause. Ten years later, the National Vacature Bank investigated whether the predictions come true and what has changed. The career site mapped out the future-proofness of different professions, partly based on UWV data. Danger zone Some popular jobs that can be replaced according to the National Vacancy Bank are (financial) administrative assistant, office manager and executive secretary. Many of their tasks are taken over by smart software. Statistics Netherlands data shows that the number of administrative employees already decreased by percent between and , while the number of secretaries decreased by no less than a third in that period: from to . Suzanne IJzerman, labor market advisor at UWV, does have a comment at these figures. The functions that are threatened by digitization, she says, are mainly those at the MBO level. An executive secretaries at higher vocational education level have very different tasks and skills, such as project management or a deeper insight into the portfolio. The demand for secretaries at that level is certainly still increasing. There is also a demand for bookkeepers and financial administrators who have a more advisory function, and thus help think about savings for the organization, for example.\\' Routine work is replaced much sooner.\\' - Suzanne IJzerman, labor market adviser at UWV - Routine work replaced earlierRecently, a major study was launched. An international consortium won a Horizon Europe grant of million euros to map the impact of global social changes on the labor market. In addition to digitization, the study also looks at migration and climate transition, says project leader and professor at Leiden University Olaf van Vliet. You see, for example, that many transport jobs in the Netherlands are now mainly practiced by people from Eastern and Central Europe. At the same time, globalization offers opportunities for highly educated people. Due to climate policy and the energy transition, more and more jobs in polluting sectors will probably disappear in the long term. But the latter trend is also creating new jobs. \\'A lot of work is shifting from the brown to the green sector; people who previously installed central heating boilers may now work with heat pumps or solar panels. The question is: can employees make that transition? Should they retrain or retrain? If they are properly guided in this, we will see less friction on the labor market.\\' The UWV publishes a list of promising professions every year. Some of these future-proof jobs include: machine and tool designer, assistant accountant, human resources officer/HR employee, recruiter, and elementary school group teacher. IJzerman: \\'What these promising jobs have in common is that they are less easy to digitize. Routine work is replaced much earlier.\\' According to her, there is still a strong need for human work, such as childcare workers, teachers or care workers. Professions in technology or transport cannot be digitized quickly either. Consider, for example, the installation and maintenance of machines and equipment or the truck driver who delivers goods. \\'ChatGPT The trends that the National Vacancy Bank survey and UWV visualize can be put to good use by students and job seekers in their choice of study, career switch or job hunt. Because you may have your eye on a dream job, but how do you know whether it is future-proof? IJzerman has seen four very constant sectors in the list of promising professions in recent years. In technology, ICT, healthcare and education, people are still very much needed. Looking further ahead, artificial intelligence invariably appears in the crystal ball. When ChatGPT was introduced at the end of last year, many people anxiously googled whether their job would soon be referred to the Stone Age. IJzerman and her team did a small test at the UWV. We experimented with ChatGPT, but we couldn\\'t write a current article with it. Substantive expertise remains necessary to assess the generated texts. To a certain extent, questions can be answered with, for example, a good website or the use of chatbots, but call center employees are still needed for more complex questions. AI also offers opportunities, says Van Vliet. \"It li'],\n",
       " [\"Some popular jobs that can be replaced according to the National Vacancy Bank are (financial) administrative assistant, office manager and executive secretary. Many of their tasks are taken over by smart software. Statistics Netherlands data shows that the number of administrative employees already decreased by percent between and , while the number of secretaries decreased by no less than a third in that period: from to . Suzanne IJzerman, labor market advisor at UWV, does have a comment at these figures. The functions that are threatened by digitization, she says, are mainly those at the MBO level. An executive secretaries at higher vocational education level have very different tasks and skills, such as project management or a deeper insight into the portfolio. The demand for secretaries at that level is certainly still increasing. There is also a demand for bookkeepers and financial administrators who have a more advisory function, and thus help think about savings for the organization, for example.' Routine work is replaced much sooner.' - Suzanne IJzerman, labor market adviser at UWV - Routine work replaced earlierRecently, a major study was launched. An international consortium won a Horizon Europe grant of million euros to map the impact of global social changes on the labor market. In addition to digitization, the study also looks at migration and climate transition, says project leader and professor at Leiden University Olaf van Vliet. You see, for example, that many transport jobs in the Netherlands are now mainly practiced by people from Eastern and Central Europe. At the same time, globalization offers opportunities for highly educated people. Due to climate policy and the energy transition, more and more jobs in polluting sectors will probably disappear in the long term. But the latter trend is also creating new jobs. 'A lot of work is shifting from the brown to the green sector; people who previously installed central heating boilers may now work with heat pumps or solar panels. The question is: can employees make that transition? Should they retrain or retrain? If they are properly guided in this, we will see less friction on the labor market.' The UWV publishes a list of promising professions every year. Some of these future-proof jobs include: machine and tool designer, assistant accountant, human resources officer/HR employee, recruiter, and elementary school group teacher. IJzerman: 'What these promising jobs have in common is that they are less easy to digitize. Routine work is replaced much earlier.' According to her, there is still a strong need for human work, such as childcare workers, teachers or care workers. Professions in technology or transport cannot be digitized quickly either. Consider, for example, the installation and maintenance of machines and equipment or the truck driver who delivers goods. 'ChatGPT The trends that the National Vacancy Bank survey and UWV visualize can be put to good use by students and job seekers in their choice of study, career switch or job hunt. Because you may have your eye on a dream job, but how do you know whether it is future-proof? IJzerman has seen four very constant sectors in the list of promising professions in recent years. In technology, ICT, healthcare and education, people are still very much needed. Looking further ahead, artificial intelligence invariably appears in the crystal ball. When ChatGPT was introduced at the end of last year, many people anxiously googled whether their job would soon be referred to the Stone Age. IJzerman and her team did a small test at the UWV. We experimented with ChatGPT, but we couldn't write a current article with it. Substantive expertise remains necessary to assess the generated texts. To a certain extent, questions can be answered with, for example, a good website or the use of chatbots, but call center employees are still needed for more complex questions. AI also offers opportunities, says Van Vliet. It seems very threatening, but you could specialize in using ChatGPT optimally. I do have the impression that young people show a lot of interest in future-oriented courses, such as designing games. There will undoubtedly be a lot of work in this area in the coming years. Read more about the research on the National Vacancy Bank. Are you looking for a future-proof job? View the latest vacancies via Intermediair's job finder.\"],\n",
       " [\"A major investigation was recently launched. An international consortium won a Horizon Europe grant of million euros to map the impact of global social changes on the labor market. In addition to digitization, the study also looks at migration and climate transition, says project leader and professor at Leiden University Olaf van Vliet. You see, for example, that many transport jobs in the Netherlands are now mainly practiced by people from Eastern and Central Europe. At the same time, globalization offers opportunities for highly educated people. Due to climate policy and the energy transition, more and more jobs in polluting sectors will probably disappear in the long term. But the latter trend is also creating new jobs. 'A lot of work is shifting from the brown to the green sector; people who previously installed central heating boilers may now work with heat pumps or solar panels. The question is: can employees make that transition? Should they retrain or retrain? If they are properly guided in this, we will see less friction on the labor market.' The UWV publishes a list of promising professions every year. Some of these future-proof jobs include: machine and tool designer, assistant accountant, human resources officer/HR employee, recruiter, and elementary school group teacher. IJzerman: 'What these promising jobs have in common is that they are less easy to digitize. Routine work is replaced much earlier.' According to her, there is still a strong need for human work, such as childcare workers, teachers or care workers. Professions in technology or transport cannot be digitized quickly either. Consider, for example, the installation and maintenance of machines and equipment or the truck driver who delivers goods. 'ChatGPT The trends that the National Vacancy Bank survey and UWV visualize can be put to good use by students and job seekers in their choice of study, career switch or job hunt. Because you may have your eye on a dream job, but how do you know whether it is future-proof? IJzerman has seen four very constant sectors in the list of promising professions in recent years. In technology, ICT, healthcare and education, people are still very much needed. Looking further ahead, artificial intelligence invariably appears in the crystal ball. When ChatGPT was introduced at the end of last year, many people anxiously googled whether their job would soon be referred to the Stone Age. IJzerman and her team did a small test at the UWV. We experimented with ChatGPT, but we couldn't write a current article with it. Substantive expertise remains necessary to assess the generated texts. To a certain extent, questions can be answered with, for example, a good website or the use of chatbots, but call center employees are still needed for more complex questions. AI also offers opportunities, says Van Vliet. It seems very threatening, but you could specialize in using ChatGPT optimally. I do have the impression that young people show a lot of interest in future-oriented courses, such as designing games. There will undoubtedly be a lot of work in this area in the coming years. Read more about the research on the National Vacancy Bank. Are you looking for a future-proof job? View the latest vacancies via Intermediair's job finder.\"],\n",
       " [\"Due to climate policy and the energy transition, more and more jobs in polluting sectors will probably disappear in the long term. But the latter trend is also creating new jobs. 'A lot of work is shifting from the brown to the green sector; people who previously installed central heating boilers may now work with heat pumps or solar panels. The question is: can employees make that transition? Should they retrain or retrain? If they are properly guided in this, we will see less friction on the labor market.' The UWV publishes a list of promising professions every year. Some of these future-proof jobs include: machine and tool designer, assistant accountant, human resources officer/HR employee, recruiter, and elementary school group teacher. IJzerman: 'What these promising jobs have in common is that they are less easy to digitize. Routine work is replaced much earlier.' According to her, there is still a strong need for human work, such as childcare workers, teachers or care workers. Professions in technology or transport cannot be digitized quickly either. Consider, for example, the installation and maintenance of machines and equipment or the truck driver who delivers goods. 'ChatGPT The trends that the National Vacancy Bank survey and UWV visualize can be put to good use by students and job seekers in their choice of study, career switch or job hunt. Because you may have your eye on a dream job, but how do you know whether it is future-proof? IJzerman has seen four very constant sectors in the list of promising professions in recent years. In technology, ICT, healthcare and education, people are still very much needed. Looking further ahead, artificial intelligence invariably appears in the crystal ball. When ChatGPT was introduced at the end of last year, many people anxiously googled whether their job would soon be referred to the Stone Age. IJzerman and her team did a small test at the UWV. We experimented with ChatGPT, but we couldn't write a current article with it. Substantive expertise remains necessary to assess the generated texts. To a certain extent, questions can be answered with, for example, a good website or the use of chatbots, but call center employees are still needed for more complex questions. AI also offers opportunities, says Van Vliet. It seems very threatening, but you could specialize in using ChatGPT optimally. I do have the impression that young people show a lot of interest in future-oriented courses, such as designing games. There will undoubtedly be a lot of work in this area in the coming years. Read more about the research on the National Vacancy Bank. Are you looking for a future-proof job? View the latest vacancies via Intermediair's job finder.\"],\n",
       " [\"he UWV publishes a list of promising professions every year. Some of these future-proof jobs include: machine and tool designer, assistant accountant, human resources officer/HR employee, recruiter, and elementary school group teacher. IJzerman: 'What these promising jobs have in common is that they are less easy to digitize. Routine work is replaced much earlier.' According to her, there is still a strong need for human work, such as childcare workers, teachers or care workers. Professions in technology or transport cannot be digitized quickly either. Consider, for example, the installation and maintenance of machines and equipment or the truck driver who delivers goods. 'ChatGPT The trends that the National Vacancy Bank survey and UWV visualize can be put to good use by students and job seekers in their choice of study, career switch or job hunt. Because you may have your eye on a dream job, but how do you know whether it is future-proof? IJzerman has seen four very constant sectors in the list of promising professions in recent years. In technology, ICT, healthcare and education, people are still very much needed. Looking further ahead, artificial intelligence invariably appears in the crystal ball. When ChatGPT was introduced at the end of last year, many people anxiously googled whether their job would soon be referred to the Stone Age. IJzerman and her team did a small test at the UWV. We experimented with ChatGPT, but we couldn't write a current article with it. Substantive expertise remains necessary to assess the generated texts. To a certain extent, questions can be answered with, for example, a good website or the use of chatbots, but call center employees are still needed for more complex questions. AI also offers opportunities, says Van Vliet. It seems very threatening, but you could specialize in using ChatGPT optimally. I do have the impression that young people show a lot of interest in future-oriented courses, such as designing games. There will undoubtedly be a lot of work in this area in the coming years. Read more about the research on the National Vacancy Bank. Are you looking for a future-proof job? View the latest vacancies via Intermediair's job finder.\"],\n",
       " [\"Students and job seekers can make good use of the trends that the National Vacancy Bank survey and the UWV show in their study choice, career switch or job hunt. Because you may have your eye on a dream job, but how do you know whether it is future-proof? IJzerman has seen four very constant sectors in the list of promising professions in recent years. In technology, ICT, healthcare and education, people are still very much needed. Looking further ahead, artificial intelligence invariably appears in the crystal ball. When ChatGPT was introduced at the end of last year, many people anxiously googled whether their job would soon be referred to the Stone Age. IJzerman and her team did a small test at the UWV. We experimented with ChatGPT, but we couldn't write a current article with it. Substantive expertise remains necessary to assess the generated texts. To a certain extent, questions can be answered with, for example, a good website or the use of chatbots, but call center employees are still needed for more complex questions. AI also offers opportunities, says Van Vliet. It seems very threatening, but you could specialize in using ChatGPT optimally. I do have the impression that young people show a lot of interest in future-oriented courses, such as designing games. There will undoubtedly be a lot of work in this area in the coming years. Read more about the research on the National Vacancy Bank. Are you looking for a future-proof job? View the latest vacancies via Intermediair's job finder.\"],\n",
       " [\"If we look further ahead, artificial intelligence invariably appears in the crystal ball. When ChatGPT was introduced at the end of last year, many people anxiously googled whether their job would soon be referred to the Stone Age. IJzerman and her team did a small test at the UWV. We experimented with ChatGPT, but we couldn't write a current article with it. Substantive expertise remains necessary to assess the generated texts. To a certain extent, questions can be answered with, for example, a good website or the use of chatbots, but call center employees are still needed for more complex questions. AI also offers opportunities, says Van Vliet. It seems very threatening, but you could specialize in using ChatGPT optimally. I do have the impression that young people show a lot of interest in future-oriented courses, such as designing games. There will undoubtedly be a lot of work in this area in the coming years. Read more about the research on the National Vacancy Bank. Are you looking for a future-proof job? View the latest vacancies via Intermediair's job finder.\"],\n",
       " [\"According to the research by the National Vacature Bank, call center employees are also a profession with a high automation risk. To a certain extent, questions can be answered with, for example, a good website or the use of chatbots, but call center employees are still needed for more complex questions. AI also offers opportunities, says Van Vliet. It seems very threatening, but you could specialize in using ChatGPT optimally. I do have the impression that young people show a lot of interest in future-oriented courses, such as designing games. There will undoubtedly be a lot of work in this area in the coming years. Read more about the research on the National Vacancy Bank. Are you looking for a future-proof job? View the latest vacancies via Intermediair's job finder.\"],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['We believe the solution for this problem lies in educational chatbots. This project will develop an educational chatbot that provides instant, personalized and context-specific study advice to students in all educational programs at the OU. A pilot chatbot is currently under development at the Faculty of Educational Sciences, but this chatbot features fixed, pre-structured advice methods in one limited setting. This project investigates how a much more general, adaptive chatbot can be obtained for experimental investigation with automated advice strategies on effective learning.'],\n",
       " [\"Based on two introductory presentations by Prof. Anna Berlee, Professor of Data Protection and Privacy Law, and Dr. Clara Maathuis, Assistant Professor of AI & Cyber Operations (both Open University), we dive into the operation of the various new announced and ' released into the wild Generative AI applications such as DallE & Midjourney, ChatGPT, Bing Chat, and Google Bard. What are they actually, how do they work (in general terms), and are these applications free to use or does the law (already) impose restrictions on them, or should there perhaps be restrictions on their use? We will investigate this together with the participants in an interactive meeting. We look forward to welcoming you in Utrecht or online on Saturday May!\"],\n",
       " [],\n",
       " ['he next step is to develop a more general, adaptive chatbot for experimental research with automated advisory strategies around effective learning. The team investigates how what we know about effective learning strategies can be formalized into new representations and algorithms. Based on this, an adaptive dialogue manager, part of the chatbot, can support the learning process of students. More specifically, this project will link up with recent research in the field of artificial intelligence into which formalized knowledge, for example in the form of rules, restrictions or domain knowledge, is introduced.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [\"We all long for spring, because life is so nice when the sun is shining. But do we really only need that golden yellow sphere for that? Or is a healthier lifestyle perhaps the medicine to feel better? Marjan Nijkamp and Trijntje Vllink from our Faculty of Psychology look back and ahead at the symposium they organized 'Lifestyle as medicine for Diabetes'. The successful symposium with a large number of speakers highlighted the successes, but also failed initiatives. And then ChatGPT, will this extremely popular chatbot ensure that we spend less time behind our laptop and can spend more time outside? Three of our scientific collaborators discuss the pros and cons in this issue. One thing is for sure, it's here to stay and it will only get used more and more. Maybe in a few years your student magazine will be made by this program or something like that. I hope not because I enjoy creating it for you every time. Although I might have a little more time to enjoy spring and all its positive effects...Janine CranshofGraphic Designer Modular\"],\n",
       " [\"And then ChatGPT, is this wildly popular chatbot going to ensure that we spend less time behind our laptop and more time outside? Three of our scientific collaborators discuss the pros and cons in this issue. One thing is for sure, it's here to stay and it will only get used more and more. Maybe in a few years your student magazine will be made by this program or something like that. I hope not because I enjoy creating it for you every time. Although I might have a little more time to enjoy spring and all its positive effects...Janine CranshofGraphic Designer Modular\"],\n",
       " [],\n",
       " [],\n",
       " [\"During the symposium there will be a vernissage by the AI artist Alexander Grten from Berlin. Alexander Grten studied Design and Mathematics and has long been working with Hendrik Drachsler on the impact of AI on society, and more specifically education and art. In he wrote his Diploma thesis in philosophy of art entitled 'Can an artificial intelligence understand art'. In his AI art, he focuses on certain graphic styles and prefers to give the AI as much creative freedom as possible.\"],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['In the coming years, Microsoft will invest around ten billion dollars in the further development of the extremely popular chatbot ChatGPT. This AI-based online chat program can answer millions of questions in any area, just like competitor Google can. But ChatGPT can also write texts such as papers and essays itself if you order it. What does the program mean for the learning environment?'],\n",
       " [\"How do you prevent students from committing plagiarism by blindly copying AI texts? Fabian: 'What is plagiarism? Because a text that comes from ChatGPT has not existed before. It is true that we, as teachers, may have to take a closer look at our current writing assignments. Especially because Halszka already said it ChatGPT is here to stay and will eventually become a permanent part of word processing programs, among other things. Hugo: On behalf of all three of us I would like to point out that we are now giving our personal opinion. We are not responsible for OU policies on how to handle ChatGPT. The Open University is going to develop official guidelines for this.'\"],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['he Joint Legal Technologies Program is led by Prof. Dr. Reijer Passchier, Professor of Digitization and the Democratic Rule of Law at the Open University and also affiliated with Leiden University. Lecturers from both universities and guest lecturers from other universities and practitioners are active in the programme. Emeritus professor Prof. Dr. Jaap van den Herik, one of the founders of AI in the Netherlands and co-founder of the original Leiden Legal Technologies Program, will remain connected to the new program as a scientific advisor.'],\n",
       " [],\n",
       " [\"During the symposium there will be a vernissage by the AI artist Alexander Grten from Berlin. Alexander Grten studied Design and Mathematics and has long been collaborating with Hendrik Drachsler on the impact of AI on society, in particular education and art. In he wrote his Diploma thesis in philosophy of art entitled 'Can an artificial intelligence understand art'. In his AI art, he focuses on certain graphic styles and prefers to give the AI as much creative freedom as possible.\"],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['By , the population living in cities will increase by an additional billion people, placing a great strain on resources, infrastructure, jobs and healthcare (UN ). It has become clear that to combat this change, a number of creative approaches need to be put in place to ensure the sustainable growth of cities - one such approach is the smart city (UN ). Due to the relative infancy of smart cities, and the diversity of approaches and implementations of smart information systems (Big Data and AI), many of the ethical challenges are still being defined.One of the reasons behind this challenge is a result of the varying smart information systems (SIS) being used in different urban contexts. This case study aspires to unpack some of these ethical challenges by looking at four different applications of SIS being deployed in large European cities: an AI used to understand citizens complaints (Amsterdam), a parking permit chat-bot (Helsinki), a platform for data exchange (Copenhagen), and a project with an open-source algorithm (Hamburg).Upon first glance, these technologies seem very disparate, but they all factor into the equation of what goes into making a smart city, smart.Over the course of the interviews, what quickly became clear was the degree to which smart cities are in their infancy, meaning that the availability and accuracy of data remains an issue in a large majority of the cases. In terms of the accuracy of recommendations due to the early stages of smart city implementation, many projects remain wary of expanding the use of SIS, due to potential unforeseen issues and are therefore proceeding cautiously.Data has been taken on as a potentially helpful tool for citizens and planners alike to regain control and access to information within their respective cities. Consent, transparency and data ownership featured as prominent ethical considerations in all cases, especially the focus on citizens regaining control over their own data. Further, it remained a point of contention to whom the data would belong with an overall consensus that data should remain the property of the citizen or municipality and not necessarily that of private companies.Throughout the process, it became clear that collaboration is at the heart of a successful smart city. Many of the projects utilised a collaborative public-private model to facilitate both the business development side and the citizen-engagement sides of the smart city. With differing degrees of success in the individual projects, this remained an important feature that experts believe will continue to develop in tandem with smart city projects. A bottom-up approach is clearly the most effective way to ensure that a smart city works and is used by its citizens.Overall, this case study offers valuable insights into the development of smart cities in a European context: including the use and implementation of SIS in urban environments, what kinds of ethical issues are evaluated in the literature and how they contrast and diverge from those faced by professionals in practice. It is hoped that this case study will offer practitioners, policymakers, smart city organisations, and private ICT companies interesting observations about a more ethically responsible approach towards SIS implementation in smart city projects.'],\n",
       " [],\n",
       " ['he new OnePlanet ICAI lab for Precision Health, Nutrition and Behavior is a collaboration between Radboud University, OnePlanet Research Center, Radboudumc and Wageningen University & Research, among others. Eight PhD students and three postdocs will eventually start within the new initiative. Among other things, they work on the development of new sensors, algorithms, chatbots and apps that provide personalized support in the field of health and (eating) behaviour. Guido Camps from Wageningen University & Research and Tibor Bosse from Radboud University will start as academic directors of the new lab. They are enthusiastic about the new collaboration between the various institutes. Bosse: This lab gives us the opportunity to take major steps in the application of Artificial Intelligence in the field of food and healthcare. The personal approach combined with technical means contributes to a necessary change in our eating behaviour. Camps adds: The expertise in the field of AI comes from Radboud University, the sensors from imec, OnePlanet and the other industrial partners and Wageningen University. & Research provides expertise in the field of nutrition and health. By joining forces, I think we will make a real contribution to the field. We know that making nutritional recommendations is quite time consuming in practice. By using smart apps, the important interpersonal side within nutritional advice and (eating) behavior can receive even more attention. About ICAI ICAI is a national network focused on technology and talent development between knowledge institutions, industry and government in the field of Artificial Intelligence. It is the second ICAI lab for WUR, after the AI for Agro-Food Lab. Want to know more? Please contact Guido Camps, guido.camps.nl. More info about the Lab:'],\n",
       " ['Guido Camps from Wageningen University & Research and Tibor Bosse from Radboud University will start as academic directors of the new lab. They are enthusiastic about the new collaboration between the various institutes. Bosse: This lab gives us the opportunity to take major steps in the application of Artificial Intelligence in the field of food and healthcare. The personal approach combined with technical means contributes to a necessary change in our eating behaviour. Camps adds: The expertise in the field of AI comes from Radboud University, the sensors from imec, OnePlanet and the other industrial partners and Wageningen University. & Research provides expertise in the field of nutrition and health. By joining forces, I think we will make a real contribution to the field. We know that making nutritional recommendations is quite time consuming in practice. By using smart apps, the important interpersonal side within nutritional advice and (eating) behavior can receive even more attention. About ICAI ICAI is a national network focused on technology and talent development between knowledge institutions, industry and government in the field of Artificial Intelligence. It is the second ICAI lab for WUR, after the AI for Agro-Food Lab. Want to know more? Please contact Guido Camps, guido.camps.nl. More info about the Lab:'],\n",
       " ['Camps adds: The expertise in the field of AI comes from Radboud University, the sensors from imec, OnePlanet and the other industrial partners, and Wageningen University & Research provides the expertise in the field of nutrition and health. By joining forces, I think we will make a real contribution to the field. We know that making nutritional recommendations is quite time consuming in practice. By using smart apps, the important interpersonal side within nutritional advice and (eating) behavior can receive even more attention. About ICAI ICAI is a national network focused on technology and talent development between knowledge institutions, industry and government in the field of Artificial Intelligence. It is the second ICAI lab for WUR, after the AI for Agro-Food Lab. Want to know more? Please contact Guido Camps, guido.camps.nl. More info about the Lab:'],\n",
       " [],\n",
       " ['here is an urgent need for better, more relevant and visually appealing information aimed at consumers to stimulate behavioural change. But these interventions must also be affordable and easy to implement. By combining our in-depth knowledge of consumer behaviour with the latest AI models, we can develop new approaches that are tailored to how consumers prefer to communicate. This will allow us to improve personalised behavioural interventions in nutrition at a relatively low cost.Feeding AI models with sound knowledge rulesThe problem is that AI models, such as large language models (like ChatGPT) and diffusion models used to convert text to images, can produce convincing but completely inaccurate content. In this PPP, we are developing an AI model that generates content based on in-depth knowledge of consumer behaviour, ensuring that it sticks to facts that are based on scientific evidence. To put it another way, we are feeding current generative AI models with science-based knowledge rules from behavioural science, and we are learning what works best by testing the effectiveness scientifically.Developing an AI marketing toolIn this PPP, we are aiming to develop an AI marketing tool for generating truly personalised nutritional advice. We are aiming to do the following: Understand which aspects of communication encourage healthier and more environmentally friendly behaviour. Here we are focusing on elements such as the emotional setting, the use of colour and social norms in the context of choice. In this project, we can test an almost infinite number of variants, as opposed to the limited customisation options we had before. Design psychosocial guidelines for generative AI models to expand application possibilities, including true personalisation, inclusive texts and automatically adapting advice to reading time, channels or reading ability. Join usWe are looking for the following partners: Organisations with expertise in artificial intelligence and machine learning, with a particular focus on generative models, interested in nutrition as an application area. Organisations with expertise in food science, food consumption behaviour and personalised nutritional advice. Organisations with strong networks and connections in the food sector, both in the Netherlands and internationally. Are you interested in taking part in this exciting development and being at the forefront of using AI for personalised nutritional advice? Then register for our information session without obligation. During this session, we will discuss the project in more detail and answer any questions you may have.'],\n",
       " ['he problem is that AI models, such as large language models (like ChatGPT) and diffusion models used to convert text to images, can produce convincing but completely inaccurate content. In this PPP, we are developing an AI model that generates content based on in-depth knowledge of consumer behaviour, ensuring that it sticks to facts that are based on scientific evidence. To put it another way, we are feeding current generative AI models with science-based knowledge rules from behavioural science, and we are learning what works best by testing the effectiveness scientifically.Developing an AI marketing toolIn this PPP, we are aiming to develop an AI marketing tool for generating truly personalised nutritional advice. We are aiming to do the following: Understand which aspects of communication encourage healthier and more environmentally friendly behaviour. Here we are focusing on elements such as the emotional setting, the use of colour and social norms in the context of choice. In this project, we can test an almost infinite number of variants, as opposed to the limited customisation options we had before. Design psychosocial guidelines for generative AI models to expand application possibilities, including true personalisation, inclusive texts and automatically adapting advice to reading time, channels or reading ability. Join usWe are looking for the following partners: Organisations with expertise in artificial intelligence and machine learning, with a particular focus on generative models, interested in nutrition as an application area. Organisations with expertise in food science, food consumption behaviour and personalised nutritional advice. Organisations with strong networks and connections in the food sector, both in the Netherlands and internationally. Are you interested in taking part in this exciting development and being at the forefront of using AI for personalised nutritional advice? Then register for our information session without obligation. During this session, we will discuss the project in more detail and answer any questions you may have.'],\n",
       " [],\n",
       " ['Are you interested in taking part in this exciting development and being at the forefront of using AI for personalised nutritional advice? Then register for our information session without obligation. During this session, we will discuss the project in more detail and answer any questions you may have.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [\"ChatGPT is a chatbot based on artificial intelligence using a large language model. It is trained on large datasets of human language. Language models have been around for quite some time and most of us use them regularly. These models range from predicting the words youll type to more advanced Siri or Google Home assistants. What is new about ChatGPT is its ability to have strikingly natural conversations and to produce fluid texts on a huge range of topics. General issues with ChatGPT It is important to keep the following general shortcomings in mind:ChatGPT is not a search engine. It has been trained with a large amount of information, but the chatbot doesnt understand the meaning of the information itself.ChatGPT is developed and distributed by OpenAI, an American corporation. This company defines what are acceptable answers and what knowledge is worth including in the language model. As of this writing, OpenAI refuses to release information on the data used to train ChatGPT. Artificial intelligence models are notoriously known to be biased. The quality of the answers heavily depends on the quality of the input (prompts) that are entered into the chatbot. ChatGPT & scientific literature search Before rushing to ChatGPT, always ask yourself if this is the most appropriate tool for your task. Well discuss the use of ChatGPT in the different phases of searching for literature.Orientating on a topicChatGPT is not able to help you define your information need. ChatGPT has only been trained on data until . It does not have any information on the most recent research output. However, you can use the discussion tool to get some inspiration when formulating your research question. Be aware that ChatGPT is not trained to formulate search questions for searching scientific articles in bibliographic databases. Youll need to edit and reformulate the answers it gives. You also need to be wary of any biases that ChatGPT might incorporate into your discussion. Preparing your searchChatGPT can help you identify appropriate aids or databases to a certain degree. Be aware that it doesnt always provide complete or exhaustive overviews of available domain-specific resources. Moreover, it cant tell you if the library subscribes to a specific database. For a complete overview of multi-discipline, discipline-specific databases, resources and subscription information, please use the WUR Library Databases & Collections tool. ChatGPT is great to help you find good search terms for your search query. Do not hesitate to push ChatGPT to add more terms than the ones in its initial answer. This does not replace the need to consult additional sources, such as a synonyms dictionary or a thesaurus, or to check the jargon used by authors in your field. Performing your searchChatGPT cannot help you at this stage. ChatGPT is unable to determine the best search strategy for your information need. Whats more, it cant search for information systematically and transparently, nor is it good at building search queries. ChatGPT may provide you with some information on how a database works. However, we advise you to always directly check the help menu of your chosen bibliographic database. Functionalities may have changed since , and the ChatGPT answer may well be outdated. Evaluating the results you foundYou cant use ChatGPT to evaluate your search results. Evaluating information is a human skill based on obvious and latent criteria that you deem relevant. As a researcher or student, you must decide whether a source is relevant to your work. You can, however, currently use ChatGPT to clarify difficult texts since it is good at summarizing or reformulating a text.Citing and referencingChatGPT cannot or will not provide sources for the texts it writes. Moreover, something odd happens when you ask ChatGPT to provide a bibliography on a specific topic. It will come up with a list of sources that initially seems accurate. However, upon closer look, these sources are often fake and totally made up. Moreover, ChatGPT is unable to create reference lists following specific guidelines. Reference management software, such as EndNote or Mendeley, support countless reference styles and are a much better choice.Writing and communicatingThe use of ChatGPT to write scientific articles is problematic. An increasing number of publishers explicitly forbid its use as a writing assistant. For a comprehensive discussion, see this article. Should I cite and refer to ChatGPT?Yes, if you've used ChatGPT in your work, you should explicitly mention any use of it. There is currently an ongoing discussion on how this is best done. Reference style guidelines have not yet been updated.We advise you to cite and refer to ChatGPT as a personal communication or as a computer program. In any case, you need to explicitly inform the reader about your use of ChatGPT, for example, in your materials and methods, including the prompt you used. If the publication allows i\"],\n",
       " [\"It is important to keep the following general shortcomings in mind:ChatGPT is not a search engine. It has been trained with a large amount of information, but the chatbot doesnt understand the meaning of the information itself.ChatGPT is developed and distributed by OpenAI, an American corporation. This company defines what are acceptable answers and what knowledge is worth including in the language model. As of this writing, OpenAI refuses to release information on the data used to train ChatGPT. Artificial intelligence models are notoriously known to be biased. The quality of the answers heavily depends on the quality of the input (prompts) that are entered into the chatbot. ChatGPT & scientific literature search Before rushing to ChatGPT, always ask yourself if this is the most appropriate tool for your task. Well discuss the use of ChatGPT in the different phases of searching for literature.Orientating on a topicChatGPT is not able to help you define your information need. ChatGPT has only been trained on data until . It does not have any information on the most recent research output. However, you can use the discussion tool to get some inspiration when formulating your research question. Be aware that ChatGPT is not trained to formulate search questions for searching scientific articles in bibliographic databases. Youll need to edit and reformulate the answers it gives. You also need to be wary of any biases that ChatGPT might incorporate into your discussion. Preparing your searchChatGPT can help you identify appropriate aids or databases to a certain degree. Be aware that it doesnt always provide complete or exhaustive overviews of available domain-specific resources. Moreover, it cant tell you if the library subscribes to a specific database. For a complete overview of multi-discipline, discipline-specific databases, resources and subscription information, please use the WUR Library Databases & Collections tool. ChatGPT is great to help you find good search terms for your search query. Do not hesitate to push ChatGPT to add more terms than the ones in its initial answer. This does not replace the need to consult additional sources, such as a synonyms dictionary or a thesaurus, or to check the jargon used by authors in your field. Performing your searchChatGPT cannot help you at this stage. ChatGPT is unable to determine the best search strategy for your information need. Whats more, it cant search for information systematically and transparently, nor is it good at building search queries. ChatGPT may provide you with some information on how a database works. However, we advise you to always directly check the help menu of your chosen bibliographic database. Functionalities may have changed since , and the ChatGPT answer may well be outdated. Evaluating the results you foundYou cant use ChatGPT to evaluate your search results. Evaluating information is a human skill based on obvious and latent criteria that you deem relevant. As a researcher or student, you must decide whether a source is relevant to your work. You can, however, currently use ChatGPT to clarify difficult texts since it is good at summarizing or reformulating a text.Citing and referencingChatGPT cannot or will not provide sources for the texts it writes. Moreover, something odd happens when you ask ChatGPT to provide a bibliography on a specific topic. It will come up with a list of sources that initially seems accurate. However, upon closer look, these sources are often fake and totally made up. Moreover, ChatGPT is unable to create reference lists following specific guidelines. Reference management software, such as EndNote or Mendeley, support countless reference styles and are a much better choice.Writing and communicatingThe use of ChatGPT to write scientific articles is problematic. An increasing number of publishers explicitly forbid its use as a writing assistant. For a comprehensive discussion, see this article. Should I cite and refer to ChatGPT?Yes, if you've used ChatGPT in your work, you should explicitly mention any use of it. There is currently an ongoing discussion on how this is best done. Reference style guidelines have not yet been updated.We advise you to cite and refer to ChatGPT as a personal communication or as a computer program. In any case, you need to explicitly inform the reader about your use of ChatGPT, for example, in your materials and methods, including the prompt you used. If the publication allows it, you can also include your chat as an appendix. SourcesChatGPT. (2023, March ). In Wikipedia. R. B., Teeple, S., & Navathe, A. S. (2019). Addressing bias in artificial intelligence in health care. Jama,322(24), -2378. Roselli, D., Matthews, J., & Talagala, N. (2019, May). Managing bias in AI. In Companion Proceedings of The World Wide Web Conference (pp. -544).\"],\n",
       " [\"Before rushing to ChatGPT, always ask yourself if this is the most appropriate tool for your task. Well discuss the use of ChatGPT in the different phases of searching for literature.Orientating on a topicChatGPT is not able to help you define your information need. ChatGPT has only been trained on data until . It does not have any information on the most recent research output. However, you can use the discussion tool to get some inspiration when formulating your research question. Be aware that ChatGPT is not trained to formulate search questions for searching scientific articles in bibliographic databases. Youll need to edit and reformulate the answers it gives. You also need to be wary of any biases that ChatGPT might incorporate into your discussion. Preparing your searchChatGPT can help you identify appropriate aids or databases to a certain degree. Be aware that it doesnt always provide complete or exhaustive overviews of available domain-specific resources. Moreover, it cant tell you if the library subscribes to a specific database. For a complete overview of multi-discipline, discipline-specific databases, resources and subscription information, please use the WUR Library Databases & Collections tool. ChatGPT is great to help you find good search terms for your search query. Do not hesitate to push ChatGPT to add more terms than the ones in its initial answer. This does not replace the need to consult additional sources, such as a synonyms dictionary or a thesaurus, or to check the jargon used by authors in your field. Performing your searchChatGPT cannot help you at this stage. ChatGPT is unable to determine the best search strategy for your information need. Whats more, it cant search for information systematically and transparently, nor is it good at building search queries. ChatGPT may provide you with some information on how a database works. However, we advise you to always directly check the help menu of your chosen bibliographic database. Functionalities may have changed since , and the ChatGPT answer may well be outdated. Evaluating the results you foundYou cant use ChatGPT to evaluate your search results. Evaluating information is a human skill based on obvious and latent criteria that you deem relevant. As a researcher or student, you must decide whether a source is relevant to your work. You can, however, currently use ChatGPT to clarify difficult texts since it is good at summarizing or reformulating a text.Citing and referencingChatGPT cannot or will not provide sources for the texts it writes. Moreover, something odd happens when you ask ChatGPT to provide a bibliography on a specific topic. It will come up with a list of sources that initially seems accurate. However, upon closer look, these sources are often fake and totally made up. Moreover, ChatGPT is unable to create reference lists following specific guidelines. Reference management software, such as EndNote or Mendeley, support countless reference styles and are a much better choice.Writing and communicatingThe use of ChatGPT to write scientific articles is problematic. An increasing number of publishers explicitly forbid its use as a writing assistant. For a comprehensive discussion, see this article. Should I cite and refer to ChatGPT?Yes, if you've used ChatGPT in your work, you should explicitly mention any use of it. There is currently an ongoing discussion on how this is best done. Reference style guidelines have not yet been updated.We advise you to cite and refer to ChatGPT as a personal communication or as a computer program. In any case, you need to explicitly inform the reader about your use of ChatGPT, for example, in your materials and methods, including the prompt you used. If the publication allows it, you can also include your chat as an appendix. SourcesChatGPT. (2023, March ). In Wikipedia. R. B., Teeple, S., & Navathe, A. S. (2019). Addressing bias in artificial intelligence in health care. Jama,322(24), -2378. Roselli, D., Matthews, J., & Talagala, N. (2019, May). Managing bias in AI. In Companion Proceedings of The World Wide Web Conference (pp. -544). post The APA-Team - Chat GPT Blog post Han_ ChatGPT & de docentenpraktijk Workshop SHB ChatGPT and information literacy\"],\n",
       " [\"ChatGPT is not able to help you define your information need. ChatGPT has only been trained on data until . It does not have any information on the most recent research output. However, you can use the discussion tool to get some inspiration when formulating your research question. Be aware that ChatGPT is not trained to formulate search questions for searching scientific articles in bibliographic databases. Youll need to edit and reformulate the answers it gives. You also need to be wary of any biases that ChatGPT might incorporate into your discussion. Preparing your searchChatGPT can help you identify appropriate aids or databases to a certain degree. Be aware that it doesnt always provide complete or exhaustive overviews of available domain-specific resources. Moreover, it cant tell you if the library subscribes to a specific database. For a complete overview of multi-discipline, discipline-specific databases, resources and subscription information, please use the WUR Library Databases & Collections tool. ChatGPT is great to help you find good search terms for your search query. Do not hesitate to push ChatGPT to add more terms than the ones in its initial answer. This does not replace the need to consult additional sources, such as a synonyms dictionary or a thesaurus, or to check the jargon used by authors in your field. Performing your searchChatGPT cannot help you at this stage. ChatGPT is unable to determine the best search strategy for your information need. Whats more, it cant search for information systematically and transparently, nor is it good at building search queries. ChatGPT may provide you with some information on how a database works. However, we advise you to always directly check the help menu of your chosen bibliographic database. Functionalities may have changed since , and the ChatGPT answer may well be outdated. Evaluating the results you foundYou cant use ChatGPT to evaluate your search results. Evaluating information is a human skill based on obvious and latent criteria that you deem relevant. As a researcher or student, you must decide whether a source is relevant to your work. You can, however, currently use ChatGPT to clarify difficult texts since it is good at summarizing or reformulating a text.Citing and referencingChatGPT cannot or will not provide sources for the texts it writes. Moreover, something odd happens when you ask ChatGPT to provide a bibliography on a specific topic. It will come up with a list of sources that initially seems accurate. However, upon closer look, these sources are often fake and totally made up. Moreover, ChatGPT is unable to create reference lists following specific guidelines. Reference management software, such as EndNote or Mendeley, support countless reference styles and are a much better choice.Writing and communicatingThe use of ChatGPT to write scientific articles is problematic. An increasing number of publishers explicitly forbid its use as a writing assistant. For a comprehensive discussion, see this article. Should I cite and refer to ChatGPT?Yes, if you've used ChatGPT in your work, you should explicitly mention any use of it. There is currently an ongoing discussion on how this is best done. Reference style guidelines have not yet been updated.We advise you to cite and refer to ChatGPT as a personal communication or as a computer program. In any case, you need to explicitly inform the reader about your use of ChatGPT, for example, in your materials and methods, including the prompt you used. If the publication allows it, you can also include your chat as an appendix. SourcesChatGPT. (2023, March ). In Wikipedia. R. B., Teeple, S., & Navathe, A. S. (2019). Addressing bias in artificial intelligence in health care. Jama,322(24), -2378. Roselli, D., Matthews, J., & Talagala, N. (2019, May). Managing bias in AI. In Companion Proceedings of The World Wide Web Conference (pp. -544). post The APA-Team - Chat GPT Blog post Han_ ChatGPT & de docentenpraktijk Workshop SHB ChatGPT and information literacy\"],\n",
       " [\"ChatGPT can help you identify appropriate aids or databases to a certain degree. Be aware that it doesnt always provide complete or exhaustive overviews of available domain-specific resources. Moreover, it cant tell you if the library subscribes to a specific database. For a complete overview of multi-discipline, discipline-specific databases, resources and subscription information, please use the WUR Library Databases & Collections tool. ChatGPT is great to help you find good search terms for your search query. Do not hesitate to push ChatGPT to add more terms than the ones in its initial answer. This does not replace the need to consult additional sources, such as a synonyms dictionary or a thesaurus, or to check the jargon used by authors in your field. Performing your searchChatGPT cannot help you at this stage. ChatGPT is unable to determine the best search strategy for your information need. Whats more, it cant search for information systematically and transparently, nor is it good at building search queries. ChatGPT may provide you with some information on how a database works. However, we advise you to always directly check the help menu of your chosen bibliographic database. Functionalities may have changed since , and the ChatGPT answer may well be outdated. Evaluating the results you foundYou cant use ChatGPT to evaluate your search results. Evaluating information is a human skill based on obvious and latent criteria that you deem relevant. As a researcher or student, you must decide whether a source is relevant to your work. You can, however, currently use ChatGPT to clarify difficult texts since it is good at summarizing or reformulating a text.Citing and referencingChatGPT cannot or will not provide sources for the texts it writes. Moreover, something odd happens when you ask ChatGPT to provide a bibliography on a specific topic. It will come up with a list of sources that initially seems accurate. However, upon closer look, these sources are often fake and totally made up. Moreover, ChatGPT is unable to create reference lists following specific guidelines. Reference management software, such as EndNote or Mendeley, support countless reference styles and are a much better choice.Writing and communicatingThe use of ChatGPT to write scientific articles is problematic. An increasing number of publishers explicitly forbid its use as a writing assistant. For a comprehensive discussion, see this article. Should I cite and refer to ChatGPT?Yes, if you've used ChatGPT in your work, you should explicitly mention any use of it. There is currently an ongoing discussion on how this is best done. Reference style guidelines have not yet been updated.We advise you to cite and refer to ChatGPT as a personal communication or as a computer program. In any case, you need to explicitly inform the reader about your use of ChatGPT, for example, in your materials and methods, including the prompt you used. If the publication allows it, you can also include your chat as an appendix. SourcesChatGPT. (2023, March ). In Wikipedia. R. B., Teeple, S., & Navathe, A. S. (2019). Addressing bias in artificial intelligence in health care. Jama,322(24), -2378. Roselli, D., Matthews, J., & Talagala, N. (2019, May). Managing bias in AI. In Companion Proceedings of The World Wide Web Conference (pp. -544). post The APA-Team - Chat GPT Blog post Han_ ChatGPT & de docentenpraktijk Workshop SHB ChatGPT and information literacy\"],\n",
       " [\"ChatGPT is great to help you find good search terms for your search query. Do not hesitate to push ChatGPT to add more terms than the ones in its initial answer. This does not replace the need to consult additional sources, such as a synonyms dictionary or a thesaurus, or to check the jargon used by authors in your field. Performing your searchChatGPT cannot help you at this stage. ChatGPT is unable to determine the best search strategy for your information need. Whats more, it cant search for information systematically and transparently, nor is it good at building search queries. ChatGPT may provide you with some information on how a database works. However, we advise you to always directly check the help menu of your chosen bibliographic database. Functionalities may have changed since , and the ChatGPT answer may well be outdated. Evaluating the results you foundYou cant use ChatGPT to evaluate your search results. Evaluating information is a human skill based on obvious and latent criteria that you deem relevant. As a researcher or student, you must decide whether a source is relevant to your work. You can, however, currently use ChatGPT to clarify difficult texts since it is good at summarizing or reformulating a text.Citing and referencingChatGPT cannot or will not provide sources for the texts it writes. Moreover, something odd happens when you ask ChatGPT to provide a bibliography on a specific topic. It will come up with a list of sources that initially seems accurate. However, upon closer look, these sources are often fake and totally made up. Moreover, ChatGPT is unable to create reference lists following specific guidelines. Reference management software, such as EndNote or Mendeley, support countless reference styles and are a much better choice.Writing and communicatingThe use of ChatGPT to write scientific articles is problematic. An increasing number of publishers explicitly forbid its use as a writing assistant. For a comprehensive discussion, see this article. Should I cite and refer to ChatGPT?Yes, if you've used ChatGPT in your work, you should explicitly mention any use of it. There is currently an ongoing discussion on how this is best done. Reference style guidelines have not yet been updated.We advise you to cite and refer to ChatGPT as a personal communication or as a computer program. In any case, you need to explicitly inform the reader about your use of ChatGPT, for example, in your materials and methods, including the prompt you used. If the publication allows it, you can also include your chat as an appendix. SourcesChatGPT. (2023, March ). In Wikipedia. R. B., Teeple, S., & Navathe, A. S. (2019). Addressing bias in artificial intelligence in health care. Jama,322(24), -2378. Roselli, D., Matthews, J., & Talagala, N. (2019, May). Managing bias in AI. In Companion Proceedings of The World Wide Web Conference (pp. -544). post The APA-Team - Chat GPT Blog post Han_ ChatGPT & de docentenpraktijk Workshop SHB ChatGPT and information literacy\"],\n",
       " [\"ChatGPT cannot help you at this stage. ChatGPT is unable to determine the best search strategy for your information need. Whats more, it cant search for information systematically and transparently, nor is it good at building search queries. ChatGPT may provide you with some information on how a database works. However, we advise you to always directly check the help menu of your chosen bibliographic database. Functionalities may have changed since , and the ChatGPT answer may well be outdated. Evaluating the results you foundYou cant use ChatGPT to evaluate your search results. Evaluating information is a human skill based on obvious and latent criteria that you deem relevant. As a researcher or student, you must decide whether a source is relevant to your work. You can, however, currently use ChatGPT to clarify difficult texts since it is good at summarizing or reformulating a text.Citing and referencingChatGPT cannot or will not provide sources for the texts it writes. Moreover, something odd happens when you ask ChatGPT to provide a bibliography on a specific topic. It will come up with a list of sources that initially seems accurate. However, upon closer look, these sources are often fake and totally made up. Moreover, ChatGPT is unable to create reference lists following specific guidelines. Reference management software, such as EndNote or Mendeley, support countless reference styles and are a much better choice.Writing and communicatingThe use of ChatGPT to write scientific articles is problematic. An increasing number of publishers explicitly forbid its use as a writing assistant. For a comprehensive discussion, see this article. Should I cite and refer to ChatGPT?Yes, if you've used ChatGPT in your work, you should explicitly mention any use of it. There is currently an ongoing discussion on how this is best done. Reference style guidelines have not yet been updated.We advise you to cite and refer to ChatGPT as a personal communication or as a computer program. In any case, you need to explicitly inform the reader about your use of ChatGPT, for example, in your materials and methods, including the prompt you used. If the publication allows it, you can also include your chat as an appendix. SourcesChatGPT. (2023, March ). In Wikipedia. R. B., Teeple, S., & Navathe, A. S. (2019). Addressing bias in artificial intelligence in health care. Jama,322(24), -2378. Roselli, D., Matthews, J., & Talagala, N. (2019, May). Managing bias in AI. In Companion Proceedings of The World Wide Web Conference (pp. -544). post The APA-Team - Chat GPT Blog post Han_ ChatGPT & de docentenpraktijk Workshop SHB ChatGPT and information literacy\"],\n",
       " [\"ChatGPT may provide you with some information on how a database works. However, we advise you to always directly check the help menu of your chosen bibliographic database. Functionalities may have changed since , and the ChatGPT answer may well be outdated. Evaluating the results you foundYou cant use ChatGPT to evaluate your search results. Evaluating information is a human skill based on obvious and latent criteria that you deem relevant. As a researcher or student, you must decide whether a source is relevant to your work. You can, however, currently use ChatGPT to clarify difficult texts since it is good at summarizing or reformulating a text.Citing and referencingChatGPT cannot or will not provide sources for the texts it writes. Moreover, something odd happens when you ask ChatGPT to provide a bibliography on a specific topic. It will come up with a list of sources that initially seems accurate. However, upon closer look, these sources are often fake and totally made up. Moreover, ChatGPT is unable to create reference lists following specific guidelines. Reference management software, such as EndNote or Mendeley, support countless reference styles and are a much better choice.Writing and communicatingThe use of ChatGPT to write scientific articles is problematic. An increasing number of publishers explicitly forbid its use as a writing assistant. For a comprehensive discussion, see this article. Should I cite and refer to ChatGPT?Yes, if you've used ChatGPT in your work, you should explicitly mention any use of it. There is currently an ongoing discussion on how this is best done. Reference style guidelines have not yet been updated.We advise you to cite and refer to ChatGPT as a personal communication or as a computer program. In any case, you need to explicitly inform the reader about your use of ChatGPT, for example, in your materials and methods, including the prompt you used. If the publication allows it, you can also include your chat as an appendix. SourcesChatGPT. (2023, March ). In Wikipedia. R. B., Teeple, S., & Navathe, A. S. (2019). Addressing bias in artificial intelligence in health care. Jama,322(24), -2378. Roselli, D., Matthews, J., & Talagala, N. (2019, May). Managing bias in AI. In Companion Proceedings of The World Wide Web Conference (pp. -544). post The APA-Team - Chat GPT Blog post Han_ ChatGPT & de docentenpraktijk Workshop SHB ChatGPT and information literacy\"],\n",
       " [\"You cant use ChatGPT to evaluate your search results. Evaluating information is a human skill based on obvious and latent criteria that you deem relevant. As a researcher or student, you must decide whether a source is relevant to your work. You can, however, currently use ChatGPT to clarify difficult texts since it is good at summarizing or reformulating a text.Citing and referencingChatGPT cannot or will not provide sources for the texts it writes. Moreover, something odd happens when you ask ChatGPT to provide a bibliography on a specific topic. It will come up with a list of sources that initially seems accurate. However, upon closer look, these sources are often fake and totally made up. Moreover, ChatGPT is unable to create reference lists following specific guidelines. Reference management software, such as EndNote or Mendeley, support countless reference styles and are a much better choice.Writing and communicatingThe use of ChatGPT to write scientific articles is problematic. An increasing number of publishers explicitly forbid its use as a writing assistant. For a comprehensive discussion, see this article. Should I cite and refer to ChatGPT?Yes, if you've used ChatGPT in your work, you should explicitly mention any use of it. There is currently an ongoing discussion on how this is best done. Reference style guidelines have not yet been updated.We advise you to cite and refer to ChatGPT as a personal communication or as a computer program. In any case, you need to explicitly inform the reader about your use of ChatGPT, for example, in your materials and methods, including the prompt you used. If the publication allows it, you can also include your chat as an appendix. SourcesChatGPT. (2023, March ). In Wikipedia. R. B., Teeple, S., & Navathe, A. S. (2019). Addressing bias in artificial intelligence in health care. Jama,322(24), -2378. Roselli, D., Matthews, J., & Talagala, N. (2019, May). Managing bias in AI. In Companion Proceedings of The World Wide Web Conference (pp. -544). post The APA-Team - Chat GPT Blog post Han_ ChatGPT & de docentenpraktijk Workshop SHB ChatGPT and information literacy\"],\n",
       " [\"You can, however, currently use ChatGPT to clarify difficult texts since it is good at summarizing or reformulating a text.Citing and referencingChatGPT cannot or will not provide sources for the texts it writes. Moreover, something odd happens when you ask ChatGPT to provide a bibliography on a specific topic. It will come up with a list of sources that initially seems accurate. However, upon closer look, these sources are often fake and totally made up. Moreover, ChatGPT is unable to create reference lists following specific guidelines. Reference management software, such as EndNote or Mendeley, support countless reference styles and are a much better choice.Writing and communicatingThe use of ChatGPT to write scientific articles is problematic. An increasing number of publishers explicitly forbid its use as a writing assistant. For a comprehensive discussion, see this article. Should I cite and refer to ChatGPT?Yes, if you've used ChatGPT in your work, you should explicitly mention any use of it. There is currently an ongoing discussion on how this is best done. Reference style guidelines have not yet been updated.We advise you to cite and refer to ChatGPT as a personal communication or as a computer program. In any case, you need to explicitly inform the reader about your use of ChatGPT, for example, in your materials and methods, including the prompt you used. If the publication allows it, you can also include your chat as an appendix. SourcesChatGPT. (2023, March ). In Wikipedia. R. B., Teeple, S., & Navathe, A. S. (2019). Addressing bias in artificial intelligence in health care. Jama,322(24), -2378. Roselli, D., Matthews, J., & Talagala, N. (2019, May). Managing bias in AI. In Companion Proceedings of The World Wide Web Conference (pp. -544). post The APA-Team - Chat GPT Blog post Han_ ChatGPT & de docentenpraktijk Workshop SHB ChatGPT and information literacy\"],\n",
       " [\"ChatGPT cannot or will not provide sources for the texts it writes. Moreover, something odd happens when you ask ChatGPT to provide a bibliography on a specific topic. It will come up with a list of sources that initially seems accurate. However, upon closer look, these sources are often fake and totally made up. Moreover, ChatGPT is unable to create reference lists following specific guidelines. Reference management software, such as EndNote or Mendeley, support countless reference styles and are a much better choice.Writing and communicatingThe use of ChatGPT to write scientific articles is problematic. An increasing number of publishers explicitly forbid its use as a writing assistant. For a comprehensive discussion, see this article. Should I cite and refer to ChatGPT?Yes, if you've used ChatGPT in your work, you should explicitly mention any use of it. There is currently an ongoing discussion on how this is best done. Reference style guidelines have not yet been updated.We advise you to cite and refer to ChatGPT as a personal communication or as a computer program. In any case, you need to explicitly inform the reader about your use of ChatGPT, for example, in your materials and methods, including the prompt you used. If the publication allows it, you can also include your chat as an appendix. SourcesChatGPT. (2023, March ). In Wikipedia. R. B., Teeple, S., & Navathe, A. S. (2019). Addressing bias in artificial intelligence in health care. Jama,322(24), -2378. Roselli, D., Matthews, J., & Talagala, N. (2019, May). Managing bias in AI. In Companion Proceedings of The World Wide Web Conference (pp. -544). post The APA-Team - Chat GPT Blog post Han_ ChatGPT & de docentenpraktijk Workshop SHB ChatGPT and information literacy\"],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['You are invited to the EEMCS Educational Seminar on Artificial Intelligence Since the release of ChatGPT in November , tech companies have been locked in a highspeed race to claim a share on the Artificial Intelligence market. Each development follows quicker than the last, leaving us to hasten to catch up. But what effects does AI have on education and our teaching? Join us and our three speakers in an interesting seminar about the effect that Artificial Intelligence has on education. The seminar will be a Panel Discussion with a short presentation beforehand about the developments of AI in education. So, feel free to voice your opinions, worries and ideas during the discussion or just sit back and listen. SpeakersThe panel discussion will be moderated by Cora Salm, Educational Programme Director of Electrical Engineering. We have invited three individuals who each have their own experiences with Artificial Intelligence, namely: R.H.M. van Emmerloot BSc (Robin) Educational consultant TELT+31534898922 r.h.m.vanemmerloot.nlBuilding: Citadel H325Personal pageL. Spek MSc (Len) PostDoc MIA department+31534897069 l.spek.nlBuilding: Zilverling Building: Zilverling Personal pageM. A. Gmez Maureira (Maro) Assistant Professor HMI Department+31534891950 m.a.gomezmaureira.nlPersonal pageRegister now!You can attend the seminar in person or watch it online with a livestream. Please note that there is no opportunity for interaction via the livestream. You will receive the link to the livestream no later than June. Lunch will be provided during the seminar.You can easily register via an online form.Register now!We hope to see you there! Kind regards, The UTeachers Academy and edusupport team'],\n",
       " ['Since the release of ChatGPT in November , tech companies have been locked in a highspeed race to claim a share on the Artificial Intelligence market. Each development follows quicker than the last, leaving us to hasten to catch up. But what effects does AI have on education and our teaching? Join us and our three speakers in an interesting seminar about the effect that Artificial Intelligence has on education. The seminar will be a Panel Discussion with a short presentation beforehand about the developments of AI in education. So, feel free to voice your opinions, worries and ideas during the discussion or just sit back and listen. SpeakersThe panel discussion will be moderated by Cora Salm, Educational Programme Director of Electrical Engineering. We have invited three individuals who each have their own experiences with Artificial Intelligence, namely: R.H.M. van Emmerloot BSc (Robin) Educational consultant TELT+31534898922 r.h.m.vanemmerloot.nlBuilding: Citadel H325Personal pageL. Spek MSc (Len) PostDoc MIA department+31534897069 l.spek.nlBuilding: Zilverling Building: Zilverling Personal pageM. A. Gmez Maureira (Maro) Assistant Professor HMI Department+31534891950 m.a.gomezmaureira.nlPersonal pageRegister now!You can attend the seminar in person or watch it online with a livestream. Please note that there is no opportunity for interaction via the livestream. You will receive the link to the livestream no later than June. Lunch will be provided during the seminar.You can easily register via an online form.Register now!We hope to see you there! Kind regards, The UTeachers Academy and edusupport team'],\n",
       " ['Join us and our three speakers in an interesting seminar about the effect that Artificial Intelligence has on education. The seminar will be a Panel Discussion with a short presentation beforehand about the developments of AI in education. So, feel free to voice your opinions, worries and ideas during the discussion or just sit back and listen. SpeakersThe panel discussion will be moderated by Cora Salm, Educational Programme Director of Electrical Engineering. We have invited three individuals who each have their own experiences with Artificial Intelligence, namely: R.H.M. van Emmerloot BSc (Robin) Educational consultant TELT+31534898922 r.h.m.vanemmerloot.nlBuilding: Citadel H325Personal pageL. Spek MSc (Len) PostDoc MIA department+31534897069 l.spek.nlBuilding: Zilverling Building: Zilverling Personal pageM. A. Gmez Maureira (Maro) Assistant Professor HMI Department+31534891950 m.a.gomezmaureira.nlPersonal pageRegister now!You can attend the seminar in person or watch it online with a livestream. Please note that there is no opportunity for interaction via the livestream. You will receive the link to the livestream no later than June. Lunch will be provided during the seminar.You can easily register via an online form.Register now!We hope to see you there! Kind regards, The UTeachers Academy and edusupport team'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [\"he University of Twente's perspective is that this technology will only grow further and have more impact. While measures like detection are possible, they will not be the answer to the change in education.We must embrace AI technology carefully and strengthen the human factor in education to adapt and deal with the technology responsibly and ethically.Executive Board UTExamination boards have also formulated their recommendations and stance on the use of generative AI.AssessmentAre my assessment methods still reliable? you might ask yourself. Generally speaking, fraudulent use of AI can be done when no supervision is involved. Of course, students are able to prepare for a supervised assessment while using AI themselves. To help you see the potential risk in your type of assessment, this graph was drafted by the Centre of Expertise in Learning & Teaching.When you want to ensure the reliability and authenticity of your assessment, there are some general guidelines to keep in mind.Mix several types of assessment, especially when you are using unsupervised assessment now.Try out your current assessment in one of the generative AI tools to assess the output quality.Explicitly state your position in assessment, in relation to the usage of AI in education towards your students.Detecting ChatGPT If you specifically want to avoid whether work is (partially) done by ChatGPT , here are a couple of tips.Text generated by ChatGPT can be overly correct in grammar.Faults or missing information in references and sourcesTo prevent this, you can focus on incorporating relevant sources (since ) and own experiences/examplesFinally, Turnitin has released an update to detect ChatGPT written text as well. The UTs license is temporary, and the false positives and negatives are high, but they can give an indication of potential misconduct.As this topic is highly dynamic, some of the provided advice and guidelines might be overruled by new technological developments.\"],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [\"We know that keeping up with new technology can be tricky, but this session will be easy to follow and full of good tips and practices. You'll know how to deal with fraud and ensure academic integrity with the current advancements of ChatGPT. All this while having a good discussion with your fellow teachers! What? The session will be packed with current information, good practices, and tips on preventing fraud with ChatGPT. We will have multiple speakers (teachers and support staff) during the session. When? June th , from :30 to :15 Where? On campus - RA3237Online - MS TeamsJoin us for an educational and interactive session that will cover the best practices to ensure academic integrity at BMS/UT. Add this event to your calendar\"],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Before generating a story, the chatbot will ask a couple of questions. The awnsers of which will be incorperated in the story. Each question contains a parameter and a list of sentences.'],\n",
       " ['he chatbot features a blacklist in the configuration.json. This is a list of all the topics the chatbot should not talk about. The user can add words or whole sentances to the list that should not be named in the stories. When the chatbot encounters one of the blacklisted items, it will stop generating the story and instead send one of the error sentances.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Marinelli, Giorgia (2021) Implementation of chatbots for the job selection : advantages and disadvantages. PDF MBAbstract:Currently, in a highly competitive global market where the war for talent takes place, companies are always more looking for new and innovative solutions that strengthen their selection processes. This research wants to investigate and explore where it is more profitable designing and inserting chatbots considering the different stages of the selection process, focusing attention on chatbots advantages and disadvantages of its implementation. A qualitative research method was adopted, in order to identify and understand in which stages of the selection process chatbots are most suitable to be implemented. A certain number of interviews with multiple HR professionals from different companies were conducted and then codified through the software program ATLAS.ti. Interesting results emerged, given that none of these companies adopts AI tools. Indeed, each HR professional described the proper selection process of the company, hypothesizing the implementation of a chatbot throughout it, coming to different conclusions. Since the answer to the research question is not so obvious and predictable, the successful implementation of a new technology needs to be properly accepted by those who will get in touch with it, showing a positive attitude. In other words, it is not just a question of understanding in which stages of the selection process chatbots are most suitable to implement, but also whether the company feels ready for the change it will bring.Item Type:Essay (Master)Faculty:BMS: Behavioural, Management and Social SciencesSubject:85 business administration, organizational scienceProgramme:Business Administration MSc (60644)Link to this item: this item as:BibTeXEndNoteHTML CitationReference Manager Show download statistics for this publication Repository Staff Only: item control page'],\n",
       " ['PDF MBAbstract:Currently, in a highly competitive global market where the war for talent takes place, companies are always more looking for new and innovative solutions that strengthen their selection processes. This research wants to investigate and explore where it is more profitable designing and inserting chatbots considering the different stages of the selection process, focusing attention on chatbots advantages and disadvantages of its implementation. A qualitative research method was adopted, in order to identify and understand in which stages of the selection process chatbots are most suitable to be implemented. A certain number of interviews with multiple HR professionals from different companies were conducted and then codified through the software program ATLAS.ti. Interesting results emerged, given that none of these companies adopts AI tools. Indeed, each HR professional described the proper selection process of the company, hypothesizing the implementation of a chatbot throughout it, coming to different conclusions. Since the answer to the research question is not so obvious and predictable, the successful implementation of a new technology needs to be properly accepted by those who will get in touch with it, showing a positive attitude. In other words, it is not just a question of understanding in which stages of the selection process chatbots are most suitable to implement, but also whether the company feels ready for the change it will bring.Item Type:Essay (Master)Faculty:BMS: Behavioural, Management and Social SciencesSubject:85 business administration, organizational scienceProgramme:Business Administration MSc (60644)Link to this item: this item as:BibTeXEndNoteHTML CitationReference Manager Show download statistics for this publication Repository Staff Only: item control page'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [\"Now that ChatGPT is on the tips of everybody's tongues, many of you must be wondering how it works and its use at UT and education in general. The upcoming Chat GPT workshop this Tuesday at by Robin Van Emmerloot will answer all of your questions.\"],\n",
       " [],\n",
       " [],\n",
       " [\"Fischer, Simon (2022) The Indeterminate Self and Large Language Models : A Nietzschean Critique of GPT-3. PDF kBAbstract:Nietzsche's will to power ontology conceives of the self as having no pre-established essence. Instead, the self is a priori undefined and its development remains unfinished and unknown. The self is thus inherently indeterminate and always in a state of becoming. In this, it is formed through interaction. Becoming is not an autonomous process, however, as the self is always constrained to some degree by the social context in which it is embedded. Accordingly, I will address the question of how the interaction with synthetic texts generated by GPT-3 debilitates self-formation.Item Type:Essay (Master)Faculty:BMS: Behavioural, Management and Social SciencesSubject:02 science and culture in general, philosophyProgrammehilosophy of Science, Technology and Society MSc (60024)Link to this item: this item as:BibTeXEndNoteHTML CitationReference Manager Show download statistics for this publication Repository Staff Only: item control page\"],\n",
       " [\"PDF kBAbstract:Nietzsche's will to power ontology conceives of the self as having no pre-established essence. Instead, the self is a priori undefined and its development remains unfinished and unknown. The self is thus inherently indeterminate and always in a state of becoming. In this, it is formed through interaction. Becoming is not an autonomous process, however, as the self is always constrained to some degree by the social context in which it is embedded. Accordingly, I will address the question of how the interaction with synthetic texts generated by GPT-3 debilitates self-formation.Item Type:Essay (Master)Faculty:BMS: Behavioural, Management and Social SciencesSubject:02 science and culture in general, philosophyProgrammehilosophy of Science, Technology and Society MSc (60024)Link to this item: this item as:BibTeXEndNoteHTML CitationReference Manager Show download statistics for this publication Repository Staff Only: item control page\"],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['The last thing I would like to mention is monitoring and enforcement, Van Dijck continues. You can develop technical tools, and watermark information, for example, so you know where it comes from, but you will always lag behind the technology you want to control. Monitoring and enforcement is something quite different. AI tools are available and new tools will come to market, but as long as you cannot access their training models, monitoring is basically impossible.In the end, it comes down to transparency and manpower, Van Dijck concludes. You have to enforce continuous access to constantly monitor and assess the underlying language models of AI tools. And right now, only a few people have the knowledge to do this monitoring, so investing in new experts is incredibly important. Queeny Rajkowski organiseert AI-college voor medekamerleden, Goed Ingelichte Kring (8 April ) De Tweede Kamer werd woensdag bijgepraat door experts over ChatGPT. Het is net magie, NRC (19 April ) Item about artificial intelligence, Even Tot Hier (22 April , starting at19:55)'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['It is now common knowledge that ChatGPT is capable of generating accurate texts based on a question ( prompt). Currently, we are surveying university-wide what the possibilities and risks are.The following is already clear: if a student uses an AI tool (such as ChatGPT or a similar tool) to generate texts and then presents these as his/her own work for an assessment (this includes a thesis or dissertation), this will be marked as fraud. Such use AI is therefore not permitted. After all, it is important that you yourself are able to process knowledge and report on it in a convincing text (essay, pleading paper, research report, etc.) and that you can account for it. So please read the two principles below.In the coming period, we want to explore (with you) what (permissible) possibilities and risks exist and how such tools like ChatGPT could be used for the benefit of teaching and studying. We will do this university-wide. If you have your own ideas and experiences about this, please let us know by sending an email to: onderwijsdirecteur.rechten.nl. Guideline:The use of an AI tool (such as ChatGPT or a similar tool) is regarded as fraud if a student generates texts with it and presents them as his/her own work for the purpose of a summative or formative assessment such as an examination, an essay, thesis or dissertation (or parts thereof), cf. art. section OER (BA/ art. section MA).The obligation to be active in and be prepared for classes (art. OER-BA/4.3 OER-MA) is considered not to have been met if a student has only (or to a predominant extent) used an AI tool (such as ChatGPT or a similar tool) for preparation and presents the preparations as his own work.'],\n",
       " ['he following is already clear: if a student uses an AI tool (such as ChatGPT or a similar tool) to generate texts and then presents these as his/her own work for an assessment (this includes a thesis or dissertation), this will be marked as fraud. Such use AI is therefore not permitted. After all, it is important that you yourself are able to process knowledge and report on it in a convincing text (essay, pleading paper, research report, etc.) and that you can account for it. So please read the two principles below.In the coming period, we want to explore (with you) what (permissible) possibilities and risks exist and how such tools like ChatGPT could be used for the benefit of teaching and studying. We will do this university-wide. If you have your own ideas and experiences about this, please let us know by sending an email to: onderwijsdirecteur.rechten.nl. Guideline:The use of an AI tool (such as ChatGPT or a similar tool) is regarded as fraud if a student generates texts with it and presents them as his/her own work for the purpose of a summative or formative assessment such as an examination, an essay, thesis or dissertation (or parts thereof), cf. art. section OER (BA/ art. section MA).The obligation to be active in and be prepared for classes (art. OER-BA/4.3 OER-MA) is considered not to have been met if a student has only (or to a predominant extent) used an AI tool (such as ChatGPT or a similar tool) for preparation and presents the preparations as his own work.'],\n",
       " ['In the coming period, we want to explore (with you) what (permissible) possibilities and risks exist and how such tools like ChatGPT could be used for the benefit of teaching and studying. We will do this university-wide. If you have your own ideas and experiences about this, please let us know by sending an email to: onderwijsdirecteur.rechten.nl. Guideline:The use of an AI tool (such as ChatGPT or a similar tool) is regarded as fraud if a student generates texts with it and presents them as his/her own work for the purpose of a summative or formative assessment such as an examination, an essay, thesis or dissertation (or parts thereof), cf. art. section OER (BA/ art. section MA).The obligation to be active in and be prepared for classes (art. OER-BA/4.3 OER-MA) is considered not to have been met if a student has only (or to a predominant extent) used an AI tool (such as ChatGPT or a similar tool) for preparation and presents the preparations as his own work.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['With the opening of the National Police Lab AI external link, the National Police Corps, Utrecht University, and the University of Amsterdam will soon begin collaborating in the field of artificial intelligence. The lab is the ideal facility for young scientists to conduct research into ways that artificial intelligence can support police work over the coming years. The official opening will be held at Utrecht University on January.'],\n",
       " ['Processing online police reports and analysing hours of image recordings in just a few seconds: these are just two examples of possible police applications of artificial intelligence. The long-term collaboration as part of the National Police Lab AI will ensure that police officers will be able to rely on the most state-of-the-art technology in the field of artificial intelligence for years to come. Artificial intelligence will enhance our operational effectiveness, says Theo van der Plas, Programme Director for Digitalisation and Cybercrime. The increase in the amount of data available in society, and the rapid pace of technological developments, will have an enormous impact on police work. With this collaboration, we will have the knowledge necessary to respond to these changes in-house.'],\n",
       " ['he scientists involved in the lab will focus on applications of artificial intelligence that can automate time-consuming police work and support difficult tasks. For example, in Utrecht we are developing a chatbot that will be able to talk to people submitting a police report online, explains Floris Bex, member of the Scientific Directorate of the National Police Lab AI. The chatbot will know exactly what questions need to be asked in order to process the report successfully.'],\n",
       " [],\n",
       " [\"In the article 'How does AI change the labor market? 'This machine is really much too smart'' (de Volkskrant, May ) Anna Salomons also spoke about AI (specifically about ChatGPT). The predictions that AI will cause unemployment are based on a fallacy, she says. They assume that there are a fixed number of tasks and jobs in the economy, and that those jobs will disappear altogether if some of those tasks are automated. Jobs are disappearing, but new ones are being created. Automating tasks makes us more productive, makes us richer and makes us want more of everything.\"],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Of the companies that expect to use AI in the near future, percent expect that this will cause jobs to disappear and percent that it will create jobs. Keynes predicted in the early twentieth century that future generations could become unemployed because of technological progress, but that has not happened. In fact, more and more work has been added, says Goos. An example of a new position is that of prompt engineer, someone without programming knowledge who knows how to ask the right questions to the AI system (which then writes the code for an application).'],\n",
       " [\"Anna Salomons was a guest in the program Jinek (RTL ), Maarten Goos was interviewed by Nieuwsuur (NPO ). Both experts from the Utrecht University School of Economics (U.S.E.) spoke about the relationship between the use of Artificial Intelligence (AI) and the labor market. Salomons also explained in de Volkskrant that the predictions that AI will cause unemployment are based on a fallacy. Goos made it clear that AI can also be a solution for shortages in the labor market, for example in healthcare. Asked about the chance that people will soon become unemployed due to AI, Anna Salomons said in the television program Jinek: is not that big. I have done research that shows that about percent of the jobs that exist today did not exist at all eighty years ago. In addition, there is a lot of adjustment within jobs. If you see what an administrative assistant does at our university, it is (still) dealing with the professors' egos, but not typing more things in, and organizing more conferences, for example. The job still exists and has changed. Of course, that also requires a lot of adjustment from the employees; it is not a painless process. But it is also not the case that you can make a simple addition.\"],\n",
       " [],\n",
       " [],\n",
       " ['ChatGPT allows students to have (parts of) texts generated automatically. What does this mean for writing education? Should we let students write with pen and paper or wait for better plagiarism detectors before conducting writing assignments again? Or should we embrace these AI text generators precisely because it can support students in their writing (learning) process? And what does this mean for how we ideally design writing education? In this session, we will discuss the pros and cons of ChatGPT for the academic writing education of the future.Language: Dutch and listening languageWorkform: DiscussionThis session will be given by:'],\n",
       " [],\n",
       " ['he interdisciplinary study critically examines how citizens interactions with Conversational Agents such as chatbots and voice bots shape trust in public organisations. Four studies aligned with trust dimensions will be conducted. These studies examine key trust concepts, identify trust markers in human-bot dialogues, conduct experiments centred on human-bot relationships, and investigate the role of CAs in the citizen journey through digital services. The research will be closely executed with potential partners in the public sector, to gather data, show how interactions with conversational agents can be improved and to better understand trust in the context of conversational agents. One of the results is to provide them with guidelines or ideas about how a chatbot influences accessible and inclusive communication for these organisations.ResearcherRhied Al-Othmani, PhD studentLectoraat Marketing & Customer Experience, Knowledge Centre Digital Business & Media, Utrecht University of Applied SciencesAcademic supervisorsDr. Gerrita van der Veen (HU), Prof. Dr. Nanna Verhoeff (UU), Dr. Dennis Nguyen (UU)Grant funding agency; (co-)funding (non-)academic partnersNWO.The study has further been recommended by the Municipality of Utrecht, YDigital & Infomedics. More information Read more here.'],\n",
       " ['ChatGPT is a language AI that can write texts based on a command you give the program. The program will write an essay, advertising text, song (really!) or complete paper for you in no time. The program scours the internet and makes a remix of everything it finds there and that remix often looks surprisingly human. Universities and schools do their very best to prevent fraud, but it is often difficult to distinguish the work of students and ChatGPT from each other.'],\n",
       " [],\n",
       " ['AI has the potential to automate many tasks that currently require human intelligence, such as recognizing images and speech, making choices and solving problems. But it is unlikely that AI will completely take over all of human day-to-day thinking. While AI can perform specific tasks with high efficiency and accuracy, it currently lacks the ability to understand context and make judgments like humans can, and many tasks require a level of creativity and adaptability that AI has not yet achieved. more likely that AI will augment human intelligence by helping with specific tasks, rather than replacing human intelligence altogether.\"'],\n",
       " ['As ChatGPT itself admits, it seems unlikely that computer programs will completely take over our writing tasks. As you can read above, AI is already quite practiced in collecting, selecting and sorting existing data and can create structured texts from existing sources in this way. But AI cannot make value judgments: the program does not do fact-checking and the program also lacks a moral compass. That is why SETUP warns that we should not lose our ability to think for ourselves by outsourcing thinking tasks to bots.'],\n",
       " ['During the event A different state of mind, we asked computer scientist and philosopher Prof. Mehdi Dastani whether AI can become more like us in the future and can learn to make choices based on moral compass or feeling. According to Dastani, computer models first need emotions for this: emotions are crucial for making choices in a world full of uncertainties. Before we get to that point, we cannot yet leave the real thinking to computer programs and we will really have to reflect, reason and make the connections ourselves.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['But is it fair to blame it all on the technology? We need to keep in mind that AI systems are not neutral systems, says philosopher Jan Broersen external link, who chairs Utrecht Universitys Human-Centred Artificial Intelligence research group together with computer scientist Mehdi Dastani. Behind AI are people who express personal ideals of what a good outcome is or what success means, their values, preferences and prejudices, and all of this will be reflected in the system.Broersen illustrates: Say youre developing a program to identify pets. If you train the algorithm on a million images of dogs because you find them cuter or friendlier, but only a few thousand pictures of cats, the algorithms idea of what a cat looks like will be less fully formed, and therefore it will be worse at recognising them. AI can be biased because it makes decisions based on data or training choices that contain our own human biases, Broersen explains.Another, bigger problem is when data sets that feed machine learning algorithms are based on historic discrimination. Then, theres a risk of not only reproducing structural inequalities, but even amplifying them. Think of an algorithm trained to select candidates for a job: if most candidates have been men in the past, the algorithm is likely to reproduce that pattern and end up discriminating women as a result. Examples of coded bias are everywhere; some close to home, such as the algorithms used by the Dutch Tax Authorities that led to racial profiling (widely known as the toeslagenaffaire). In one important way, Broersen adds, algorithmic biases are bringing to the fore prejudices that were rampant in job hiring processes, credit worthiness evaluations or government applications. But once we become aware of them, machines are more easily de-biased than most humans are. Its an opportunity for researchers of AI to do better.'],\n",
       " ['Broersen illustrates: Say youre developing a program to identify pets. If you train the algorithm on a million images of dogs because you find them cuter or friendlier, but only a few thousand pictures of cats, the algorithms idea of what a cat looks like will be less fully formed, and therefore it will be worse at recognising them. AI can be biased because it makes decisions based on data or training choices that contain our own human biases, Broersen explains.Another, bigger problem is when data sets that feed machine learning algorithms are based on historic discrimination. Then, theres a risk of not only reproducing structural inequalities, but even amplifying them. Think of an algorithm trained to select candidates for a job: if most candidates have been men in the past, the algorithm is likely to reproduce that pattern and end up discriminating women as a result. Examples of coded bias are everywhere; some close to home, such as the algorithms used by the Dutch Tax Authorities that led to racial profiling (widely known as the toeslagenaffaire). In one important way, Broersen adds, algorithmic biases are bringing to the fore prejudices that were rampant in job hiring processes, credit worthiness evaluations or government applications. But once we become aware of them, machines are more easily de-biased than most humans are. Its an opportunity for researchers of AI to do better.'],\n",
       " [],\n",
       " [],\n",
       " ['One such instrument is deontic logic, says Jan Broersen external link, whos leading a project to prepare intelligent systems to behave according to ethical and legal principles. Deontic logic is about how to reason correctly with norms, that is, with obligations, permissions and prohibitions that are part of a moral or legal code. It could inform us about when it is appropriate for a self-driving car to violate traffic laws in order to prevent greater harm, for example when somebody has to be rushed to the hospital in order to save their life. If deontic logic can give us models for how to correctly draw conclusions on what an AI must do or is not allowed to do, given certain observations as inputs, we have a basis for machine ethics. And we can have more confidence in such (deontic) logic-based models than ones that need to learn how to behave ethically through machine learning.With the pace of change, innovative forms of regulation are also needed, adds Pnar Yolum external link, Associate Professor of Intelligent Systems. Our traffic laws may need to change as self-driving cars will be able to talk to each other and make decisions, for example, by negotiating who goes first at a crossing. That requires these AI systems to do something very human: use argumentation to negotiate and persuade. Yolum is investigating how to train devices so that they can take decisions on our behalf, knowing our preferences over privacy. Incidentally, this line of research invites a reflection about the process of trusting these systems. We delegate responsibility to other people all the time! How do we get to trust them? By giving them small tasks. I sometimes compare this with children: Ok, you can go to the park across the street. Then the next day you can go to the shop around the corner. Maybe a year later, you can go downtown. You build trust over these interactions and their results. Same with autonomous agents. Thats how I envision the relationship between humans and autonomous systems in the future.'],\n",
       " ['With the pace of change, innovative forms of regulation are also needed, adds Pnar Yolum external link, Associate Professor of Intelligent Systems. Our traffic laws may need to change as self-driving cars will be able to talk to each other and make decisions, for example, by negotiating who goes first at a crossing. That requires these AI systems to do something very human: use argumentation to negotiate and persuade. Yolum is investigating how to train devices so that they can take decisions on our behalf, knowing our preferences over privacy. Incidentally, this line of research invites a reflection about the process of trusting these systems. We delegate responsibility to other people all the time! How do we get to trust them? By giving them small tasks. I sometimes compare this with children: Ok, you can go to the park across the street. Then the next day you can go to the shop around the corner. Maybe a year later, you can go downtown. You build trust over these interactions and their results. Same with autonomous agents. Thats how I envision the relationship between humans and autonomous systems in the future.'],\n",
       " [\"Self-driving cars, care bots and surgical robots are on their way. These artificial intelligence systems could make our roads safer, the lives of people with disabilities or the elderly easier, and patient recovery faster. The promises of artificial intelligence (AI) are huge, and their possibilities endless. But can we really trust machines with our lives? If they act on our behalf, will they do so in a responsible way? If something goes wrong with AI, who is to be held responsible? What happens when we fail to tackle bias and discrimination? At Utrecht University we work to design better, more responsible and trustworthy AI systems. That involves teaching machines how to reason and justify decisions, just as we would, but also solving some of the most pressing ethical and legal challenges AI presents. Unboxing the black box of AIEstimated reading time: minutes Photo: Peter Bak Heres a thought experiment: Youre standing by the tram stop when you catch sight of a runaway trolley rushing down the tracks towards five people who dont see it coming. Now imagine you could divert the trolley onto a second track, which has just one person on it. What do you do? Would you sacrifice the one to save the five? The trolley problem has been a classic dilemma in ethics or philosophy courses for decades. Suddenly, as experimental self-driving cars started hitting the roads, we were faced with a real-world dilemma: what should the AI system be programmed to do in such a life-or-death situation? poses philosopher Sven Nyholm external link from Utrecht University. We will want to know before entrusting our safety to it.What if an autonomous car injures or kills someone? Who should be held responsible? Philosopher Sven Nyholm Knowing how AI systems reach decisions isnt always clear or straightforward. Many algorithmic systems are a black box: information goes in, and decisions come out, but we have little idea how they arrived at those decisions. So, what if an autonomous car injures or kills someone? Who should be held responsible: Is it the distracted person sitting behind the self-driving wheel? The authorities that allowed the car on the road? Or the manufacturer who set up the preferences to save the passenger at all costs? raises Nyholm, who penned an influential paper about the pressing ethics of accident-algorithms for autonomous vehicles external link. People want someone to blame, but we havent reached a universal agreement yet.As a society, discussing what these artificial intelligent systems should or should not do is essential before they start crowding our roads and virtually every other aspect of our lives. Because how can we ever trust systems whose decisions we don't understand? How will we account for wrongdoings? And can they be prevented? Since the s, Utrecht University has been building a diverse community of experts to unbox artificial intelligence to allow the promises of this technological revolution to emerge. What makes artificial intelligence so impactful (and promising) is that it gives computers or machines the ability to model, simulate or even enhance human intelligence. AI systems can sense their environments, learn and reason to decide appropriate actions to achieve their designed objectives, says Mehdi Dastani external link, programme leader of the Master in Artificial Intelligence at Utrecht University. He adds: It is precisely the ability to learn from experience accrued from data that is so central to many of the revolutionary applications of AI today. Its the reason Google translations are now finally decent or why Gmail successfully filters % of spam. But it's essential to ensure that humans remain in control of the AI technology, says Dastani, and distinguish between the good, the bad and the ugly.The good using AI to treat diseaseA virtual sleep coach for sufferers of insomnia, a game for children with chronic illness, or a robot for nudging social distance to prevent the spread of the coronavirus. Beyond the promise of convenience and work efficiencies, AI can help save lives. AI systems can help detect abnormalities in patients medical images that can escape even the best physicians, says Kenneth Gilhuijs external link, Associate Professor at University Medical Centre Utrechts Image Sciences Institute. Gilhuijs has developed a computer-aided diagnosis programme that might soon help doctors detect breast cancer earlier, faster, and more accurately than is possible today.Our AI-powered system can reduce the number of false positives down to % without missing any [breast] cancer. Medical physicist Kenneth Gilhuijs The idea came after a study external link, led by his colleague and cancer epidemiologist Carla van Gils external link, suggested adopting Magnetic Resolution Imaging (MRI) in screening of women with extremely dense breasts could help reduce breast-cancer mortality in this group. Adding MRI to standard mammograph\"],\n",
       " ['detected approximately additional breast cancers; the downside being, % of the total number of lesions referred to additional MRI or biopsy were false-positive for cancer. If the number of biopsies on benign lesions can be reduced, that would alleviate the burden on women and clinical resources, Gilhuijs thought.We have now shown that the AI-powered system can reduce the number of false positives down to % without missing any cancer, says Gilhuijs, in whose lab the algorithm was trained on a database of MRIs from women in The Netherlands who had taken part in Van Gilss study. We want to improve it even further to aid radiologists, by enabling them to focus on cases that require greater human judgement. Oncologists are still responsible for the diagnosis, Gilhuijs remarks, but they use the computer as a tool, just as they might use a statoscope. Its also important to note that the end users of the decision-support system medical doctors have been actively involved in its design. This ensures better acceptance and trust. Photo: Peter Bak The bad using AI to overrule human decisionsBut what happens when users arent involved and dont know how an AI second opinion came about? What could happen is an affront to peoples rights, says legal scholar at Utrecht University Max Vetzo external link. Thats what happened when a judge in Wisconsin relied on an algorithmic tool called COMPAS to decide on the sentence of a man who was found driving a car involved in a shooting. The algorithm in question classified the defendant as a high risk of recidivism, so the then -years old was sentenced to six years of prison. Vetzo: Fundamental rights law guarantees defendants to rebut and fight a judges decision. In this case, when the lawyers appealed the decision, the judge couldnt explain how the system reached that outcome.Thats not to say that the sentence was wrong, or that algorithmic tools cant be used to positive effect, Vetzo notes. AI can be a valuable sparring partner for judges, and even reduce biases in the criminal-justice system, he says. But its the judges responsibility to ensure the transparency of the judicial process. They should, at least, be able to understand how these algorithmic systems reach decisions, and even help assess what legal problems arise from using AI. If not, how can a persons fundamental right to a fair trial be safeguarded?, says Vetzo, co-author of Algorithms and Fundamental Rights (in Dutch), an evaluation of the impact of new AI technologies, specifically in The Netherlands, on fundamental rights such as privacy, freedom of expression or the right to equal treatment.AI can overrule human decisions in more surreptitious ways. We found that algorithms that are connected to home applications, such as smart TVs or digital assistants, which may cause a chilling effect, where people adjust their behaviour knowing that they can be monitored. That is a great concern for privacy. Or our view of the world can be reduced, because of algorithms that select content based on online habits, as with music recommendation algorithms that end up being unfair to female artists. And the ugly coded biasBut is it fair to blame it all on the technology? We need to keep in mind that AI systems are not neutral systems, says philosopher Jan Broersen external link, who chairs Utrecht Universitys Human-Centred Artificial Intelligence research group together with computer scientist Mehdi Dastani. Behind AI are people who express personal ideals of what a good outcome is or what success means, their values, preferences and prejudices, and all of this will be reflected in the system.Broersen illustrates: Say youre developing a program to identify pets. If you train the algorithm on a million images of dogs because you find them cuter or friendlier, but only a few thousand pictures of cats, the algorithms idea of what a cat looks like will be less fully formed, and therefore it will be worse at recognising them. AI can be biased because it makes decisions based on data or training choices that contain our own human biases, Broersen explains.Another, bigger problem is when data sets that feed machine learning algorithms are based on historic discrimination. Then, theres a risk of not only reproducing structural inequalities, but even amplifying them. Think of an algorithm trained to select candidates for a job: if most candidates have been men in the past, the algorithm is likely to reproduce that pattern and end up discriminating women as a result. Examples of coded bias are everywhere; some close to home, such as the algorithms used by the Dutch Tax Authorities that led to racial profiling (widely known as the toeslagenaffaire). In one important way, Broersen adds, algorithmic biases are bringing to the fore prejudices that were rampant in job hiring processes, credit worthiness evaluations or government applications. But once we beco'],\n",
       " [],\n",
       " [\"e Netherlands are already using DEDA to implement data and algorithms responsibly.Practically, says Schaefer, this participatory process enables users of algorithms to document their choices, so that values (and biases) baked into the system can be traceable now and in the future. Algorithms are situated in a context and a place, but our norms and values change. What we found acceptable years ago may be unacceptable now. So tools like BIAS and DEDA help organisations review their choices over time and adapt their design accordingly. Together with colleagues from Utrecht Data School, Schaefer and Professor of Fundamental Rights Janneke Gerards have launched an Impact Assessment for Human Rights and Algorithms (IAMA) aimed at preventing human rights violations, such as the toeslagenaffaire. Forward-looking responsibilitySelf-driving cars are one such example where the law can't keep up: all traffic laws assume theres a human doing the steering and the breaking. Rather than leaving it to regulatory catch-up, researchers in Utrecht are getting ahead by thinking of how we can design autonomous systems now to keep them from behaving wrong in the future including in situations we can't even anticipate today.Deontic logic can give us a basis for machine ethics. Logician Jan Broersen One such instrument is deontic logic, says Jan Broersen external link, whos leading a project to prepare intelligent systems to behave according to ethical and legal principles. Deontic logic is about how to reason correctly with norms, that is, with obligations, permissions and prohibitions that are part of a moral or legal code. It could inform us about when it is appropriate for a self-driving car to violate traffic laws in order to prevent greater harm, for example when somebody has to be rushed to the hospital in order to save their life. If deontic logic can give us models for how to correctly draw conclusions on what an AI must do or is not allowed to do, given certain observations as inputs, we have a basis for machine ethics. And we can have more confidence in such (deontic) logic-based models than ones that need to learn how to behave ethically through machine learning.With the pace of change, innovative forms of regulation are also needed, adds Pnar Yolum external link, Associate Professor of Intelligent Systems. Our traffic laws may need to change as self-driving cars will be able to talk to each other and make decisions, for example, by negotiating who goes first at a crossing. That requires these AI systems to do something very human: use argumentation to negotiate and persuade. Yolum is investigating how to train devices so that they can take decisions on our behalf, knowing our preferences over privacy. Incidentally, this line of research invites a reflection about the process of trusting these systems. We delegate responsibility to other people all the time! How do we get to trust them? By giving them small tasks. I sometimes compare this with children: Ok, you can go to the park across the street. Then the next day you can go to the shop around the corner. Maybe a year later, you can go downtown. You build trust over these interactions and their results. Same with autonomous agents. Thats how I envision the relationship between humans and autonomous systems in the future. Diverse skills and peopleFinally, if we are to trust that AI is moving in the right direction, we need to bring in everyone: different skills and diverse teams, that can check on each others biases to produce a more inclusive output and that starts with our education. Were equipping a new generation of AI professionals with interdisciplinary skills and a moral compass for the social context in which technologies evolve, says Mehdi Dastani external link, programme leader of the Masters programme in Artificial Intelligence and co-chair of the Human-Centred Artificial Intelligence group at Utrecht University. For one main reason: AI powering our future intelligent (autonomous) systems is much more than learning from patterns extracted from big data. It is, above all, about rich representation systems, correct reasoning schemes, and about modelling intelligence that approach problems and tasks efficiently and accurately. Those models can benefit from scientific knowledge accrued over time from different scientific disciplines, such as psychology, philosophy, linguistics, and computer sciences. But also from different cultural backgrounds and perspectives.Were equipping a new generation of AI professionals with interdisciplinary skills and a moral compass. Computer scientist Mehdi Dastanti At Utrecht University we work to make better AI: developing explainable systems so that users can understand or challenge their decisions and outcomes; programming responsible machines so that if something goes wrong or bias creeps in, organisations can redress it; or interacting with robots so that we create human-centred machin\"],\n",
       " ['Heres a thought experiment: Youre standing by the tram stop when you catch sight of a runaway trolley rushing down the tracks towards five people who dont see it coming. Now imagine you could divert the trolley onto a second track, which has just one person on it. What do you do? Would you sacrifice the one to save the five? The trolley problem has been a classic dilemma in ethics or philosophy courses for decades. Suddenly, as experimental self-driving cars started hitting the roads, we were faced with a real-world dilemma: what should the AI system be programmed to do in such a life-or-death situation? poses philosopher Sven Nyholm external link from Utrecht University. We will want to know before entrusting our safety to it.'],\n",
       " ['he trolley problem has been a classic dilemma in ethics or philosophy courses for decades. Suddenly, as experimental self-driving cars started hitting the roads, we were faced with a real-world dilemma: what should the AI system be programmed to do in such a life-or-death situation? poses philosopher Sven Nyholm external link from Utrecht University. We will want to know before entrusting our safety to it.'],\n",
       " [\"Knowing how AI systems reach decisions isnt always clear or straightforward. Many algorithmic systems are a black box: information goes in, and decisions come out, but we have little idea how they arrived at those decisions. So, what if an autonomous car injures or kills someone? Who should be held responsible: Is it the distracted person sitting behind the self-driving wheel? The authorities that allowed the car on the road? Or the manufacturer who set up the preferences to save the passenger at all costs? raises Nyholm, who penned an influential paper about the pressing ethics of accident-algorithms for autonomous vehicles external link. People want someone to blame, but we havent reached a universal agreement yet.As a society, discussing what these artificial intelligent systems should or should not do is essential before they start crowding our roads and virtually every other aspect of our lives. Because how can we ever trust systems whose decisions we don't understand? How will we account for wrongdoings? And can they be prevented? Since the s, Utrecht University has been building a diverse community of experts to unbox artificial intelligence to allow the promises of this technological revolution to emerge.\"],\n",
       " [],\n",
       " ['A virtual sleep coach for sufferers of insomnia, a game for children with chronic illness, or a robot for nudging social distance to prevent the spread of the coronavirus. Beyond the promise of convenience and work efficiencies, AI can help save lives. AI systems can help detect abnormalities in patients medical images that can escape even the best physicians, says Kenneth Gilhuijs external link, Associate Professor at University Medical Centre Utrechts Image Sciences Institute. Gilhuijs has developed a computer-aided diagnosis programme that might soon help doctors detect breast cancer earlier, faster, and more accurately than is possible today.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['he impact of ChatGPT on writing educationDr. Renske Bouwer, Assistant Professor in Language & EducationWith ChatGPT students can automatically generate (parts of) texts. What does this mean for the way we teach academic writing at universities? Shall we ask students to write with paper and pen again? Wait for better (automated) plagiarism detection before asking our students to ever again complete writing assignments? Or should we embrace these AI text generators, as they can support students in (mastering) their writing process? And what does ChatGPT mean for our ideal of writing education? In this session we will discuss the pro- and cons of ChatGPT for academic writing education of the future.'],\n",
       " ['Dr. Renske Bouwer, Assistant Professor in Language & EducationWith ChatGPT students can automatically generate (parts of) texts. What does this mean for the way we teach academic writing at universities? Shall we ask students to write with paper and pen again? Wait for better (automated) plagiarism detection before asking our students to ever again complete writing assignments? Or should we embrace these AI text generators, as they can support students in (mastering) their writing process? And what does ChatGPT mean for our ideal of writing education? In this session we will discuss the pro- and cons of ChatGPT for academic writing education of the future.'],\n",
       " ['With ChatGPT students can automatically generate (parts of) texts. What does this mean for the way we teach academic writing at universities? Shall we ask students to write with paper and pen again? Wait for better (automated) plagiarism detection before asking our students to ever again complete writing assignments? Or should we embrace these AI text generators, as they can support students in (mastering) their writing process? And what does ChatGPT mean for our ideal of writing education? In this session we will discuss the pro- and cons of ChatGPT for academic writing education of the future.'],\n",
       " [],\n",
       " ['wo weeks before TIMs fourth session Social imaginaries of ethics and AI, my friends and I started to obsess over The Chat GPT, a chatbot recently launched by OpenAI. Our discussions tended towards the dystopian-speculative view that was one of the common attitudes towards AI discussed by the speakers Sonja Rebecca Rattay, Irina Shklovski and Marco Rozendaal. The bot writes surprisingly adequate essays about almost every subject and seems to combine varying concepts creatively. What will happen to thought and writing in cultural and social studies if AI produces essays many times faster than the speed with which we take things in, and transform and type them out as texts? Well lose our jobs, perhaps, but maybe worse, theory could lose the ambivalence inherent to the thought, bodies, and environments from which it emergesto become products of an echo-chamber devouring its own data, and that ruminates and spits out its uncontestable digits. With this in mind, I wondered what essay the GPTchat would write about ethical AI In words, it resumed societal concerns about biased algorithms, displacement of jobs, and AI potentially serving malicious proposes (i.e. weapon developments). To produce ethical AImeaning ensuring that it is used for the benefit of humanity and does not cause harmAI developers, companies, and governments should provide the means to halt biases, unemployment, and misuses of the technology. By following ethical principles, the bot concludes, we can ensure that AI is a positive force for good in the world.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['In this blogpost, I will explore different positions towards ChatGPT, a language model developed by OpenAI that has become a cultural phenomenon since its release. According to ChatGPT itself, ChatGPT is trained using a deep learning technique called transformer architecture. This architecture is based on a neural network that is trained using a technique called unsupervised learning, where the model is fed vast amounts of text data and learns patterns and relationships between words and phrases in the data. During training, the model is presented with a sequence of words and the task is to predict the next word in the sequence. Over time, the model learns to generate coherent and fluent text that resembles human language (see figure ).'],\n",
       " [],\n",
       " [],\n",
       " ['his is not the only position towards ChatGPT. The American left-wing website Jacobin published an article in January which, following a Marxist approach, argues that AI inevitably competes with humans for jobs and will therefore be used by capital as a weapon to weaken labor and suppress strikes (Zickgraf). Obviously, this article represents a dystopian-speculative position towards AI and sees ChatGPT as a sign that AI is starting to compete with white collar workers. However, this is not the dominant view on the side of the capital. The Economist, published an article in December that recounts the excitement among corporate users and venture-capital backers (Artificial Intelligence). For sure these people are more focused on the foresight and potential of the generative AI such as ChatGPT.'],\n",
       " ['he new chat program writes essays, literature and scientific papers on command. With its apparent all-rounder, the program raises all kinds of questions. Will the chatbot soon be able to write as well as we do? Can he think for himself and come up with creative solutions? What does this mean for education and science?'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [\"Finding the truth is not important That brought Gijsbers to a sensitive point. According to him, the chatbot is not programmed for truth-finding. While earlier artificial intelligent systems were. OpenAI, the company behind ChatGPT, wouldn't care about that. For example, Gijsbers presented the chatbot with a problem that had already been solved by a program from the s. The chatbot came up with incorrect answers several times. The program also occasionally does strange things. If you ask ChatGPT ten times what the capital of the Netherlands is, he will say Amsterdam nine times and Rotterdam once.\"],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['he idea is that students will be able to access the profile pages of those taking the same courses as them. Said profile page will be based on a compilation of data and photos made by UU with the help of ChatGPT and other AI bots.'],\n",
       " ['Are you a member of a student association? What are your hobbies? Where do you go out clubbing? Soon, your fellow students will get to know all about you on your UU profile page. The university collected information about every student by using tools like the AI bots ChatGPT. Curious to take a peek? The project will go live this weekend. *This article was our april fools joke*'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Koenders is convinced that students will make use of these new tools. A UU teacher who asked essay questions to ChatGPT out of curiosity concluded with bewilderment that the bot certainly scored a pass.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['he Utrecht University Special Interest Group Principles by Design: Towards Good Data Practice, part of the Governing the Digital Society focus area, is looking for enthusiastic UU master students who wish to participate in the student-led workshop How do you want to be governed? A multidisciplinary discussion on the pacing of innovation: A ChatGPT case study, which will take place on the th of July , :00 :00.The deadline for the submission of CV & short motivation letter is: May , AM. For details, see the brochure. The student workshop will be organized in association with the International Conference on Robot Ethics and Standards (ICRES) external link that Utrecht University hosts this year. The findings of the workshops discussion will also be presented at the ICRES conference.Theme of the workshopShould we slow down the development of artificial intelligence? The common phrase AI today is the stupidest it will ever be perfectly encompasses AIs exponential growth. This became increasingly obvious in November when OpenAI deployed ChatGPT, an AI-powered chatbot. The ChatGPT template has been adapted to numerous fields in just five months. Its offspring has become a virtual therapist (Wysa), and a companion (Snapchat My AI), and its further potential is yet to be seen. What was initially a virtual assistant has increasingly implanted itself into the human experience and is continuously learning how to get better. Some embrace this rapid innovation, while others call for a halt in development to consider broader societal impacts and facilitate regulation. An open letter by AI experts called for a six-month pause in developing systems more powerful than OpenAIs newly launched GPT-4. Geoffrey Hinton, a renowned researcher in neural networks and computer science dubbed the Godfather of AI, highlighted that the current acceleration of development in an unregulated environment creates opportunities for actors to abuse these technologies. Scepticism surrounding ChatGPT continues to grow as countries and companies ban the chatbot due to privacy concerns. Is this a justified response?The workshop will bring together Utrecht University masters students from various disciplines to discuss the topic: Should we pace innovation? The case study of ChatGPT and its by-products. It gives students the opportunity to apply their research to a current societal issue and provide their perspective on the regulation of technology. They will also be given the opportunity to present their findings at the Conference. Moreover, co-author a piece which will be published on the Conferences official website.This is a great opportunity for students to learn from other fields, which will be useful for your future employment. They will be able to demonstrate their ability to work in a multidisciplinary team. Moreover, allow them to stand out as students and take the next step in academic research.For further questions on the student-led workshop, contact the chair of the workshop, Simona Jansonaite at s.jansonaite.nl.'],\n",
       " ['he deadline for the submission of CV & short motivation letter is: May , AM. For details, see the brochure. The student workshop will be organized in association with the International Conference on Robot Ethics and Standards (ICRES) external link that Utrecht University hosts this year. The findings of the workshops discussion will also be presented at the ICRES conference.Theme of the workshopShould we slow down the development of artificial intelligence? The common phrase AI today is the stupidest it will ever be perfectly encompasses AIs exponential growth. This became increasingly obvious in November when OpenAI deployed ChatGPT, an AI-powered chatbot. The ChatGPT template has been adapted to numerous fields in just five months. Its offspring has become a virtual therapist (Wysa), and a companion (Snapchat My AI), and its further potential is yet to be seen. What was initially a virtual assistant has increasingly implanted itself into the human experience and is continuously learning how to get better. Some embrace this rapid innovation, while others call for a halt in development to consider broader societal impacts and facilitate regulation. An open letter by AI experts called for a six-month pause in developing systems more powerful than OpenAIs newly launched GPT-4. Geoffrey Hinton, a renowned researcher in neural networks and computer science dubbed the Godfather of AI, highlighted that the current acceleration of development in an unregulated environment creates opportunities for actors to abuse these technologies. Scepticism surrounding ChatGPT continues to grow as countries and companies ban the chatbot due to privacy concerns. Is this a justified response?The workshop will bring together Utrecht University masters students from various disciplines to discuss the topic: Should we pace innovation? The case study of ChatGPT and its by-products. It gives students the opportunity to apply their research to a current societal issue and provide their perspective on the regulation of technology. They will also be given the opportunity to present their findings at the Conference. Moreover, co-author a piece which will be published on the Conferences official website.This is a great opportunity for students to learn from other fields, which will be useful for your future employment. They will be able to demonstrate their ability to work in a multidisciplinary team. Moreover, allow them to stand out as students and take the next step in academic research.For further questions on the student-led workshop, contact the chair of the workshop, Simona Jansonaite at s.jansonaite.nl.'],\n",
       " ['Should we slow down the development of artificial intelligence? The common phrase AI today is the stupidest it will ever be perfectly encompasses AIs exponential growth. This became increasingly obvious in November when OpenAI deployed ChatGPT, an AI-powered chatbot. The ChatGPT template has been adapted to numerous fields in just five months. Its offspring has become a virtual therapist (Wysa), and a companion (Snapchat My AI), and its further potential is yet to be seen. What was initially a virtual assistant has increasingly implanted itself into the human experience and is continuously learning how to get better. Some embrace this rapid innovation, while others call for a halt in development to consider broader societal impacts and facilitate regulation. An open letter by AI experts called for a six-month pause in developing systems more powerful than OpenAIs newly launched GPT-4. Geoffrey Hinton, a renowned researcher in neural networks and computer science dubbed the Godfather of AI, highlighted that the current acceleration of development in an unregulated environment creates opportunities for actors to abuse these technologies. Scepticism surrounding ChatGPT continues to grow as countries and companies ban the chatbot due to privacy concerns. Is this a justified response?The workshop will bring together Utrecht University masters students from various disciplines to discuss the topic: Should we pace innovation? The case study of ChatGPT and its by-products. It gives students the opportunity to apply their research to a current societal issue and provide their perspective on the regulation of technology. They will also be given the opportunity to present their findings at the Conference. Moreover, co-author a piece which will be published on the Conferences official website.This is a great opportunity for students to learn from other fields, which will be useful for your future employment. They will be able to demonstrate their ability to work in a multidisciplinary team. Moreover, allow them to stand out as students and take the next step in academic research.For further questions on the student-led workshop, contact the chair of the workshop, Simona Jansonaite at s.jansonaite.nl.'],\n",
       " ['Some embrace this rapid innovation, while others call for a halt in development to consider broader societal impacts and facilitate regulation. An open letter by AI experts called for a six-month pause in developing systems more powerful than OpenAIs newly launched GPT-4. Geoffrey Hinton, a renowned researcher in neural networks and computer science dubbed the Godfather of AI, highlighted that the current acceleration of development in an unregulated environment creates opportunities for actors to abuse these technologies. Scepticism surrounding ChatGPT continues to grow as countries and companies ban the chatbot due to privacy concerns. Is this a justified response?The workshop will bring together Utrecht University masters students from various disciplines to discuss the topic: Should we pace innovation? The case study of ChatGPT and its by-products. It gives students the opportunity to apply their research to a current societal issue and provide their perspective on the regulation of technology. They will also be given the opportunity to present their findings at the Conference. Moreover, co-author a piece which will be published on the Conferences official website.This is a great opportunity for students to learn from other fields, which will be useful for your future employment. They will be able to demonstrate their ability to work in a multidisciplinary team. Moreover, allow them to stand out as students and take the next step in academic research.For further questions on the student-led workshop, contact the chair of the workshop, Simona Jansonaite at s.jansonaite.nl.'],\n",
       " ['he workshop will bring together Utrecht University masters students from various disciplines to discuss the topic: Should we pace innovation? The case study of ChatGPT and its by-products. It gives students the opportunity to apply their research to a current societal issue and provide their perspective on the regulation of technology. They will also be given the opportunity to present their findings at the Conference. Moreover, co-author a piece which will be published on the Conferences official website.This is a great opportunity for students to learn from other fields, which will be useful for your future employment. They will be able to demonstrate their ability to work in a multidisciplinary team. Moreover, allow them to stand out as students and take the next step in academic research.For further questions on the student-led workshop, contact the chair of the workshop, Simona Jansonaite at s.jansonaite.nl.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['DUB took a walk in the Utrecht Science Park during the latest exam week, wondering if UU students will still study for their exams now that ChatGPT took the world by storm.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [\"Quizzing yourself UU's Executive board was as startled as anyone else by the speed with which AI has been advancing and rushed to tighten its plagiarism rules. Nevertheless, the goal of the new regulations isnt to keep ChatGPT from ever being used but rather to regulate its use. Teachers will mainly have to change the way their courses are assessed. For now, things haven't gone that far.\"],\n",
       " [],\n",
       " ['A friend of mine works as a French teacher and he says that around percent of all papers are written by AI now, we hear from Caitrione, a History student. I know people who have used it to write essays. The biggest danger is that people will become very lazy and use ChatGPT instead of thinking for themselves. On the other hand, this technology has its benefits as well. Ive heard that there are people using it to quiz themselves ahead of an exam, for instance.'],\n",
       " [],\n",
       " ['Johan Jeuring, a Professor in Information and Computing Sciences, acknowledges that ChatGPT will bring forth considerable challenges for the education sector. Assessment methods like traditional essays and open-book exams are less and less useful this way, he states.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [\"Most students we interviewed at the Utrecht Science Park arent afraid that the chatbot will develop a consciousness of its own and take over the world someday. To Merlijn, a Masters student in Computing Science with a Bachelors in Artificial Intelligence, the question of whether computers will ever be able to have their own consciousness is a philosophical discussion. Hence his decision to follow a Bachelor's that included Philosophy courses.\"],\n",
       " ['Merlijn is thus convinced that there is no such thing as strong AI right now. Moreover, he says most IT students dont believe such a thing would be possible in the future. Its not a realistic to think that a chatbot like that will take over the world.'],\n",
       " ['Other students are afraid that ChatGPT will replace a significant number of jobs down the line, make their studies redundant. Professor Jeuring, however, debunks that scenario. People said the same in the early s about IT development but that ended up creating more jobs instead. This type of tool can only take over relatively easy, repetitive tasks. I believe this new technology will enable us to focus on creative, more interesting tasks.'],\n",
       " [],\n",
       " [\"Nevertheless, Naomi, an Audiovisual Media student at HKU, does worry about the creative industry, where she and other students would like to work. ChatGPT can already write simple stories and song lyrics; other AI tools make music and art. I just really hope people will keep appreciating it when something is created by a human, she sighs. When something is human-made, there is a certain feeling behind it. Someones thought about every single stroke. That doesn't happen with AI art.\"],\n",
       " ['Are students still writing their own essays? Is there any point left in open-book exams? With its massive calculation power and the ability to \"understand\" questions, the new AI chatbot ChatGPT has been causing a global stir, especially in the higher education field. Many students believe the chatbot will give rise to major changes in higher education. The greatest danger is that people will become very lazy.'],\n",
       " [],\n",
       " [\"ChatGPT. In recent weeks, everyone has been talking about the chat robot that can generate texts itself. Unique texts, difficult to distinguish from 'real'. It is an example of artificial intelligence, also called artificial intelligence (AI). AI raises not only technical, but also moral questions: how will it affect our economy? Can AI help solve problems in our society and how? But also: what is the impact of AI on human autonomy? Various humanities scientists are conducting research into this. Responsible artificial intelligence One of them is Professor of Philosophy Jan Broersen. With a background in mathematics, logic and computer science, he explores philosophical questions raised by AI. For example, how logic-based modeling methods can help develop forms of responsible artificial intelligence that are controllable and that serve people. Broersen sees that in addition to almost unbridled optimism about the possibilities, there is also a lot of fear of artificial intelligence. intelligence. There is a lot to nuance, he thinks. In the Radio1 program 'De Nacht Van', Broersen explains both the opportunities that AI offers and its limits. And he reassures listeners who fear the malicious world domination of artificial intelligence. ChatGPT seems to understand the game of questions and answers just fine. The point is, says Broersen in an interview with NRC, he does not understand himself. Even the best AI language programs are nothing more than probabilistic calculation monsters. They can predict word order amazingly well, but they elude meaning and logical structure. Professor Jan Broersen continues to talk about all the possibilities, but also the impossibilities of AI, in his Studium Generale lecture 'How stupid is artificial intelligence?' that you stay in your political bubble' (Brandpunt+, March ) 'AI is hot on the heels of stunned, enchanted and sobered philosophers' (NRC, February ) Watch here Studium Generale with Jan Broersen 'How stupid is artificial intelligence? ' (February , ) 'The Night Of... 'The Two Sides of AI' (January , )\"],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [\"Professor of Media and Digital Society Jos van Dijck argues in the Financieel Dagblad that universities can arm themselves against plagiarism via ChatGPT by focusing on the language development of students. If writing skills were seriously seen as a foundational subject at university, we would consider ChatGPT, just like Wikipedia, search engines, spell checkers, synonym apps and other digital tools, to be part of the writing process. Van Dijck also has reservations about the 'open' aspect of the company behind ChatGPT: OpenAI. It is clear that those toys are free as long as they still need training, but what OpenAI's revenue model will become is a well-kept trade secret. Whether and how products such as ChatGPT3 and Dall-E2 will disappear behind the paywall is not yet known. The open business operations that were once advocated seem to be a thing of the past. 'Photo taken without a camera is that still a photo?' (NRC, April , ) 'Chat with artificial intelligence' (Dr Kelder & Co, April , ) 'Can politicians keep up with the rapid development of AI?', AD (April , ) 'If students use ChatGPT to think for them, teachers are doing something wrong'', Science Guide (March , ) 'How do you know if a knowledge source like ChatGPT is good', Financieel Dagblad (March , ) Read here 'Don't turn students into parrots', (Financial Dagblad, February ) external link Read here 'Idealism of OpenAI seems nothing more than a hot air balloon' (Financieel Dagblad, January ) external link\"],\n",
       " [\"Van Dijck also has her reservations about the 'open' aspect of the company behind ChatGPT: OpenAI. It is clear that those toys are free as long as they still need training, but what OpenAI's revenue model will become is a well-kept trade secret. Whether and how products such as ChatGPT3 and Dall-E2 will disappear behind the paywall is not yet known. The open business operations that were once advocated seem to be a thing of the past.\"],\n",
       " ['I believe we can defuse the hype by feeding it en masse. Data-driven technology such as ChatGPT requires paradoxical engagement. I would advise anyone, especially critics, to play with the tool endlessly and commit data sabotage while playing. Give the chatbot what it asks for. Feed him with data, but with nonsensical data.\" Van Egdom is sober about the endless possibilities of AI that the founder of ChatGPT\\'s parent company Open AI predicts. After all, it is not only companies of good will that use AI, he argues in an Another Volkskrant article: \"Translation scientist Van Egdom cites the notoriously clumsy phishing emails from the past, in which \\'Nigerian princes\\' seduce naive victims into transferring money. With the help of ChatGPT, these rattling messages can be upgraded in an instant to convincing and well-running texts in combination with a matching site.\" Many experts believe that automated disinformation and propaganda will also be distributed en masse. Van Egdom says about this: \"The language models that we now see are so efficient that the digital world will increasingly supersede the real world. be laid, until the contours of the real world will hardly be seen. \\'ChatGPT concerns: are we sinking into a swamp of disinformation?\\' De Volkskrant (January , ) \\'Confederate ChatGPT by disrupting its algorithms\\', de Volkskrant (January , )'],\n",
       " [\"Van Egdom is level-headed about the infinite possibilities of AI that the founder of ChatGPT's parent company Open AI envisions. After all, it is not only companies of good will that use AI, he argues in another Volkskrant article: Translation scientist Van Egdom cites the notoriously clumsy phishing emails from the past, in which 'Nigerian princes' seduce naive victims into transferring money. Those rattling messages can be upgraded in an instant with the help of ChatGPT to convincing and well-running texts in combination with a matching site. Many experts believe that automated disinformation and propaganda will also be distributed en masse. Van Egdom says about this: The language models we see now are so efficient that the digital world will increasingly be superimposed on the real world, until the contours of the real world will hardly be visible. 'ChatGPT concerns: are we sinking into a swamp of disinformation?' De Volkskrant (January , ) 'Confederate ChatGPT by disrupting its algorithms', de Volkskrant (January , )\"],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [\"In recent months, the application of artificial intelligence in education has taken off, especially chatbots such as ChatGPT. Utrecht University believes it is important to explore how this technology can and should relate to UU education and is making funds available from the USO fund to explore this in a cross-faculty project.AI chatbot technology touches education in three different ways, and all three present different perspectivestudents can use this technology to support their learning or use it to complete assignments, whether or not intended by the lecturer. Availability of AI chatbots has implications for learning activities and assessment. What opportunities for learning does AI technology create? What risks are there? How can we as UU deal with these opportunities and risks?Teachers can use AI chatbots to support their own teaching tasks. They can use chatbots to inspire teaching & learning design or use them to answer student questions, for example. In what ways can chatbots further support teachers and how does it help them in professionalisation? What opportunities and risks are there and how can we deal with them as UU?The field of work is changing with the availability of chatbots. Jobs and associated work tasks are changing. This means that after graduation, our students will start working in a work environment in which they might perform some of the work tasks with chatbot support. What skills will this require of our students? And what consequences could or should this have for UU education? How can we as UU deal with this?All three of these perspectives are interesting to explore further, and we warmly invite applicants to submit proposals on one or more of the above perspectives, or even put another perspective at the centre.We explicitly ask that the USO project make use of - or connect to - ongoing (faculty) projects and initiatives in the field of AI and education. The aim of this call is partly to bring together ongoing initiatives within UU.The USO project can make use of an already existing support team that coordinates cooperation with the departments within the University Corporate Offices. Educational expertise is also available to contribute to the project.ConditionsThere is available to implement projects on this theme. We welcome applications with a budget of or . One or two projects can therefore be funded. Projects start in .These interfaculty USO projects with a duration of to years have a cross-faculty character and are therefore submitted by more than one faculty. We only honour projects that are not funded by the primary education process.We want to reap the benefits of the project's revenues quickly and ask that the project description include an annual delivery of interim results.Double funding is obviously not possible. However, it is possible to further expand already funded (faculty) projects using this fund.ProcedureAn application is written by a consortium, led by a consortium leader. A consortium co-leadership is also a possibility.A meeting will be organised for anyone interested in this topic who might want to join a consortium or who would like to apply as a consortium leader. This meeting will take place on May, from :30am to pm in the Buys Ballot Building in room . This is a good opportunity to forge a consortium and select a consortium leader for this purpose. Of course, you are also free to shape this outside this meeting.During the meeting, you will be asked to share briefly how you are already working on Artificial Intelligence in education, and/or how you would like to contribute to a project.If you would like to contribute as a consortium member or leader, but cannot attend the meeting, you may send a message to cat.nl stating 'USO- Artificial Intelligence in Education', indicating how you would like to contribute to a project (as a consortium member, or leader; what activities would you like to contribute in the project?). We will share these during the meeting, allowing other participants to contact you to forge a consortium together.If you want to become a consortium member, please discuss this first with your education director and manager. Consortium leaders inform their education director, manager, vice dean of education and dean before applying. This is important because the proposal is ultimately submitted by the dean. Consortium leaders are asked to send in a motivation (300 words), reflection on the theme (300 words), teaching CV (max A4), project idea (max A4), amount to be applied for and description of the desired consortium composition and already affiliated consortium members via the form below by June at the latest.Based on this, the USO assessment committee will invite a limited number of consortium leaders to develop a proposal (deadline June). In doing so, the committee may also advise consortia to develop a joint proposal.The invited consortium leaders can explain their p\"],\n",
       " [\"AI chatbot technology touches education in three different ways, and all three present different perspectivestudents can use this technology to support their learning or use it to complete assignments, whether or not intended by the lecturer. Availability of AI chatbots has implications for learning activities and assessment. What opportunities for learning does AI technology create? What risks are there? How can we as UU deal with these opportunities and risks?Teachers can use AI chatbots to support their own teaching tasks. They can use chatbots to inspire teaching & learning design or use them to answer student questions, for example. In what ways can chatbots further support teachers and how does it help them in professionalisation? What opportunities and risks are there and how can we deal with them as UU?The field of work is changing with the availability of chatbots. Jobs and associated work tasks are changing. This means that after graduation, our students will start working in a work environment in which they might perform some of the work tasks with chatbot support. What skills will this require of our students? And what consequences could or should this have for UU education? How can we as UU deal with this?All three of these perspectives are interesting to explore further, and we warmly invite applicants to submit proposals on one or more of the above perspectives, or even put another perspective at the centre.We explicitly ask that the USO project make use of - or connect to - ongoing (faculty) projects and initiatives in the field of AI and education. The aim of this call is partly to bring together ongoing initiatives within UU.The USO project can make use of an already existing support team that coordinates cooperation with the departments within the University Corporate Offices. Educational expertise is also available to contribute to the project.ConditionsThere is available to implement projects on this theme. We welcome applications with a budget of or . One or two projects can therefore be funded. Projects start in .These interfaculty USO projects with a duration of to years have a cross-faculty character and are therefore submitted by more than one faculty. We only honour projects that are not funded by the primary education process.We want to reap the benefits of the project's revenues quickly and ask that the project description include an annual delivery of interim results.Double funding is obviously not possible. However, it is possible to further expand already funded (faculty) projects using this fund.ProcedureAn application is written by a consortium, led by a consortium leader. A consortium co-leadership is also a possibility.A meeting will be organised for anyone interested in this topic who might want to join a consortium or who would like to apply as a consortium leader. This meeting will take place on May, from :30am to pm in the Buys Ballot Building in room . This is a good opportunity to forge a consortium and select a consortium leader for this purpose. Of course, you are also free to shape this outside this meeting.During the meeting, you will be asked to share briefly how you are already working on Artificial Intelligence in education, and/or how you would like to contribute to a project.If you would like to contribute as a consortium member or leader, but cannot attend the meeting, you may send a message to cat.nl stating 'USO- Artificial Intelligence in Education', indicating how you would like to contribute to a project (as a consortium member, or leader; what activities would you like to contribute in the project?). We will share these during the meeting, allowing other participants to contact you to forge a consortium together.If you want to become a consortium member, please discuss this first with your education director and manager. Consortium leaders inform their education director, manager, vice dean of education and dean before applying. This is important because the proposal is ultimately submitted by the dean. Consortium leaders are asked to send in a motivation (300 words), reflection on the theme (300 words), teaching CV (max A4), project idea (max A4), amount to be applied for and description of the desired consortium composition and already affiliated consortium members via the form below by June at the latest.Based on this, the USO assessment committee will invite a limited number of consortium leaders to develop a proposal (deadline June). In doing so, the committee may also advise consortia to develop a joint proposal.The invited consortium leaders can explain their proposal in a pitch on July. Register as a consortium leader via this form external link\"],\n",
       " [\"All three of these perspectives are interesting to explore further, and we warmly invite applicants to submit proposals on one or more of the above perspectives, or even put another perspective at the centre.We explicitly ask that the USO project make use of - or connect to - ongoing (faculty) projects and initiatives in the field of AI and education. The aim of this call is partly to bring together ongoing initiatives within UU.The USO project can make use of an already existing support team that coordinates cooperation with the departments within the University Corporate Offices. Educational expertise is also available to contribute to the project.ConditionsThere is available to implement projects on this theme. We welcome applications with a budget of or . One or two projects can therefore be funded. Projects start in .These interfaculty USO projects with a duration of to years have a cross-faculty character and are therefore submitted by more than one faculty. We only honour projects that are not funded by the primary education process.We want to reap the benefits of the project's revenues quickly and ask that the project description include an annual delivery of interim results.Double funding is obviously not possible. However, it is possible to further expand already funded (faculty) projects using this fund.ProcedureAn application is written by a consortium, led by a consortium leader. A consortium co-leadership is also a possibility.A meeting will be organised for anyone interested in this topic who might want to join a consortium or who would like to apply as a consortium leader. This meeting will take place on May, from :30am to pm in the Buys Ballot Building in room . This is a good opportunity to forge a consortium and select a consortium leader for this purpose. Of course, you are also free to shape this outside this meeting.During the meeting, you will be asked to share briefly how you are already working on Artificial Intelligence in education, and/or how you would like to contribute to a project.If you would like to contribute as a consortium member or leader, but cannot attend the meeting, you may send a message to cat.nl stating 'USO- Artificial Intelligence in Education', indicating how you would like to contribute to a project (as a consortium member, or leader; what activities would you like to contribute in the project?). We will share these during the meeting, allowing other participants to contact you to forge a consortium together.If you want to become a consortium member, please discuss this first with your education director and manager. Consortium leaders inform their education director, manager, vice dean of education and dean before applying. This is important because the proposal is ultimately submitted by the dean. Consortium leaders are asked to send in a motivation (300 words), reflection on the theme (300 words), teaching CV (max A4), project idea (max A4), amount to be applied for and description of the desired consortium composition and already affiliated consortium members via the form below by June at the latest.Based on this, the USO assessment committee will invite a limited number of consortium leaders to develop a proposal (deadline June). In doing so, the committee may also advise consortia to develop a joint proposal.The invited consortium leaders can explain their proposal in a pitch on July. Register as a consortium leader via this form external link\"],\n",
       " [\"We explicitly ask that the USO project make use of - or connect to - ongoing (faculty) projects and initiatives in the field of AI and education. The aim of this call is partly to bring together ongoing initiatives within UU.The USO project can make use of an already existing support team that coordinates cooperation with the departments within the University Corporate Offices. Educational expertise is also available to contribute to the project.ConditionsThere is available to implement projects on this theme. We welcome applications with a budget of or . One or two projects can therefore be funded. Projects start in .These interfaculty USO projects with a duration of to years have a cross-faculty character and are therefore submitted by more than one faculty. We only honour projects that are not funded by the primary education process.We want to reap the benefits of the project's revenues quickly and ask that the project description include an annual delivery of interim results.Double funding is obviously not possible. However, it is possible to further expand already funded (faculty) projects using this fund.ProcedureAn application is written by a consortium, led by a consortium leader. A consortium co-leadership is also a possibility.A meeting will be organised for anyone interested in this topic who might want to join a consortium or who would like to apply as a consortium leader. This meeting will take place on May, from :30am to pm in the Buys Ballot Building in room . This is a good opportunity to forge a consortium and select a consortium leader for this purpose. Of course, you are also free to shape this outside this meeting.During the meeting, you will be asked to share briefly how you are already working on Artificial Intelligence in education, and/or how you would like to contribute to a project.If you would like to contribute as a consortium member or leader, but cannot attend the meeting, you may send a message to cat.nl stating 'USO- Artificial Intelligence in Education', indicating how you would like to contribute to a project (as a consortium member, or leader; what activities would you like to contribute in the project?). We will share these during the meeting, allowing other participants to contact you to forge a consortium together.If you want to become a consortium member, please discuss this first with your education director and manager. Consortium leaders inform their education director, manager, vice dean of education and dean before applying. This is important because the proposal is ultimately submitted by the dean. Consortium leaders are asked to send in a motivation (300 words), reflection on the theme (300 words), teaching CV (max A4), project idea (max A4), amount to be applied for and description of the desired consortium composition and already affiliated consortium members via the form below by June at the latest.Based on this, the USO assessment committee will invite a limited number of consortium leaders to develop a proposal (deadline June). In doing so, the committee may also advise consortia to develop a joint proposal.The invited consortium leaders can explain their proposal in a pitch on July. Register as a consortium leader via this form external link\"],\n",
       " ['Project proposals will be assessed on the following criteria:Expected returns from the project (50%)Does the problem exploration convincingly explain in which educational component a change is desired and why?Does the applicant make a plausible case that the proposed innovation can lead to an improvement or a relevant yield (e.g. using relevant literature and examples from practice)?Are the intended outputs, such as learning outcomes, vision formation or concrete products, clearly described?Are the intended proceeds of added value for students and/or teachers? Do they contribute to knowledge and vision formation on the use of AI Chatbots in education?What is the scope of the project? How many students, teachers, programmes, faculties are reached?Does the applicant make a plausible case that the project could also be of interest to others, outside the consortium?Quality of the project plan (50%)Are the activities, methods used and planning in the project plan clearly defined and appropriate for achieving the intended benefits?Do the project plan, schedule and summary risk analysis convincingly demonstrate the feasibility of the project?Are the schedule and budget realistically prepared?Does the project team have the necessary expertise to carry out the project? Are the different roles and division of tasks clear and appropriate?Are project activities and outputs evaluated appropriately, using evaluation criteria and procedures?Is the dissemination plan (the plans for disseminating the results) appropriate and sufficiently ambitious?Timeline and forms23 May : information meeting and forming consortia6 June : deadline application form consortium leader external link June : deadline application form7 July : pitching of proposal to evaluation committeeSeptember December : Start of the project.Want to know more?Read more about the Utrecht Stimulation Fund for Education here or contact the Centre for Academic Teaching and Learning with questions at cat.nl.'],\n",
       " ['Artificial Intelligence (AI) has the potential to improve the quality of education. That, by definition, makes it interesting. AI is still developing, there is plenty to talk about and discuss. ChatGTP (a computer programme that allows you to have conversations), for instance, is one of the latest developments and raises the question among teachers whether giving an essay assignment to students will still be possible in the near future. Enough reason, therefore, to discuss this together!In this information session, we will start at the beginning: what exactly does AI mean? What are the recent developments and what impact does it have on education? We will discuss this with the three experts within the UU in this field. They will also give educational and practical tips on the application of AI in education and there will be plenty of room to ask the experts questions. Programme11:30 :50 What is AI? What are the recent developments and why is it relevant?By Prof dr. Antal van den Bosch external link12:00 :20 What are the limitations of ChatGPT? What exactly can it not do?By Prof. dr. ir. Jan Broersen external link12:30 :50 The implications and opportunities of AI the education system. Practical and educational tips and tools for your teaching.By Dr. Laura Koenders external linkLanguage: Dutch, questions can be asked in English. Workform: Information session'],\n",
       " ['In this information session, we will start at the beginning: what exactly does AI mean? What are the recent developments and what impact does it have on education? We will discuss this with the three experts within the UU in this field. They will also give educational and practical tips on the application of AI in education and there will be plenty of room to ask the experts questions. Programme11:30 :50 What is AI? What are the recent developments and why is it relevant?By Prof dr. Antal van den Bosch external link12:00 :20 What are the limitations of ChatGPT? What exactly can it not do?By Prof. dr. ir. Jan Broersen external link12:30 :50 The implications and opportunities of AI the education system. Practical and educational tips and tools for your teaching.By Dr. Laura Koenders external linkLanguage: Dutch, questions can be asked in English. Workform: Information session'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['During this duo presentation, professor Antal van den Bosch and assistant professor Dong Nguyen will discuss from their own different perspectives Humanities and Computer Science the impact of the latest Artificial Intelligence developments on linguistics and the field of digital humanities in general.The general current perspective from the field of Artificial Intelligence on language one of the most abundant and prominent products of the human mind can be summarised as an endless stream of very interesting data. The latest AI developments, Large Language Models such as ChatGPT, implement this view to the hilt trained on internet-scale amounts of language; their eye-catching capacity as stochastic parrots to generate text even seems to have brought Artificial General Intelligence a step closer.But does this extremely data-driven approach bring answering the grand old theoretical questions on language any closer? What is the role of theory in this data-driven age? And what is the impact of Large Language Models on fields like digital humanities, which are not as question-free like these models appear to be?'],\n",
       " [],\n",
       " ['On Thursday afternoon, February , Antal van den Bosch and Dong Nguyen will give a lecture on the impact of the latest developments in the field of Artificial Intelligence on linguistics and digital humanities. Anyone interested is welcome to sign up!From their different areas of expertise Humanities and Science Antal van den Bosch external link and Dong Nguyen external link will offer different perspectives. The general current perspective from the field of Artificial Intelligence on language one of the most abundant and prominent products of the human mind can be summarised as an endless stream of very interesting data. The latest AI developments, Large Language Models such as ChatGPT, implement this view to the hilt trained on internet-scale amounts of language; their eye-catching capacity as stochastic parrots to generate text even seems to have brought Artificial General Intelligence a step closer.But does this extremely data-driven approach bring answering the grand old theoretical questions on language any closer? What is the role of theory in this data-driven age? And what is the impact of Large Language Models on fields like digital humanities, which are not as question-free like these models appear to be?The CDH lecture Humanities and AI One answer to a million questions? external link can be followed on location and online. We encourage anyone who can, to come by on location in the University Library City Centre. Sign up here external link'],\n",
       " ['From their different areas of expertise Humanities and Science Antal van den Bosch external link and Dong Nguyen external link will offer different perspectives. The general current perspective from the field of Artificial Intelligence on language one of the most abundant and prominent products of the human mind can be summarised as an endless stream of very interesting data. The latest AI developments, Large Language Models such as ChatGPT, implement this view to the hilt trained on internet-scale amounts of language; their eye-catching capacity as stochastic parrots to generate text even seems to have brought Artificial General Intelligence a step closer.But does this extremely data-driven approach bring answering the grand old theoretical questions on language any closer? What is the role of theory in this data-driven age? And what is the impact of Large Language Models on fields like digital humanities, which are not as question-free like these models appear to be?The CDH lecture Humanities and AI One answer to a million questions? external link can be followed on location and online. We encourage anyone who can, to come by on location in the University Library City Centre. Sign up here external link'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['You would say that all this data can be used to train AI applications, so that those applications can make predictions about biological topics. But according to Abeln, it is not straightforward to apply the most powerful AI methods directly to biological data.Suppose a researcher wants to train an AI model to predict, based on genetic data, whether a particular animal will get sick. The researcher would need data from large numbers of examples of animals of the same species, both animals that got sick and those that did not. Abeln points out that phenotypic traits, observable traits such as whether an animal is sick or not, are often missing from data sets and that data sets contain insufficient numbers of examples. It is also very expensive to create good and complete datasets that contain the numbers of examples needed. Abeln and her colleagues are therefore looking for smart solutions that will allow current AI algorithms to be trained for biological data with fewer examples.'],\n",
       " ['Suppose a researcher wants to train an AI model to predict, based on genetic data, whether a particular animal will get sick. The researcher would need data from large numbers of examples of animals of the same species, both animals that got sick and those that did not. Abeln points out that phenotypic traits, observable traits such as whether an animal is sick or not, are often missing from data sets and that data sets contain insufficient numbers of examples. It is also very expensive to create good and complete datasets that contain the numbers of examples needed. Abeln and her colleagues are therefore looking for smart solutions that will allow current AI algorithms to be trained for biological data with fewer examples.'],\n",
       " [\"Utrecht University has appointed Sanne Abeln as Professor of AI Technology for Life. Abeln and her research group will focus on developing technology in the field of artificial intelligence (AI) with the aim of gaining more insight into complex biological systems, such as cells, organisms and ecosystems. In this way, Abeln and her colleagues form a bridge between the university's Department of Biology and Department of Information and Computing Science. Abeln will start on April.\"],\n",
       " [],\n",
       " [],\n",
       " ['here is already an AI application that is making a big impact in biology: AlphaFold. To function properly, proteins must fold into a specific three-dimensional structure. With AlphaFold, it is possible to predict this structure based on the sequence of amino acids that make up the protein. Before AlphaFold existed, it was common practice to determine the structure of a protein using expensive and time-consuming experimental techniques.Even though AlphaFold can predict the structure of a protein, biologists do not actually understand how the application does that. According to Abeln, AlphaFold therefore has not yet led to new insights about how proteins fold. Abeln: \"In our new group, we are going to work on AI applications that not only makes better predictions, but for which we can also explain how each prediction was made. On what aspects of the data does an AI model base its predictions? This is called explainable AI. More understanding about how predictions are created will lead to more understanding about complex biological systems.\"MultidisciplinaryAn example of a topic the group will focus on is the interaction between plants and microorganisms. Ultimately, this could lead to an AI application that predicts which combination of microorganisms in the soil will lead to the optimal growth and development of a particular plant.Members of the new chair group will collaborate with and contribute to the Utrecht Bioinformatics Center. Abeln\\'s team will be multidisciplinary, with some researchers focusing more on computing science and others more on biology. Abeln herself studied mathematics and computing science, received her PhD in bioinformatics at Oxford and then did a postdoc in biophysics. Abeln explains that her broad experience now comes in handy. Abeln: \"I actually still use all these disciplines in my research. You have to know something about a pretty large number of topics to be able to nuance these kinds of research questions.\"'],\n",
       " ['Even though AlphaFold can predict the structure of a protein, biologists do not actually understand how the application does that. According to Abeln, AlphaFold therefore has not yet led to new insights about how proteins fold. Abeln: \"In our new group, we are going to work on AI applications that not only makes better predictions, but for which we can also explain how each prediction was made. On what aspects of the data does an AI model base its predictions? This is called explainable AI. More understanding about how predictions are created will lead to more understanding about complex biological systems.\"MultidisciplinaryAn example of a topic the group will focus on is the interaction between plants and microorganisms. Ultimately, this could lead to an AI application that predicts which combination of microorganisms in the soil will lead to the optimal growth and development of a particular plant.Members of the new chair group will collaborate with and contribute to the Utrecht Bioinformatics Center. Abeln\\'s team will be multidisciplinary, with some researchers focusing more on computing science and others more on biology. Abeln herself studied mathematics and computing science, received her PhD in bioinformatics at Oxford and then did a postdoc in biophysics. Abeln explains that her broad experience now comes in handy. Abeln: \"I actually still use all these disciplines in my research. You have to know something about a pretty large number of topics to be able to nuance these kinds of research questions.\"'],\n",
       " ['An example of a topic the group will focus on is the interaction between plants and microorganisms. Ultimately, this could lead to an AI application that predicts which combination of microorganisms in the soil will lead to the optimal growth and development of a particular plant.Members of the new chair group will collaborate with and contribute to the Utrecht Bioinformatics Center. Abeln\\'s team will be multidisciplinary, with some researchers focusing more on computing science and others more on biology. Abeln herself studied mathematics and computing science, received her PhD in bioinformatics at Oxford and then did a postdoc in biophysics. Abeln explains that her broad experience now comes in handy. Abeln: \"I actually still use all these disciplines in my research. You have to know something about a pretty large number of topics to be able to nuance these kinds of research questions.\"'],\n",
       " ['A milestone for the online training course Compass: students from Utrecht University have worked on their information skills using the training course.Information skills help you to search for and use scientific information for your essay, assignment or thesis. Since the advent of the internet, and certainly with the development of AI tools such as ChatGPT, you come across more and more information and therefore also mis- and disinformation. It is becoming increasingly important to train yourself to find and use reliable information.It is also more complicated than it seems. After all, you know how to use Google and that Wikipedia isn\\'t always reliable, right? But do you also know that scientific sources from your field can often be found in specific databases? How to choose between one source and the other? And that there is an easy way to manage all your sources and cite them? The basics of information literacyCompass provides the basics of information literacy skills. You will learn with the help of assignments how and where to search for scientific sources and how to access them. But also how you can determine whether these sources are relevant and reliable and how you can easily store and use them during your studies. The modules consist of learning material and assignments where you have to apply the material. \"The assignments are fun and provide more practical insight,\" says one of the students who completed the module.'],\n",
       " ['Information skills help you to search for and use scientific information for your essay, assignment or thesis. Since the advent of the internet, and certainly with the development of AI tools such as ChatGPT, you come across more and more information and therefore also mis- and disinformation. It is becoming increasingly important to train yourself to find and use reliable information.It is also more complicated than it seems. After all, you know how to use Google and that Wikipedia isn\\'t always reliable, right? But do you also know that scientific sources from your field can often be found in specific databases? How to choose between one source and the other? And that there is an easy way to manage all your sources and cite them? The basics of information literacyCompass provides the basics of information literacy skills. You will learn with the help of assignments how and where to search for scientific sources and how to access them. But also how you can determine whether these sources are relevant and reliable and how you can easily store and use them during your studies. The modules consist of learning material and assignments where you have to apply the material. \"The assignments are fun and provide more practical insight,\" says one of the students who completed the module.'],\n",
       " ['Utrecht University has appointed five professors at the Department of Information and Computing Sciences. Each of the professorships involves an internal candidate. The appointments are part of a growth programme with extra attention to diversity. The same programme included the recent appointment of Massimo Poesio as Professor of Natural Language Understanding. The professorships will start on May , .The position of Professor of Data-Driven Interaction has been assigned to Egon L. van den Broek. Within this chair, data is collected and analyzed from various devices, such as smartphones, smartwatches and cars. The goal is to derive patterns that can help with medical issues. For example, data from sports watches can help research heart rhythm disorders and their prediction. Possible loneliness can be recognized with, among others, smartphone data on the number of contacts a person has. And a combination of data from video, speech, and other sources can teach artificial intelligence to recognize and respond to feelings. In doing so, it learns to act empathically, which in turn has all sorts of applications, including artificial intelligence as a therapist. Ethical issues, including data management and privacy are central to this research.Evolving software developmentFabiano Dalpiaz will hold the position of Professor of Software Production. Theories for software development are outdated, and important innovations are more often originating from companies and organizations than from academic research. Within this chair, in close cooperation with industry, these theories are investigated and evolved. How are large-scale software products developed? what factors determine software quality? which techniques are effective? And how to ethically develop software that embeds artificial intelligence? Ultimately, the goal is to help analysts and developers build modern, reliable software products.Models for language generation (such as ChatGPT)Albert Gatt has been appointed Professor of Natural Language Generation. Natural language generation (NLG) refers to software that produces natural language. A well-known example of such software is ChatGPT. NLG technology is also a part of translation and summarisation systems. An important area of focus of the research will be the relationship between language and vision. In other words, Gatt will be working on computer models that accurately translate videos and images into natural language. A second important area of focus is multilingualism. Gatt will look at how we can include other languages in NLG software, so that technologies enhance linguistic and cultural diversity.Decomposing musicAnja Volk has been appointed Professor of Music Information Computing. This field has gained tremendous momentum over the past thirty years due to the extensive digitization of musical data and the corresponding availability of digitized music collections. The goal of this field is to decompose music using computer models, in order to learn how people experience music. This has a variety of applications. For example, innovative music technology can improve the role music plays in therapeutic treatments and education. But it also helps improve streaming platforms by ensuring, for example, that satisfactory suggestions can be made toward users.Trustworthy AIPnar Yolum is an Associate Professor of Intelligent Systems and appointed Professor of Trustworthy Artificial Intelligence. The research focuses on the development of artificial intelligence systems that operate lawfully and ethically, for example by taking into account our standards and expectations of privacy. Because of its interdisciplinary nature, the chair works closely with other disciplines, including law, humanities, social sciences, software development and interaction technology.'],\n",
       " ['he position of Professor of Data-Driven Interaction has been assigned to Egon L. van den Broek. Within this chair, data is collected and analyzed from various devices, such as smartphones, smartwatches and cars. The goal is to derive patterns that can help with medical issues. For example, data from sports watches can help research heart rhythm disorders and their prediction. Possible loneliness can be recognized with, among others, smartphone data on the number of contacts a person has. And a combination of data from video, speech, and other sources can teach artificial intelligence to recognize and respond to feelings. In doing so, it learns to act empathically, which in turn has all sorts of applications, including artificial intelligence as a therapist. Ethical issues, including data management and privacy are central to this research.Evolving software developmentFabiano Dalpiaz will hold the position of Professor of Software Production. Theories for software development are outdated, and important innovations are more often originating from companies and organizations than from academic research. Within this chair, in close cooperation with industry, these theories are investigated and evolved. How are large-scale software products developed? what factors determine software quality? which techniques are effective? And how to ethically develop software that embeds artificial intelligence? Ultimately, the goal is to help analysts and developers build modern, reliable software products.Models for language generation (such as ChatGPT)Albert Gatt has been appointed Professor of Natural Language Generation. Natural language generation (NLG) refers to software that produces natural language. A well-known example of such software is ChatGPT. NLG technology is also a part of translation and summarisation systems. An important area of focus of the research will be the relationship between language and vision. In other words, Gatt will be working on computer models that accurately translate videos and images into natural language. A second important area of focus is multilingualism. Gatt will look at how we can include other languages in NLG software, so that technologies enhance linguistic and cultural diversity.Decomposing musicAnja Volk has been appointed Professor of Music Information Computing. This field has gained tremendous momentum over the past thirty years due to the extensive digitization of musical data and the corresponding availability of digitized music collections. The goal of this field is to decompose music using computer models, in order to learn how people experience music. This has a variety of applications. For example, innovative music technology can improve the role music plays in therapeutic treatments and education. But it also helps improve streaming platforms by ensuring, for example, that satisfactory suggestions can be made toward users.Trustworthy AIPnar Yolum is an Associate Professor of Intelligent Systems and appointed Professor of Trustworthy Artificial Intelligence. The research focuses on the development of artificial intelligence systems that operate lawfully and ethically, for example by taking into account our standards and expectations of privacy. Because of its interdisciplinary nature, the chair works closely with other disciplines, including law, humanities, social sciences, software development and interaction technology.'],\n",
       " ['Fabiano Dalpiaz will hold the position of Professor of Software Production. Theories for software development are outdated, and important innovations are more often originating from companies and organizations than from academic research. Within this chair, in close cooperation with industry, these theories are investigated and evolved. How are large-scale software products developed? what factors determine software quality? which techniques are effective? And how to ethically develop software that embeds artificial intelligence? Ultimately, the goal is to help analysts and developers build modern, reliable software products.Models for language generation (such as ChatGPT)Albert Gatt has been appointed Professor of Natural Language Generation. Natural language generation (NLG) refers to software that produces natural language. A well-known example of such software is ChatGPT. NLG technology is also a part of translation and summarisation systems. An important area of focus of the research will be the relationship between language and vision. In other words, Gatt will be working on computer models that accurately translate videos and images into natural language. A second important area of focus is multilingualism. Gatt will look at how we can include other languages in NLG software, so that technologies enhance linguistic and cultural diversity.Decomposing musicAnja Volk has been appointed Professor of Music Information Computing. This field has gained tremendous momentum over the past thirty years due to the extensive digitization of musical data and the corresponding availability of digitized music collections. The goal of this field is to decompose music using computer models, in order to learn how people experience music. This has a variety of applications. For example, innovative music technology can improve the role music plays in therapeutic treatments and education. But it also helps improve streaming platforms by ensuring, for example, that satisfactory suggestions can be made toward users.Trustworthy AIPnar Yolum is an Associate Professor of Intelligent Systems and appointed Professor of Trustworthy Artificial Intelligence. The research focuses on the development of artificial intelligence systems that operate lawfully and ethically, for example by taking into account our standards and expectations of privacy. Because of its interdisciplinary nature, the chair works closely with other disciplines, including law, humanities, social sciences, software development and interaction technology.'],\n",
       " ['Albert Gatt has been appointed Professor of Natural Language Generation. Natural language generation (NLG) refers to software that produces natural language. A well-known example of such software is ChatGPT. NLG technology is also a part of translation and summarisation systems. An important area of focus of the research will be the relationship between language and vision. In other words, Gatt will be working on computer models that accurately translate videos and images into natural language. A second important area of focus is multilingualism. Gatt will look at how we can include other languages in NLG software, so that technologies enhance linguistic and cultural diversity.Decomposing musicAnja Volk has been appointed Professor of Music Information Computing. This field has gained tremendous momentum over the past thirty years due to the extensive digitization of musical data and the corresponding availability of digitized music collections. The goal of this field is to decompose music using computer models, in order to learn how people experience music. This has a variety of applications. For example, innovative music technology can improve the role music plays in therapeutic treatments and education. But it also helps improve streaming platforms by ensuring, for example, that satisfactory suggestions can be made toward users.Trustworthy AIPnar Yolum is an Associate Professor of Intelligent Systems and appointed Professor of Trustworthy Artificial Intelligence. The research focuses on the development of artificial intelligence systems that operate lawfully and ethically, for example by taking into account our standards and expectations of privacy. Because of its interdisciplinary nature, the chair works closely with other disciplines, including law, humanities, social sciences, software development and interaction technology.'],\n",
       " [],\n",
       " ['What do you get when you throw AI and Serious Games together on a field in Groningen and a classroom in Utrecht? A unique workshop called \"Playing with Intelligence\" on April , , between :00-17:00 in space , Bolognalaan , Utrecht. Afterwards there will be drinks in the Basket.During the workshop you will get (further) acquainted with ChatGPT and discover its wonderful possibilities in designing serious games. In this workshop we focus on \\'ChatGPT-powered (serious) game design\\' and you get the chance to experience hands-on how this tool can be used to develop your own educational and entertaining game.But that\\'s not all! With the help of ChatGPT, you will get hands-on to redesign the game \"GRUNN, pioneers in the province.\" This game brings the history of the province of Groningen to the attention of young people in a new, accessible way. By using the tiles, you build your own province and discover different types of landscape such as peat and salt marshes, raise mounds, build churches and farms, create polders and construct waterways and villages.What do you want to make of GRUNN? Do you want to focus on regional expansion into, say, Drenthe, do you prefer to focus on the characters, or do you think a GRUNN-Star Wars edition is actually the most logical step? Playing with Intelligence offers you the opportunity to put your imagination directly into practice.This workshop is organized by simulation and gaming association SAGANET and is intended for UU employees and members of SAGANET. The workshop \"Playing with Intelligence,\" given by experienced game designers and AI enthusiasts Arjan van Houwelingen of Hanze University of Applied Sciences and Tim Goudriaan of AI-Advies & Training.Sign up on the SAGANET website here. The maximum number of participants is . Technical knowledge or any understanding of serious game design and AI are NOT required or necessary for participation.Preparation: Bring a laptop, and make sure you (ideally) have your own account at chat.openai.com.'],\n",
       " ['During the workshop you will get (further) acquainted with ChatGPT and discover its wonderful possibilities in designing serious games. In this workshop we focus on \\'ChatGPT-powered (serious) game design\\' and you get the chance to experience hands-on how this tool can be used to develop your own educational and entertaining game.But that\\'s not all! With the help of ChatGPT, you will get hands-on to redesign the game \"GRUNN, pioneers in the province.\" This game brings the history of the province of Groningen to the attention of young people in a new, accessible way. By using the tiles, you build your own province and discover different types of landscape such as peat and salt marshes, raise mounds, build churches and farms, create polders and construct waterways and villages.What do you want to make of GRUNN? Do you want to focus on regional expansion into, say, Drenthe, do you prefer to focus on the characters, or do you think a GRUNN-Star Wars edition is actually the most logical step? Playing with Intelligence offers you the opportunity to put your imagination directly into practice.This workshop is organized by simulation and gaming association SAGANET and is intended for UU employees and members of SAGANET. The workshop \"Playing with Intelligence,\" given by experienced game designers and AI enthusiasts Arjan van Houwelingen of Hanze University of Applied Sciences and Tim Goudriaan of AI-Advies & Training.Sign up on the SAGANET website here. The maximum number of participants is . Technical knowledge or any understanding of serious game design and AI are NOT required or necessary for participation.Preparation: Bring a laptop, and make sure you (ideally) have your own account at chat.openai.com.'],\n",
       " ['But that\\'s not all! With the help of ChatGPT, you will get hands-on to redesign the game \"GRUNN, pioneers in the province.\" This game brings the history of the province of Groningen to the attention of young people in a new, accessible way. By using the tiles, you build your own province and discover different types of landscape such as peat and salt marshes, raise mounds, build churches and farms, create polders and construct waterways and villages.What do you want to make of GRUNN? Do you want to focus on regional expansion into, say, Drenthe, do you prefer to focus on the characters, or do you think a GRUNN-Star Wars edition is actually the most logical step? Playing with Intelligence offers you the opportunity to put your imagination directly into practice.This workshop is organized by simulation and gaming association SAGANET and is intended for UU employees and members of SAGANET. The workshop \"Playing with Intelligence,\" given by experienced game designers and AI enthusiasts Arjan van Houwelingen of Hanze University of Applied Sciences and Tim Goudriaan of AI-Advies & Training.Sign up on the SAGANET website here. The maximum number of participants is . Technical knowledge or any understanding of serious game design and AI are NOT required or necessary for participation.Preparation: Bring a laptop, and make sure you (ideally) have your own account at chat.openai.com.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [\"his session is part of the DevelopMEvent external link taking place from to April.Have you always wanted to experiment with ChatGPT? Or are you getting excited and want to know more about what it can and cannot do? Explore with us the possibilities and limitations of the AI chatbot. Together we will look at where Chatbots are good at and where they still have a lot to learn, so we can experience how it can be used well and when it isn't useful. After the workshop, you are able to decide when and where to use chatbots in your work.This working language of this session will be English and the session will be given by:\"],\n",
       " [\"Have you always wanted to experiment with ChatGPT? Or are you getting excited and want to know more about what it can and cannot do? Explore with us the possibilities and limitations of the AI chatbot. Together we will look at where Chatbots are good at and where they still have a lot to learn, so we can experience how it can be used well and when it isn't useful. After the workshop, you are able to decide when and where to use chatbots in your work.This working language of this session will be English and the session will be given by:\"],\n",
       " [],\n",
       " ['Can you check whether students used ChatGPT? The short answer is: no, you currently cannot do so. The plagiarism checkers work based on recognising exact sections of text, and ChatGPT generates new text. Other than plagiarism checkers, you can also use proctoring software, but the use of this means you will end up in a cat-and-mouse game in which you will likely lag behind with the proctoring software. As such, there is currently no known way to prove the use of ChatGPT in an assessment. You should also consider what you formally could do as an examiner with a probability percentage on the use of ChatGPT. During COVID it has been suggested to do spot checks with oral exams in addition to a take-home exam, which we could also do now. However, then as well as now it was difficult to determine which consequences a below average performance on the oral exam should have. Is this truly evidence that the student has not handed in their own work? Thus, we currently advise lectures to focus on the design phase of assessment when trying to overcome the adverse effects of ChatGPTs existence. For teaching writing (theses and essays) there are some options for monitoring the writing process more closely, to see if a student has handed in their own work. In supervision meetings, you can discuss the line of reasoning used in the submitted text as well as the steps the student used in their learning process, along with the usual discussion of supervisor feedback. This can show whether the student has gained knowledge on the subject matter and has actually improved themselves. It is also likely to improve the learning process. Indicate in advance that this is how you will fill in the supervisions meetings, this could have a preventative effect. Conclusion Exam committees and examiners would of course want to know whether students have submitted their own work. Unreported use of a chatbot to generate texts is fraud. Students should be well aware of this. The design phase of assessment offers the most options for limiting the effects of the use of ChatGPT.'],\n",
       " ['You should also consider what you formally could do as an examiner with a probability percentage on the use of ChatGPT. During COVID it has been suggested to do spot checks with oral exams in addition to a take-home exam, which we could also do now. However, then as well as now it was difficult to determine which consequences a below average performance on the oral exam should have. Is this truly evidence that the student has not handed in their own work? Thus, we currently advise lectures to focus on the design phase of assessment when trying to overcome the adverse effects of ChatGPTs existence. For teaching writing (theses and essays) there are some options for monitoring the writing process more closely, to see if a student has handed in their own work. In supervision meetings, you can discuss the line of reasoning used in the submitted text as well as the steps the student used in their learning process, along with the usual discussion of supervisor feedback. This can show whether the student has gained knowledge on the subject matter and has actually improved themselves. It is also likely to improve the learning process. Indicate in advance that this is how you will fill in the supervisions meetings, this could have a preventative effect. Conclusion Exam committees and examiners would of course want to know whether students have submitted their own work. Unreported use of a chatbot to generate texts is fraud. Students should be well aware of this. The design phase of assessment offers the most options for limiting the effects of the use of ChatGPT.'],\n",
       " ['For teaching writing (theses and essays) there are some options for monitoring the writing process more closely, to see if a student has handed in their own work. In supervision meetings, you can discuss the line of reasoning used in the submitted text as well as the steps the student used in their learning process, along with the usual discussion of supervisor feedback. This can show whether the student has gained knowledge on the subject matter and has actually improved themselves. It is also likely to improve the learning process. Indicate in advance that this is how you will fill in the supervisions meetings, this could have a preventative effect. Conclusion Exam committees and examiners would of course want to know whether students have submitted their own work. Unreported use of a chatbot to generate texts is fraud. Students should be well aware of this. The design phase of assessment offers the most options for limiting the effects of the use of ChatGPT.'],\n",
       " [],\n",
       " ['ip: Enter the assignment/take-home exam into ChatGPT and see what the result is. But beware: the chatbot will construct a unique answer every time. Thus students will not generate the same result. If you click on regenerate response multiple times, you will get different variants. This should give you an idea on the possibilities of the chatbot. These generated examples can also function as a nice input for a calibration session.'],\n",
       " ['Currently, ChatGPT has some limitations related to the functionality of the chatbot and the way it was trained. You can use this when designing your take-home exam or essay assignment. You can find some suggestions below. But beware, the application is self-learning, and there is no guarantee that these limitations are still in place after a week/month/half year. Focus on content instead of structure and writing style when formulating questions.ChatGPT makes mistakes in content, but which are written convincingly. Thus, you can focus on content in your assessment, and have structure and writing style (things the chatbot does very well) less heavily. This has a few disadvantages: firstly, you are tampering with your learning goals. And secondly, it is possible that the level of the assessment changes, i.e. becomes more difficult. This is evidently not desirable.Have students reflect on current events in the exam. Currently, ChatGPT only has access to information up to . If you design an essay assignment where you can relate a theory to current events, the chatbot will produce an error. Beware, this is circumventable by copy-pasting a recent article into the chatbot and asking it to take it into account for the answer. Focus your exam questions on recent articles or articles behind a paywall. The same limitation applies to recent articles, those written after . The chatbot also does not use articles behind a paywall, provided they are not available elsewhere on the web. As such, it is worth the effort to see whether ChatGPT can reproduce information from an article or not. Unfortunately, this method is also circumventable by copy-pasting an article into the chatbot.Ask for personal reflection in your exam, or ask questions on the writing process. ChatGPT can make personal reflectons, but these will remain generic and will evidently not fit the person who is generating them. State on the exam (and in the course manual and lecture slides) that students must submit their own work. Indicate that they must properly reference their sources. Also indicate which tools they can (e.g. statistical tools such as SPSS) and cannot use (e.g. ChatGPT) for the assessment.'],\n",
       " ['ChatGPT makes mistakes in content, but which are written convincingly. Thus, you can focus on content in your assessment, and have structure and writing style (things the chatbot does very well) less heavily. This has a few disadvantages: firstly, you are tampering with your learning goals. And secondly, it is possible that the level of the assessment changes, i.e. becomes more difficult. This is evidently not desirable.Have students reflect on current events in the exam. Currently, ChatGPT only has access to information up to . If you design an essay assignment where you can relate a theory to current events, the chatbot will produce an error. Beware, this is circumventable by copy-pasting a recent article into the chatbot and asking it to take it into account for the answer. Focus your exam questions on recent articles or articles behind a paywall. The same limitation applies to recent articles, those written after . The chatbot also does not use articles behind a paywall, provided they are not available elsewhere on the web. As such, it is worth the effort to see whether ChatGPT can reproduce information from an article or not. Unfortunately, this method is also circumventable by copy-pasting an article into the chatbot.Ask for personal reflection in your exam, or ask questions on the writing process. ChatGPT can make personal reflectons, but these will remain generic and will evidently not fit the person who is generating them. State on the exam (and in the course manual and lecture slides) that students must submit their own work. Indicate that they must properly reference their sources. Also indicate which tools they can (e.g. statistical tools such as SPSS) and cannot use (e.g. ChatGPT) for the assessment.'],\n",
       " ['Currently, ChatGPT only has access to information up to . If you design an essay assignment where you can relate a theory to current events, the chatbot will produce an error. Beware, this is circumventable by copy-pasting a recent article into the chatbot and asking it to take it into account for the answer. Focus your exam questions on recent articles or articles behind a paywall. The same limitation applies to recent articles, those written after . The chatbot also does not use articles behind a paywall, provided they are not available elsewhere on the web. As such, it is worth the effort to see whether ChatGPT can reproduce information from an article or not. Unfortunately, this method is also circumventable by copy-pasting an article into the chatbot.Ask for personal reflection in your exam, or ask questions on the writing process. ChatGPT can make personal reflectons, but these will remain generic and will evidently not fit the person who is generating them. State on the exam (and in the course manual and lecture slides) that students must submit their own work. Indicate that they must properly reference their sources. Also indicate which tools they can (e.g. statistical tools such as SPSS) and cannot use (e.g. ChatGPT) for the assessment.'],\n",
       " ['he same limitation applies to recent articles, those written after . The chatbot also does not use articles behind a paywall, provided they are not available elsewhere on the web. As such, it is worth the effort to see whether ChatGPT can reproduce information from an article or not. Unfortunately, this method is also circumventable by copy-pasting an article into the chatbot.Ask for personal reflection in your exam, or ask questions on the writing process. ChatGPT can make personal reflectons, but these will remain generic and will evidently not fit the person who is generating them. State on the exam (and in the course manual and lecture slides) that students must submit their own work. Indicate that they must properly reference their sources. Also indicate which tools they can (e.g. statistical tools such as SPSS) and cannot use (e.g. ChatGPT) for the assessment.'],\n",
       " ['ChatGPT can make personal reflectons, but these will remain generic and will evidently not fit the person who is generating them. State on the exam (and in the course manual and lecture slides) that students must submit their own work. Indicate that they must properly reference their sources. Also indicate which tools they can (e.g. statistical tools such as SPSS) and cannot use (e.g. ChatGPT) for the assessment.'],\n",
       " ['he Education and Examination Regulations (EER of Utrecht University at least) do not need to be changed as the current EER suffices. It states that: \"Fraud and plagiarism are defined as an action or omission on the part of students, which produces an incorrect representation of their own performance as regards their knowledge, skills, and understanding, which may result in the examiner no longer being able to assess the knowledge or ability of the students in a proper and fair manner.\" At most you could mention by way of example that the unreported use of ChatGPT will be marked as fraud/plagiarism.'],\n",
       " ['When discussing the use of ChatGPT in the article above, we are talking about generating a text and handing it in as your own work. This is of course not acceptable. However, there is a different use of ChatGPT possible. ChatGPT can be used as a tool in the way that Google or Wikipedia are currently being used. The questions that this raises are: which use do we find acceptable? Which use is unacceptable? Is less use acceptable in assessment than during learning? And if we do allow the use (to a greater or lesser extent): what will students learn less well? In other words: which skills are we outsourcing? And is this a problem? Should students still learn to write? And what does this mean for the final attainment goals of our programmes? There are also major ethical and moral objections to the use of ChatGPT, which you can read about in this article external link. To what extent do we facilitate or even encourage the use of this tool? Finally, read how ChatGPT responds external link to these varied concerns.'],\n",
       " ['And if we do allow the use (to a greater or lesser extent): what will students learn less well? In other words: which skills are we outsourcing? And is this a problem? Should students still learn to write? And what does this mean for the final attainment goals of our programmes? There are also major ethical and moral objections to the use of ChatGPT, which you can read about in this article external link. To what extent do we facilitate or even encourage the use of this tool? Finally, read how ChatGPT responds external link to these varied concerns.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['If you are going to change the design of your assessment, it is important to start with your learning goals. The type of learning goal determines which options you will have when changing your assessment. Within this context we can distinguish between two types of learning goals:Learning goals concerning writing skills, argumentative skills, etc. I.e. learning goals covering those aspects that ChatGTP does well. All other learning goals. . Learning goals concerning aspects that ChatGPT is good atWith this we mean writing assignments given to test how a student constructs sentences, summarises, finds the key points of a text, creates structure, etc. These are exactly those aspects that ChatGPT excels at. Should a student commit fraud in this aspect, it is hard to find out and you cannot be sure if the student has mastered these learning goals. Suppose that your course revolves around these learning goals, and you want to be sure that a student masters these skills. Which options are available to you? You can have students write sections in a controlled environment, as is the case when taking exams. Be sure to plan this well in advance. It is also possible to have them write sections during your class. You can also have the content be weighed more heavily as ChatGPT makes mistakes when it comes to content. Note: you are changing the learning goals, and thus the level of difficulty of your assessment. A few points for perspective: Students always had the ability to use a ghost writer for take-home exams, essays en theses (for instance parents, brothers/sisters, etc.) to write or improve their texts for them. From this perspective, ChatGPT is maybe just a more easily accessible form of ghost writer, but in the end, not that novel a concept. Most students understand that handing in work written by ChatGPT is considered fraud, and that they learn very little by doing so. Automatically assuming that all students will commit fraud, when possible, leads to a controlling strategy and eventually a cat-and-mouse game between plagiarism software and chatbots. Within higher education, skills such as making sentences, creating structure, and summarising are important building blocks that lead to advanced writing skills. For their thesis, students should be able to write texts that directly relate to their research, or in which the information is integrated and critically reviewed. In the end, students will have to be able to write.'],\n",
       " ['With this we mean writing assignments given to test how a student constructs sentences, summarises, finds the key points of a text, creates structure, etc. These are exactly those aspects that ChatGPT excels at. Should a student commit fraud in this aspect, it is hard to find out and you cannot be sure if the student has mastered these learning goals. Suppose that your course revolves around these learning goals, and you want to be sure that a student masters these skills. Which options are available to you? You can have students write sections in a controlled environment, as is the case when taking exams. Be sure to plan this well in advance. It is also possible to have them write sections during your class. You can also have the content be weighed more heavily as ChatGPT makes mistakes when it comes to content. Note: you are changing the learning goals, and thus the level of difficulty of your assessment. A few points for perspective: Students always had the ability to use a ghost writer for take-home exams, essays en theses (for instance parents, brothers/sisters, etc.) to write or improve their texts for them. From this perspective, ChatGPT is maybe just a more easily accessible form of ghost writer, but in the end, not that novel a concept. Most students understand that handing in work written by ChatGPT is considered fraud, and that they learn very little by doing so. Automatically assuming that all students will commit fraud, when possible, leads to a controlling strategy and eventually a cat-and-mouse game between plagiarism software and chatbots. Within higher education, skills such as making sentences, creating structure, and summarising are important building blocks that lead to advanced writing skills. For their thesis, students should be able to write texts that directly relate to their research, or in which the information is integrated and critically reviewed. In the end, students will have to be able to write.'],\n",
       " ['Suppose that your course revolves around these learning goals, and you want to be sure that a student masters these skills. Which options are available to you? You can have students write sections in a controlled environment, as is the case when taking exams. Be sure to plan this well in advance. It is also possible to have them write sections during your class. You can also have the content be weighed more heavily as ChatGPT makes mistakes when it comes to content. Note: you are changing the learning goals, and thus the level of difficulty of your assessment. A few points for perspective: Students always had the ability to use a ghost writer for take-home exams, essays en theses (for instance parents, brothers/sisters, etc.) to write or improve their texts for them. From this perspective, ChatGPT is maybe just a more easily accessible form of ghost writer, but in the end, not that novel a concept. Most students understand that handing in work written by ChatGPT is considered fraud, and that they learn very little by doing so. Automatically assuming that all students will commit fraud, when possible, leads to a controlling strategy and eventually a cat-and-mouse game between plagiarism software and chatbots. Within higher education, skills such as making sentences, creating structure, and summarising are important building blocks that lead to advanced writing skills. For their thesis, students should be able to write texts that directly relate to their research, or in which the information is integrated and critically reviewed. In the end, students will have to be able to write.'],\n",
       " ['You can also have the content be weighed more heavily as ChatGPT makes mistakes when it comes to content. Note: you are changing the learning goals, and thus the level of difficulty of your assessment. A few points for perspective: Students always had the ability to use a ghost writer for take-home exams, essays en theses (for instance parents, brothers/sisters, etc.) to write or improve their texts for them. From this perspective, ChatGPT is maybe just a more easily accessible form of ghost writer, but in the end, not that novel a concept. Most students understand that handing in work written by ChatGPT is considered fraud, and that they learn very little by doing so. Automatically assuming that all students will commit fraud, when possible, leads to a controlling strategy and eventually a cat-and-mouse game between plagiarism software and chatbots. Within higher education, skills such as making sentences, creating structure, and summarising are important building blocks that lead to advanced writing skills. For their thesis, students should be able to write texts that directly relate to their research, or in which the information is integrated and critically reviewed. In the end, students will have to be able to write.'],\n",
       " ['A few points for perspective: Students always had the ability to use a ghost writer for take-home exams, essays en theses (for instance parents, brothers/sisters, etc.) to write or improve their texts for them. From this perspective, ChatGPT is maybe just a more easily accessible form of ghost writer, but in the end, not that novel a concept. Most students understand that handing in work written by ChatGPT is considered fraud, and that they learn very little by doing so. Automatically assuming that all students will commit fraud, when possible, leads to a controlling strategy and eventually a cat-and-mouse game between plagiarism software and chatbots. Within higher education, skills such as making sentences, creating structure, and summarising are important building blocks that lead to advanced writing skills. For their thesis, students should be able to write texts that directly relate to their research, or in which the information is integrated and critically reviewed. In the end, students will have to be able to write.'],\n",
       " [],\n",
       " ['Much is said and written about the Open AI tool ChatGPT. The tool has both fans and opponents, with varying opinions. But that the tool will have consequences for education, is without a doubt. To understand what these consequences are (both positive and negative), it is useful to understand how ChatGPT works, what its abilities are, and what not. What is ChatGPT?ChatGPT is a chatbot based on a Large Language Model (LLM). That means you can ask a question (prompt) and ChatGPT will write a text for it. This ranges from writing a limerick to writing scientific articles. To generate text, ChatGPT does not need to understand the prompt (and the answer). Instead, the prompt gives the chatbot a context within which it will use probability to see which words best line up, forming sentences. It generates new unique text and does not show existing texts (like ordinary search engines). It is therefore not possible to check the authenticity of texts with plagiarism software.What is ChatGPT capable of?ChatGPT\\'s capabilities can be roughly divided into three categories. You can ask a question, and ChatGPT answers it. This usage is similar to giving a command to Google. The difference is that Google produces sources from which you have to extract the information yourself. ChatGPT is more efficient and produces a written-out answer, the disadvantage is that it is not easy to verify if the answer is true and what it bases it on. You can ask to generate a piece of text, for example an outline or a reflection on a particular topic. The question can include what length and writing style the piece should be. You can also ask for sources to be cited. If you ask it outright, it will include fabricated sources, but you can specify that you want only \\'real sources\\'. In that case, the chatbot will provide real sources, but be aware these will still not always be accurate. You can enter pieces of text and ask the chatbot to summarise, paraphrase, translate, remove spelling mistakes, give feedback on them, etc. ChatGPT predicts well what kind of answer we want to get. So even though the chatbot does not fully understand the questions and the generated answers, it is still capable to create a logical structure, as is shown in this study in which ChatGPT scores a on a Dutch secondary school (vwo) exam on reading comprehension in English.Moreover, text generation is only one of the software\\'s capabilities. Within the playground of OpenAI there are possibilities to convert a prompt to software code or have an illustration generated. Conversely, you can enter code and ask what it does. See this example for an illustration external link. Additionally, part of the source code is publicly available, therefore different add-ons are created, for example to link to Excel, Gmail, R, Youtube or Whatsapp. This gives an indication of the broad implications we can expect. What can ChatGPT not do? Incorrect referencingChatGPT uses probability theory to compose an answer based on numerous sources. It does this when compiling pieces of text, as well as when compiling a simple factual answer to a question. This means you can never identify all of the sources that were used for the output. This makes ChatGPT\\'s answer non-transparent, difficult to verify, and makes proper and complete source citation (and compliance with copy-right) impossible. If you ask ChatGPT to provide the sources used to generate an answer, the chatbot often fabricates non-existent sources. You can ask for \"real\" and \"peer-reviewed\" sources, then you will usually get existing and applicable sources, but they will not contain all the data on which it bases an answer. These are obviously major drawbacks within the scientific community. Falsehoods and biasesAnother major drawback of ChatGPT is in the training data used to develop the model. First, there are biases in data, and following the old \"garbage-in-garbage-out\" principle, the chatbot\\'s output depends on the training data, and there is a good chance that ChatGPT\\'s answers will reflect these biases. For example, it is clear from ChatGPT\\'s predecessor (GPT-3) that there were gender-stereotypical associations external link in the answers. OpenAI, the company behind ChatGPT, implements filters and human verification to extract obvious falsehoods and the most severe biases. However, this remains an inherent limitation. Outdated dataThe current version of ChatGPT (January ) is only trained on data through September . This means that the chatbot cannot interpret more recent data. This limitation probably will be short-lived; developments are rapid. Calculation errorsFinally, the chatbot (in addition to content errors) also makes computational and logic errors. Again, this has to do with how ChatGPT generates answers. It is a language model, not a calculator: text is generated in response to mathematical questions, but the outcome is a random number based on human preference for numbers external link.'],\n",
       " ['ChatGPT is a chatbot based on a Large Language Model (LLM). That means you can ask a question (prompt) and ChatGPT will write a text for it. This ranges from writing a limerick to writing scientific articles. To generate text, ChatGPT does not need to understand the prompt (and the answer). Instead, the prompt gives the chatbot a context within which it will use probability to see which words best line up, forming sentences. It generates new unique text and does not show existing texts (like ordinary search engines). It is therefore not possible to check the authenticity of texts with plagiarism software.What is ChatGPT capable of?ChatGPT\\'s capabilities can be roughly divided into three categories. You can ask a question, and ChatGPT answers it. This usage is similar to giving a command to Google. The difference is that Google produces sources from which you have to extract the information yourself. ChatGPT is more efficient and produces a written-out answer, the disadvantage is that it is not easy to verify if the answer is true and what it bases it on. You can ask to generate a piece of text, for example an outline or a reflection on a particular topic. The question can include what length and writing style the piece should be. You can also ask for sources to be cited. If you ask it outright, it will include fabricated sources, but you can specify that you want only \\'real sources\\'. In that case, the chatbot will provide real sources, but be aware these will still not always be accurate. You can enter pieces of text and ask the chatbot to summarise, paraphrase, translate, remove spelling mistakes, give feedback on them, etc. ChatGPT predicts well what kind of answer we want to get. So even though the chatbot does not fully understand the questions and the generated answers, it is still capable to create a logical structure, as is shown in this study in which ChatGPT scores a on a Dutch secondary school (vwo) exam on reading comprehension in English.Moreover, text generation is only one of the software\\'s capabilities. Within the playground of OpenAI there are possibilities to convert a prompt to software code or have an illustration generated. Conversely, you can enter code and ask what it does. See this example for an illustration external link. Additionally, part of the source code is publicly available, therefore different add-ons are created, for example to link to Excel, Gmail, R, Youtube or Whatsapp. This gives an indication of the broad implications we can expect. What can ChatGPT not do? Incorrect referencingChatGPT uses probability theory to compose an answer based on numerous sources. It does this when compiling pieces of text, as well as when compiling a simple factual answer to a question. This means you can never identify all of the sources that were used for the output. This makes ChatGPT\\'s answer non-transparent, difficult to verify, and makes proper and complete source citation (and compliance with copy-right) impossible. If you ask ChatGPT to provide the sources used to generate an answer, the chatbot often fabricates non-existent sources. You can ask for \"real\" and \"peer-reviewed\" sources, then you will usually get existing and applicable sources, but they will not contain all the data on which it bases an answer. These are obviously major drawbacks within the scientific community. Falsehoods and biasesAnother major drawback of ChatGPT is in the training data used to develop the model. First, there are biases in data, and following the old \"garbage-in-garbage-out\" principle, the chatbot\\'s output depends on the training data, and there is a good chance that ChatGPT\\'s answers will reflect these biases. For example, it is clear from ChatGPT\\'s predecessor (GPT-3) that there were gender-stereotypical associations external link in the answers. OpenAI, the company behind ChatGPT, implements filters and human verification to extract obvious falsehoods and the most severe biases. However, this remains an inherent limitation. Outdated dataThe current version of ChatGPT (January ) is only trained on data through September . This means that the chatbot cannot interpret more recent data. This limitation probably will be short-lived; developments are rapid. Calculation errorsFinally, the chatbot (in addition to content errors) also makes computational and logic errors. Again, this has to do with how ChatGPT generates answers. It is a language model, not a calculator: text is generated in response to mathematical questions, but the outcome is a random number based on human preference for numbers external link.'],\n",
       " ['ChatGPT\\'s capabilities can be roughly divided into three categories. You can ask a question, and ChatGPT answers it. This usage is similar to giving a command to Google. The difference is that Google produces sources from which you have to extract the information yourself. ChatGPT is more efficient and produces a written-out answer, the disadvantage is that it is not easy to verify if the answer is true and what it bases it on. You can ask to generate a piece of text, for example an outline or a reflection on a particular topic. The question can include what length and writing style the piece should be. You can also ask for sources to be cited. If you ask it outright, it will include fabricated sources, but you can specify that you want only \\'real sources\\'. In that case, the chatbot will provide real sources, but be aware these will still not always be accurate. You can enter pieces of text and ask the chatbot to summarise, paraphrase, translate, remove spelling mistakes, give feedback on them, etc. ChatGPT predicts well what kind of answer we want to get. So even though the chatbot does not fully understand the questions and the generated answers, it is still capable to create a logical structure, as is shown in this study in which ChatGPT scores a on a Dutch secondary school (vwo) exam on reading comprehension in English.Moreover, text generation is only one of the software\\'s capabilities. Within the playground of OpenAI there are possibilities to convert a prompt to software code or have an illustration generated. Conversely, you can enter code and ask what it does. See this example for an illustration external link. Additionally, part of the source code is publicly available, therefore different add-ons are created, for example to link to Excel, Gmail, R, Youtube or Whatsapp. This gives an indication of the broad implications we can expect. What can ChatGPT not do? Incorrect referencingChatGPT uses probability theory to compose an answer based on numerous sources. It does this when compiling pieces of text, as well as when compiling a simple factual answer to a question. This means you can never identify all of the sources that were used for the output. This makes ChatGPT\\'s answer non-transparent, difficult to verify, and makes proper and complete source citation (and compliance with copy-right) impossible. If you ask ChatGPT to provide the sources used to generate an answer, the chatbot often fabricates non-existent sources. You can ask for \"real\" and \"peer-reviewed\" sources, then you will usually get existing and applicable sources, but they will not contain all the data on which it bases an answer. These are obviously major drawbacks within the scientific community. Falsehoods and biasesAnother major drawback of ChatGPT is in the training data used to develop the model. First, there are biases in data, and following the old \"garbage-in-garbage-out\" principle, the chatbot\\'s output depends on the training data, and there is a good chance that ChatGPT\\'s answers will reflect these biases. For example, it is clear from ChatGPT\\'s predecessor (GPT-3) that there were gender-stereotypical associations external link in the answers. OpenAI, the company behind ChatGPT, implements filters and human verification to extract obvious falsehoods and the most severe biases. However, this remains an inherent limitation. Outdated dataThe current version of ChatGPT (January ) is only trained on data through September . This means that the chatbot cannot interpret more recent data. This limitation probably will be short-lived; developments are rapid. Calculation errorsFinally, the chatbot (in addition to content errors) also makes computational and logic errors. Again, this has to do with how ChatGPT generates answers. It is a language model, not a calculator: text is generated in response to mathematical questions, but the outcome is a random number based on human preference for numbers external link.'],\n",
       " ['ChatGPT predicts well what kind of answer we want to get. So even though the chatbot does not fully understand the questions and the generated answers, it is still capable to create a logical structure, as is shown in this study in which ChatGPT scores a on a Dutch secondary school (vwo) exam on reading comprehension in English.Moreover, text generation is only one of the software\\'s capabilities. Within the playground of OpenAI there are possibilities to convert a prompt to software code or have an illustration generated. Conversely, you can enter code and ask what it does. See this example for an illustration external link. Additionally, part of the source code is publicly available, therefore different add-ons are created, for example to link to Excel, Gmail, R, Youtube or Whatsapp. This gives an indication of the broad implications we can expect. What can ChatGPT not do? Incorrect referencingChatGPT uses probability theory to compose an answer based on numerous sources. It does this when compiling pieces of text, as well as when compiling a simple factual answer to a question. This means you can never identify all of the sources that were used for the output. This makes ChatGPT\\'s answer non-transparent, difficult to verify, and makes proper and complete source citation (and compliance with copy-right) impossible. If you ask ChatGPT to provide the sources used to generate an answer, the chatbot often fabricates non-existent sources. You can ask for \"real\" and \"peer-reviewed\" sources, then you will usually get existing and applicable sources, but they will not contain all the data on which it bases an answer. These are obviously major drawbacks within the scientific community. Falsehoods and biasesAnother major drawback of ChatGPT is in the training data used to develop the model. First, there are biases in data, and following the old \"garbage-in-garbage-out\" principle, the chatbot\\'s output depends on the training data, and there is a good chance that ChatGPT\\'s answers will reflect these biases. For example, it is clear from ChatGPT\\'s predecessor (GPT-3) that there were gender-stereotypical associations external link in the answers. OpenAI, the company behind ChatGPT, implements filters and human verification to extract obvious falsehoods and the most severe biases. However, this remains an inherent limitation. Outdated dataThe current version of ChatGPT (January ) is only trained on data through September . This means that the chatbot cannot interpret more recent data. This limitation probably will be short-lived; developments are rapid. Calculation errorsFinally, the chatbot (in addition to content errors) also makes computational and logic errors. Again, this has to do with how ChatGPT generates answers. It is a language model, not a calculator: text is generated in response to mathematical questions, but the outcome is a random number based on human preference for numbers external link.'],\n",
       " ['Moreover, text generation is only one of the software\\'s capabilities. Within the playground of OpenAI there are possibilities to convert a prompt to software code or have an illustration generated. Conversely, you can enter code and ask what it does. See this example for an illustration external link. Additionally, part of the source code is publicly available, therefore different add-ons are created, for example to link to Excel, Gmail, R, Youtube or Whatsapp. This gives an indication of the broad implications we can expect. What can ChatGPT not do? Incorrect referencingChatGPT uses probability theory to compose an answer based on numerous sources. It does this when compiling pieces of text, as well as when compiling a simple factual answer to a question. This means you can never identify all of the sources that were used for the output. This makes ChatGPT\\'s answer non-transparent, difficult to verify, and makes proper and complete source citation (and compliance with copy-right) impossible. If you ask ChatGPT to provide the sources used to generate an answer, the chatbot often fabricates non-existent sources. You can ask for \"real\" and \"peer-reviewed\" sources, then you will usually get existing and applicable sources, but they will not contain all the data on which it bases an answer. These are obviously major drawbacks within the scientific community. Falsehoods and biasesAnother major drawback of ChatGPT is in the training data used to develop the model. First, there are biases in data, and following the old \"garbage-in-garbage-out\" principle, the chatbot\\'s output depends on the training data, and there is a good chance that ChatGPT\\'s answers will reflect these biases. For example, it is clear from ChatGPT\\'s predecessor (GPT-3) that there were gender-stereotypical associations external link in the answers. OpenAI, the company behind ChatGPT, implements filters and human verification to extract obvious falsehoods and the most severe biases. However, this remains an inherent limitation. Outdated dataThe current version of ChatGPT (January ) is only trained on data through September . This means that the chatbot cannot interpret more recent data. This limitation probably will be short-lived; developments are rapid. Calculation errorsFinally, the chatbot (in addition to content errors) also makes computational and logic errors. Again, this has to do with how ChatGPT generates answers. It is a language model, not a calculator: text is generated in response to mathematical questions, but the outcome is a random number based on human preference for numbers external link.'],\n",
       " ['Additionally, part of the source code is publicly available, therefore different add-ons are created, for example to link to Excel, Gmail, R, Youtube or Whatsapp. This gives an indication of the broad implications we can expect. What can ChatGPT not do? Incorrect referencingChatGPT uses probability theory to compose an answer based on numerous sources. It does this when compiling pieces of text, as well as when compiling a simple factual answer to a question. This means you can never identify all of the sources that were used for the output. This makes ChatGPT\\'s answer non-transparent, difficult to verify, and makes proper and complete source citation (and compliance with copy-right) impossible. If you ask ChatGPT to provide the sources used to generate an answer, the chatbot often fabricates non-existent sources. You can ask for \"real\" and \"peer-reviewed\" sources, then you will usually get existing and applicable sources, but they will not contain all the data on which it bases an answer. These are obviously major drawbacks within the scientific community. Falsehoods and biasesAnother major drawback of ChatGPT is in the training data used to develop the model. First, there are biases in data, and following the old \"garbage-in-garbage-out\" principle, the chatbot\\'s output depends on the training data, and there is a good chance that ChatGPT\\'s answers will reflect these biases. For example, it is clear from ChatGPT\\'s predecessor (GPT-3) that there were gender-stereotypical associations external link in the answers. OpenAI, the company behind ChatGPT, implements filters and human verification to extract obvious falsehoods and the most severe biases. However, this remains an inherent limitation. Outdated dataThe current version of ChatGPT (January ) is only trained on data through September . This means that the chatbot cannot interpret more recent data. This limitation probably will be short-lived; developments are rapid. Calculation errorsFinally, the chatbot (in addition to content errors) also makes computational and logic errors. Again, this has to do with how ChatGPT generates answers. It is a language model, not a calculator: text is generated in response to mathematical questions, but the outcome is a random number based on human preference for numbers external link.'],\n",
       " ['ChatGPT uses probability theory to compose an answer based on numerous sources. It does this when compiling pieces of text, as well as when compiling a simple factual answer to a question. This means you can never identify all of the sources that were used for the output. This makes ChatGPT\\'s answer non-transparent, difficult to verify, and makes proper and complete source citation (and compliance with copy-right) impossible. If you ask ChatGPT to provide the sources used to generate an answer, the chatbot often fabricates non-existent sources. You can ask for \"real\" and \"peer-reviewed\" sources, then you will usually get existing and applicable sources, but they will not contain all the data on which it bases an answer. These are obviously major drawbacks within the scientific community. Falsehoods and biasesAnother major drawback of ChatGPT is in the training data used to develop the model. First, there are biases in data, and following the old \"garbage-in-garbage-out\" principle, the chatbot\\'s output depends on the training data, and there is a good chance that ChatGPT\\'s answers will reflect these biases. For example, it is clear from ChatGPT\\'s predecessor (GPT-3) that there were gender-stereotypical associations external link in the answers. OpenAI, the company behind ChatGPT, implements filters and human verification to extract obvious falsehoods and the most severe biases. However, this remains an inherent limitation. Outdated dataThe current version of ChatGPT (January ) is only trained on data through September . This means that the chatbot cannot interpret more recent data. This limitation probably will be short-lived; developments are rapid. Calculation errorsFinally, the chatbot (in addition to content errors) also makes computational and logic errors. Again, this has to do with how ChatGPT generates answers. It is a language model, not a calculator: text is generated in response to mathematical questions, but the outcome is a random number based on human preference for numbers external link.'],\n",
       " ['Another major drawback of ChatGPT is in the training data used to develop the model. First, there are biases in data, and following the old \"garbage-in-garbage-out\" principle, the chatbot\\'s output depends on the training data, and there is a good chance that ChatGPT\\'s answers will reflect these biases. For example, it is clear from ChatGPT\\'s predecessor (GPT-3) that there were gender-stereotypical associations external link in the answers. OpenAI, the company behind ChatGPT, implements filters and human verification to extract obvious falsehoods and the most severe biases. However, this remains an inherent limitation. Outdated dataThe current version of ChatGPT (January ) is only trained on data through September . This means that the chatbot cannot interpret more recent data. This limitation probably will be short-lived; developments are rapid. Calculation errorsFinally, the chatbot (in addition to content errors) also makes computational and logic errors. Again, this has to do with how ChatGPT generates answers. It is a language model, not a calculator: text is generated in response to mathematical questions, but the outcome is a random number based on human preference for numbers external link.'],\n",
       " ['he current version of ChatGPT (January ) is only trained on data through September . This means that the chatbot cannot interpret more recent data. This limitation probably will be short-lived; developments are rapid. Calculation errorsFinally, the chatbot (in addition to content errors) also makes computational and logic errors. Again, this has to do with how ChatGPT generates answers. It is a language model, not a calculator: text is generated in response to mathematical questions, but the outcome is a random number based on human preference for numbers external link.'],\n",
       " [],\n",
       " [],\n",
       " ['At EUR, numerous researchers are actively involved in various AI initiatives and research projects. Our experts are involved in diverse AI topics ranging from Law & Data compliance, Trustworthy and Accountable AI, Psychology of AI, Personalization & data and AI, Trial, Design and AI, Bioinformatics, Fintech, Health & Management and AI, and Retail Analytics. At ECDAOpens external, we support collaborative research & innovation programs and EUR initiatives, connecting experts across expert practices with external partners. For example, we are currently involved in projects like AiPact, AI MAPS, ALGOSOCOpens external, and EU programs such as MAGPIEOpens external.To promote the growth of our AI capabilities and address the essential questions from the community, we have launched the AI external program, which is led by a program team of EUR Data Protection Officers and ECDA marketing and program managers, supported by AiPact, and with ambassadors from all the different faculties. The program aims to identify and connect all researchers and staff involved in AI, create more awareness of AI-related activities on campus, and promote ethical and trustworthy AI practices while informing all stakeholders about the legislation on data & AI coming from the EU.To connect and stimulate dialogues with our academics, we believe engaging in community building around data, AI & digitalisation is essential. Therefore, we are facilitating a dialogue with our researchers and staff about ethical, trustworthy, and responsible AI use. This comes together in the AI Program, which will officially kick off on May . The Ethics & Data Ethics event on May will focus on the risks and potential of recent AI developments on our ethical thinking, considerations, (daily) practices, and dilemmas.Through our upcoming sessions in , we aim to capture the lessons learned and insights from current research and invite EUR faculty and staff to reflect on challenges, opportunities, and restrictions, with regards to the development and application of algorithms, from the Erasmian Values point of view. In addition, we are committed to promoting responsible and trustworthy AI use while driving innovation and progress in AI research and development.2. How does ECDA support and collaborate with other departments or research centres involved in AI research?ECDA collaborates closely with other departments and research centres involved in AI research. We have a multidisciplinary structure of expert practices focused on foundational domains and six application domains. Each expert practice is led by an Academic Director, an inspiring and renowned researcher engaged in all the different schools at EUR. This makes it a transdisciplinary group representing the broad field of data sciences at the university.Furthermore, the ECDA community stimulates collaborations across existing and new domains through initiatives such as facilitating collaborative research and innovation programs, maintaining a fast and diverse network of external partners, and organising regular opportunities to connect with both internal and external stakeholders. ECDA also has administrative commitments with other faculties at the university, such as EUR CvB, RSMOpens external, ESSB and ConvergenceOpens external.ECDA also collaborates with other EUR entities such as the RSM centresOpens external, Erasmus Centre for EntrepreneurshipOpens external, Erasmus University Library, CLI, Erasmus UPT, and different student organisations like Erasmus Tech CommunityOpens external, Turing studentsOpens external, MAEUROpens external, Sustainability HubOpens external, and Convergence research centres at TU Delft and Erasmus MC, as well as LDE centresOpens external like Centre for BOLD citiesOpens external.On a national level, ECDA is part of the broader data, AI, and innovation networks such as the Dutch NLAIC networkOpens external and Responsible AI network of universities of applied science. On an international level, ECDA is involved in diverse EU initiatives such as ENOLLOpens external, OASCOpens external, and other international AI networks. In addition, we engage heavily in community building and creating collaboration and networking opportunities for their researchers.3. Can you discuss any particularly innovative or groundbreaking projects currently being undertaken at the centre?One of the notable projects is the EUR Smart Campus Project,Opens external which aims to utilise data and digitalisation to create awareness around sustainability and human well-being. The project involves the campus \"citizens\" themselves, and there are collaborations with Real Estate and Facilities, Erasmus Digitalisation & Information Services, the EUR data protection office, the sustainability hub, and external companies and startups. The EUR campus serves as a testbed for innovation projects that contribute to campus users\\' well-being, campus sustainability, operations excellence, and optimal'],\n",
       " [\"nd durable use of campus facilities.Another significant project is the EU MAGPIE projectOpens external, an EU-funded innovation project led by the Port of RotterdamOpens external. The project aims to force a breakthrough in the supply and use of green energy carriers in transport to, from, and within ports. The project harnesses the power of data by linking a digital twin of the port with the power of AI to optimise the energy system and the use of renewable energy in connection with an optimised logistics network. In addition, the project explores various research questions, such as willingness to share data, algorithms for prediction and matching, and new business models.ECDA is also working towards realising an immersive tech experience, data, and research space alongside with various parties at EUR and external parties. The space seeks to foster experimentation, data sharing, stimulate imagination, and support education and research initiatives. Additionally, ECDA is collaborating with students and researchers from the University of Applied Sciences RotterdamOpens external and additional external partners in the context of energy transition and the immersive tech week in Rotterdam.ECDA is also supporting studies into the psychology of AI, generative AI (such as chatGPT), and immersive tech, which are still ongoing. These projects show that ECDA is committed to utilising data and digitalisation to create innovative solutions contributing to sustainability, well-being, and decarbonisation.4. How has the field of AI, data, and digitalisation evolved during your time at Erasmus University Rotterdam/ECDA?During my time at Erasmus University Rotterdam and ECDA, I've witnessed significant advancements in AI, data, and digitalisation. While the first steps towards AI were taken in the s, it wasn't until the last two decades that we saw a rise in AI in autonomous vehicles, image recognition, IBM Watson, AI technologies in robotics, and most recently, openAI Chat GPT (from ).Data platforms have also become increasingly important, and in , ECDA conducted an important study as part of the EU project RuggedisedOpens external on urban data platform development among European cities. The study concluded that most cities still need to move from a situation where data is stuck in different silos to a situation where data can be shared in an open urban data platform. In order to create value from urban data platforms, building an ecosystem of trust among public, private, academia, and citizens is essential. Open data standards are also a crucial requirement for interoperability and data sharing between platforms, data owners, and data users.At ECDA, we're actively supporting the Living-in-EU movement, which has laid down a clear set of guidelines and design principles for creating inclusive smart and sustainable cities fuelled by open urban data platforms and digital twins.The discussions on AI and algorithms that are currently taking place are often rooted in data discussions. Fortunately, these have already been subject to many studies at EUR and other institutions. Topics include data quality, privacy, ethics, accountability, cybersecurity, and private property.In recent years, public awareness and use of algorithms have grown significantly, with costs decreasing and AI as a service becoming more commonly available. Digitalisation is taking place across society and all disciplines, where eventually, everything will be connected via IoT. Data is our common fuel, and it's a very powerful fuel that demands new considerations, particularly with more advanced use of algorithms in our daily lives and generative AI.Lately, developments in AI, especially around generative AI, are accelerating so fast that experts are asking for a time-out for humans and legal frameworks to catch up with the possibilities and consider how society wants to move forward in the development of AI. At EUR and ECDA, we want to stimulate this dialogue around ethical and trustworthy AI via programs like AI. Many ECDA experts are directly involved in data privacy and data sharing discussions and legal implications of the EU AI act.5. What is the uniqueness of how ECDA /EUR research approaches and addresses societal AI challenges?The uniqueness of how ECDA/EUR research approaches and addresses societal AI challenges lies in our combination of deep contextual knowledge and cutting-edge techniques and methodologies in data analytics, AI, and immersive technology. Our researchers have specific application domain expertise and organisational context knowledge, which we combine with advanced technological approaches to improve human-centred decision-making and solve societal and business challenges.Our human-centred approach is a critical aspect of our research, and it reflects the diverse schools that form the Erasmus University Rotterdam and shape the Erasmian values. We believe that the link between context, strong techniques, and soci\"],\n",
       " ['o promote the growth of our AI capabilities and address the essential questions from the community, we have launched the AI external program, which is led by a program team of EUR Data Protection Officers and ECDA marketing and program managers, supported by AiPact, and with ambassadors from all the different faculties. The program aims to identify and connect all researchers and staff involved in AI, create more awareness of AI-related activities on campus, and promote ethical and trustworthy AI practices while informing all stakeholders about the legislation on data & AI coming from the EU.To connect and stimulate dialogues with our academics, we believe engaging in community building around data, AI & digitalisation is essential. Therefore, we are facilitating a dialogue with our researchers and staff about ethical, trustworthy, and responsible AI use. This comes together in the AI Program, which will officially kick off on May . The Ethics & Data Ethics event on May will focus on the risks and potential of recent AI developments on our ethical thinking, considerations, (daily) practices, and dilemmas.Through our upcoming sessions in , we aim to capture the lessons learned and insights from current research and invite EUR faculty and staff to reflect on challenges, opportunities, and restrictions, with regards to the development and application of algorithms, from the Erasmian Values point of view. In addition, we are committed to promoting responsible and trustworthy AI use while driving innovation and progress in AI research and development.2. How does ECDA support and collaborate with other departments or research centres involved in AI research?ECDA collaborates closely with other departments and research centres involved in AI research. We have a multidisciplinary structure of expert practices focused on foundational domains and six application domains. Each expert practice is led by an Academic Director, an inspiring and renowned researcher engaged in all the different schools at EUR. This makes it a transdisciplinary group representing the broad field of data sciences at the university.Furthermore, the ECDA community stimulates collaborations across existing and new domains through initiatives such as facilitating collaborative research and innovation programs, maintaining a fast and diverse network of external partners, and organising regular opportunities to connect with both internal and external stakeholders. ECDA also has administrative commitments with other faculties at the university, such as EUR CvB, RSMOpens external, ESSB and ConvergenceOpens external.ECDA also collaborates with other EUR entities such as the RSM centresOpens external, Erasmus Centre for EntrepreneurshipOpens external, Erasmus University Library, CLI, Erasmus UPT, and different student organisations like Erasmus Tech CommunityOpens external, Turing studentsOpens external, MAEUROpens external, Sustainability HubOpens external, and Convergence research centres at TU Delft and Erasmus MC, as well as LDE centresOpens external like Centre for BOLD citiesOpens external.On a national level, ECDA is part of the broader data, AI, and innovation networks such as the Dutch NLAIC networkOpens external and Responsible AI network of universities of applied science. On an international level, ECDA is involved in diverse EU initiatives such as ENOLLOpens external, OASCOpens external, and other international AI networks. In addition, we engage heavily in community building and creating collaboration and networking opportunities for their researchers.3. Can you discuss any particularly innovative or groundbreaking projects currently being undertaken at the centre?One of the notable projects is the EUR Smart Campus Project,Opens external which aims to utilise data and digitalisation to create awareness around sustainability and human well-being. The project involves the campus \"citizens\" themselves, and there are collaborations with Real Estate and Facilities, Erasmus Digitalisation & Information Services, the EUR data protection office, the sustainability hub, and external companies and startups. The EUR campus serves as a testbed for innovation projects that contribute to campus users\\' well-being, campus sustainability, operations excellence, and optimal and durable use of campus facilities.Another significant project is the EU MAGPIE projectOpens external, an EU-funded innovation project led by the Port of RotterdamOpens external. The project aims to force a breakthrough in the supply and use of green energy carriers in transport to, from, and within ports. The project harnesses the power of data by linking a digital twin of the port with the power of AI to optimise the energy system and the use of renewable energy in connection with an optimised logistics network. In addition, the project explores various research questions, such as willingness to share data, algorithms for prediction and matching, and new b'],\n",
       " ['o connect and stimulate dialogues with our academics, we believe engaging in community building around data, AI & digitalisation is essential. Therefore, we are facilitating a dialogue with our researchers and staff about ethical, trustworthy, and responsible AI use. This comes together in the AI Program, which will officially kick off on May . The Ethics & Data Ethics event on May will focus on the risks and potential of recent AI developments on our ethical thinking, considerations, (daily) practices, and dilemmas.Through our upcoming sessions in , we aim to capture the lessons learned and insights from current research and invite EUR faculty and staff to reflect on challenges, opportunities, and restrictions, with regards to the development and application of algorithms, from the Erasmian Values point of view. In addition, we are committed to promoting responsible and trustworthy AI use while driving innovation and progress in AI research and development.2. How does ECDA support and collaborate with other departments or research centres involved in AI research?ECDA collaborates closely with other departments and research centres involved in AI research. We have a multidisciplinary structure of expert practices focused on foundational domains and six application domains. Each expert practice is led by an Academic Director, an inspiring and renowned researcher engaged in all the different schools at EUR. This makes it a transdisciplinary group representing the broad field of data sciences at the university.Furthermore, the ECDA community stimulates collaborations across existing and new domains through initiatives such as facilitating collaborative research and innovation programs, maintaining a fast and diverse network of external partners, and organising regular opportunities to connect with both internal and external stakeholders. ECDA also has administrative commitments with other faculties at the university, such as EUR CvB, RSMOpens external, ESSB and ConvergenceOpens external.ECDA also collaborates with other EUR entities such as the RSM centresOpens external, Erasmus Centre for EntrepreneurshipOpens external, Erasmus University Library, CLI, Erasmus UPT, and different student organisations like Erasmus Tech CommunityOpens external, Turing studentsOpens external, MAEUROpens external, Sustainability HubOpens external, and Convergence research centres at TU Delft and Erasmus MC, as well as LDE centresOpens external like Centre for BOLD citiesOpens external.On a national level, ECDA is part of the broader data, AI, and innovation networks such as the Dutch NLAIC networkOpens external and Responsible AI network of universities of applied science. On an international level, ECDA is involved in diverse EU initiatives such as ENOLLOpens external, OASCOpens external, and other international AI networks. In addition, we engage heavily in community building and creating collaboration and networking opportunities for their researchers.3. Can you discuss any particularly innovative or groundbreaking projects currently being undertaken at the centre?One of the notable projects is the EUR Smart Campus Project,Opens external which aims to utilise data and digitalisation to create awareness around sustainability and human well-being. The project involves the campus \"citizens\" themselves, and there are collaborations with Real Estate and Facilities, Erasmus Digitalisation & Information Services, the EUR data protection office, the sustainability hub, and external companies and startups. The EUR campus serves as a testbed for innovation projects that contribute to campus users\\' well-being, campus sustainability, operations excellence, and optimal and durable use of campus facilities.Another significant project is the EU MAGPIE projectOpens external, an EU-funded innovation project led by the Port of RotterdamOpens external. The project aims to force a breakthrough in the supply and use of green energy carriers in transport to, from, and within ports. The project harnesses the power of data by linking a digital twin of the port with the power of AI to optimise the energy system and the use of renewable energy in connection with an optimised logistics network. In addition, the project explores various research questions, such as willingness to share data, algorithms for prediction and matching, and new business models.ECDA is also working towards realising an immersive tech experience, data, and research space alongside with various parties at EUR and external parties. The space seeks to foster experimentation, data sharing, stimulate imagination, and support education and research initiatives. Additionally, ECDA is collaborating with students and researchers from the University of Applied Sciences RotterdamOpens external and additional external partners in the context of energy transition and the immersive tech week in Rotterdam.ECDA is also supporting studies into the psychology of AI, generative AI'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['On a national level, ECDA is part of the broader data, AI, and innovation networks such as the Dutch NLAIC networkOpens external and Responsible AI network of universities of applied science. On an international level, ECDA is involved in diverse EU initiatives such as ENOLLOpens external, OASCOpens external, and other international AI networks. In addition, we engage heavily in community building and creating collaboration and networking opportunities for their researchers.3. Can you discuss any particularly innovative or groundbreaking projects currently being undertaken at the centre?One of the notable projects is the EUR Smart Campus Project,Opens external which aims to utilise data and digitalisation to create awareness around sustainability and human well-being. The project involves the campus \"citizens\" themselves, and there are collaborations with Real Estate and Facilities, Erasmus Digitalisation & Information Services, the EUR data protection office, the sustainability hub, and external companies and startups. The EUR campus serves as a testbed for innovation projects that contribute to campus users\\' well-being, campus sustainability, operations excellence, and optimal and durable use of campus facilities.Another significant project is the EU MAGPIE projectOpens external, an EU-funded innovation project led by the Port of RotterdamOpens external. The project aims to force a breakthrough in the supply and use of green energy carriers in transport to, from, and within ports. The project harnesses the power of data by linking a digital twin of the port with the power of AI to optimise the energy system and the use of renewable energy in connection with an optimised logistics network. In addition, the project explores various research questions, such as willingness to share data, algorithms for prediction and matching, and new business models.ECDA is also working towards realising an immersive tech experience, data, and research space alongside with various parties at EUR and external parties. The space seeks to foster experimentation, data sharing, stimulate imagination, and support education and research initiatives. Additionally, ECDA is collaborating with students and researchers from the University of Applied Sciences RotterdamOpens external and additional external partners in the context of energy transition and the immersive tech week in Rotterdam.ECDA is also supporting studies into the psychology of AI, generative AI (such as chatGPT), and immersive tech, which are still ongoing. These projects show that ECDA is committed to utilising data and digitalisation to create innovative solutions contributing to sustainability, well-being, and decarbonisation.4. How has the field of AI, data, and digitalisation evolved during your time at Erasmus University Rotterdam/ECDA?During my time at Erasmus University Rotterdam and ECDA, I\\'ve witnessed significant advancements in AI, data, and digitalisation. While the first steps towards AI were taken in the s, it wasn\\'t until the last two decades that we saw a rise in AI in autonomous vehicles, image recognition, IBM Watson, AI technologies in robotics, and most recently, openAI Chat GPT (from ).Data platforms have also become increasingly important, and in , ECDA conducted an important study as part of the EU project RuggedisedOpens external on urban data platform development among European cities. The study concluded that most cities still need to move from a situation where data is stuck in different silos to a situation where data can be shared in an open urban data platform. In order to create value from urban data platforms, building an ecosystem of trust among public, private, academia, and citizens is essential. Open data standards are also a crucial requirement for interoperability and data sharing between platforms, data owners, and data users.At ECDA, we\\'re actively supporting the Living-in-EU movement, which has laid down a clear set of guidelines and design principles for creating inclusive smart and sustainable cities fuelled by open urban data platforms and digital twins.The discussions on AI and algorithms that are currently taking place are often rooted in data discussions. Fortunately, these have already been subject to many studies at EUR and other institutions. Topics include data quality, privacy, ethics, accountability, cybersecurity, and private property.In recent years, public awareness and use of algorithms have grown significantly, with costs decreasing and AI as a service becoming more commonly available. Digitalisation is taking place across society and all disciplines, where eventually, everything will be connected via IoT. Data is our common fuel, and it\\'s a very powerful fuel that demands new considerations, particularly with more advanced use of algorithms in our daily lives and generative AI.Lately, developments in AI, especially around generative AI, are accelerating so fast that experts are asking for a time'],\n",
       " ['One of the notable projects is the EUR Smart Campus Project,Opens external which aims to utilise data and digitalisation to create awareness around sustainability and human well-being. The project involves the campus \"citizens\" themselves, and there are collaborations with Real Estate and Facilities, Erasmus Digitalisation & Information Services, the EUR data protection office, the sustainability hub, and external companies and startups. The EUR campus serves as a testbed for innovation projects that contribute to campus users\\' well-being, campus sustainability, operations excellence, and optimal and durable use of campus facilities.Another significant project is the EU MAGPIE projectOpens external, an EU-funded innovation project led by the Port of RotterdamOpens external. The project aims to force a breakthrough in the supply and use of green energy carriers in transport to, from, and within ports. The project harnesses the power of data by linking a digital twin of the port with the power of AI to optimise the energy system and the use of renewable energy in connection with an optimised logistics network. In addition, the project explores various research questions, such as willingness to share data, algorithms for prediction and matching, and new business models.ECDA is also working towards realising an immersive tech experience, data, and research space alongside with various parties at EUR and external parties. The space seeks to foster experimentation, data sharing, stimulate imagination, and support education and research initiatives. Additionally, ECDA is collaborating with students and researchers from the University of Applied Sciences RotterdamOpens external and additional external partners in the context of energy transition and the immersive tech week in Rotterdam.ECDA is also supporting studies into the psychology of AI, generative AI (such as chatGPT), and immersive tech, which are still ongoing. These projects show that ECDA is committed to utilising data and digitalisation to create innovative solutions contributing to sustainability, well-being, and decarbonisation.4. How has the field of AI, data, and digitalisation evolved during your time at Erasmus University Rotterdam/ECDA?During my time at Erasmus University Rotterdam and ECDA, I\\'ve witnessed significant advancements in AI, data, and digitalisation. While the first steps towards AI were taken in the s, it wasn\\'t until the last two decades that we saw a rise in AI in autonomous vehicles, image recognition, IBM Watson, AI technologies in robotics, and most recently, openAI Chat GPT (from ).Data platforms have also become increasingly important, and in , ECDA conducted an important study as part of the EU project RuggedisedOpens external on urban data platform development among European cities. The study concluded that most cities still need to move from a situation where data is stuck in different silos to a situation where data can be shared in an open urban data platform. In order to create value from urban data platforms, building an ecosystem of trust among public, private, academia, and citizens is essential. Open data standards are also a crucial requirement for interoperability and data sharing between platforms, data owners, and data users.At ECDA, we\\'re actively supporting the Living-in-EU movement, which has laid down a clear set of guidelines and design principles for creating inclusive smart and sustainable cities fuelled by open urban data platforms and digital twins.The discussions on AI and algorithms that are currently taking place are often rooted in data discussions. Fortunately, these have already been subject to many studies at EUR and other institutions. Topics include data quality, privacy, ethics, accountability, cybersecurity, and private property.In recent years, public awareness and use of algorithms have grown significantly, with costs decreasing and AI as a service becoming more commonly available. Digitalisation is taking place across society and all disciplines, where eventually, everything will be connected via IoT. Data is our common fuel, and it\\'s a very powerful fuel that demands new considerations, particularly with more advanced use of algorithms in our daily lives and generative AI.Lately, developments in AI, especially around generative AI, are accelerating so fast that experts are asking for a time-out for humans and legal frameworks to catch up with the possibilities and consider how society wants to move forward in the development of AI. At EUR and ECDA, we want to stimulate this dialogue around ethical and trustworthy AI via programs like AI. Many ECDA experts are directly involved in data privacy and data sharing discussions and legal implications of the EU AI act.5. What is the uniqueness of how ECDA /EUR research approaches and addresses societal AI challenges?The uniqueness of how ECDA/EUR research approaches and addresses societal AI challenges lies in our combination'],\n",
       " [\"Another significant project is the EU MAGPIE projectOpens external, an EU-funded innovation project led by the Port of RotterdamOpens external. The project aims to force a breakthrough in the supply and use of green energy carriers in transport to, from, and within ports. The project harnesses the power of data by linking a digital twin of the port with the power of AI to optimise the energy system and the use of renewable energy in connection with an optimised logistics network. In addition, the project explores various research questions, such as willingness to share data, algorithms for prediction and matching, and new business models.ECDA is also working towards realising an immersive tech experience, data, and research space alongside with various parties at EUR and external parties. The space seeks to foster experimentation, data sharing, stimulate imagination, and support education and research initiatives. Additionally, ECDA is collaborating with students and researchers from the University of Applied Sciences RotterdamOpens external and additional external partners in the context of energy transition and the immersive tech week in Rotterdam.ECDA is also supporting studies into the psychology of AI, generative AI (such as chatGPT), and immersive tech, which are still ongoing. These projects show that ECDA is committed to utilising data and digitalisation to create innovative solutions contributing to sustainability, well-being, and decarbonisation.4. How has the field of AI, data, and digitalisation evolved during your time at Erasmus University Rotterdam/ECDA?During my time at Erasmus University Rotterdam and ECDA, I've witnessed significant advancements in AI, data, and digitalisation. While the first steps towards AI were taken in the s, it wasn't until the last two decades that we saw a rise in AI in autonomous vehicles, image recognition, IBM Watson, AI technologies in robotics, and most recently, openAI Chat GPT (from ).Data platforms have also become increasingly important, and in , ECDA conducted an important study as part of the EU project RuggedisedOpens external on urban data platform development among European cities. The study concluded that most cities still need to move from a situation where data is stuck in different silos to a situation where data can be shared in an open urban data platform. In order to create value from urban data platforms, building an ecosystem of trust among public, private, academia, and citizens is essential. Open data standards are also a crucial requirement for interoperability and data sharing between platforms, data owners, and data users.At ECDA, we're actively supporting the Living-in-EU movement, which has laid down a clear set of guidelines and design principles for creating inclusive smart and sustainable cities fuelled by open urban data platforms and digital twins.The discussions on AI and algorithms that are currently taking place are often rooted in data discussions. Fortunately, these have already been subject to many studies at EUR and other institutions. Topics include data quality, privacy, ethics, accountability, cybersecurity, and private property.In recent years, public awareness and use of algorithms have grown significantly, with costs decreasing and AI as a service becoming more commonly available. Digitalisation is taking place across society and all disciplines, where eventually, everything will be connected via IoT. Data is our common fuel, and it's a very powerful fuel that demands new considerations, particularly with more advanced use of algorithms in our daily lives and generative AI.Lately, developments in AI, especially around generative AI, are accelerating so fast that experts are asking for a time-out for humans and legal frameworks to catch up with the possibilities and consider how society wants to move forward in the development of AI. At EUR and ECDA, we want to stimulate this dialogue around ethical and trustworthy AI via programs like AI. Many ECDA experts are directly involved in data privacy and data sharing discussions and legal implications of the EU AI act.5. What is the uniqueness of how ECDA /EUR research approaches and addresses societal AI challenges?The uniqueness of how ECDA/EUR research approaches and addresses societal AI challenges lies in our combination of deep contextual knowledge and cutting-edge techniques and methodologies in data analytics, AI, and immersive technology. Our researchers have specific application domain expertise and organisational context knowledge, which we combine with advanced technological approaches to improve human-centred decision-making and solve societal and business challenges.Our human-centred approach is a critical aspect of our research, and it reflects the diverse schools that form the Erasmus University Rotterdam and shape the Erasmian values. We believe that the link between context, strong techniques, and society is essential to make AI work for\"],\n",
       " [\"ECDA is also working towards realising an immersive tech experience, data, and research space alongside with various parties at EUR and external parties. The space seeks to foster experimentation, data sharing, stimulate imagination, and support education and research initiatives. Additionally, ECDA is collaborating with students and researchers from the University of Applied Sciences RotterdamOpens external and additional external partners in the context of energy transition and the immersive tech week in Rotterdam.ECDA is also supporting studies into the psychology of AI, generative AI (such as chatGPT), and immersive tech, which are still ongoing. These projects show that ECDA is committed to utilising data and digitalisation to create innovative solutions contributing to sustainability, well-being, and decarbonisation.4. How has the field of AI, data, and digitalisation evolved during your time at Erasmus University Rotterdam/ECDA?During my time at Erasmus University Rotterdam and ECDA, I've witnessed significant advancements in AI, data, and digitalisation. While the first steps towards AI were taken in the s, it wasn't until the last two decades that we saw a rise in AI in autonomous vehicles, image recognition, IBM Watson, AI technologies in robotics, and most recently, openAI Chat GPT (from ).Data platforms have also become increasingly important, and in , ECDA conducted an important study as part of the EU project RuggedisedOpens external on urban data platform development among European cities. The study concluded that most cities still need to move from a situation where data is stuck in different silos to a situation where data can be shared in an open urban data platform. In order to create value from urban data platforms, building an ecosystem of trust among public, private, academia, and citizens is essential. Open data standards are also a crucial requirement for interoperability and data sharing between platforms, data owners, and data users.At ECDA, we're actively supporting the Living-in-EU movement, which has laid down a clear set of guidelines and design principles for creating inclusive smart and sustainable cities fuelled by open urban data platforms and digital twins.The discussions on AI and algorithms that are currently taking place are often rooted in data discussions. Fortunately, these have already been subject to many studies at EUR and other institutions. Topics include data quality, privacy, ethics, accountability, cybersecurity, and private property.In recent years, public awareness and use of algorithms have grown significantly, with costs decreasing and AI as a service becoming more commonly available. Digitalisation is taking place across society and all disciplines, where eventually, everything will be connected via IoT. Data is our common fuel, and it's a very powerful fuel that demands new considerations, particularly with more advanced use of algorithms in our daily lives and generative AI.Lately, developments in AI, especially around generative AI, are accelerating so fast that experts are asking for a time-out for humans and legal frameworks to catch up with the possibilities and consider how society wants to move forward in the development of AI. At EUR and ECDA, we want to stimulate this dialogue around ethical and trustworthy AI via programs like AI. Many ECDA experts are directly involved in data privacy and data sharing discussions and legal implications of the EU AI act.5. What is the uniqueness of how ECDA /EUR research approaches and addresses societal AI challenges?The uniqueness of how ECDA/EUR research approaches and addresses societal AI challenges lies in our combination of deep contextual knowledge and cutting-edge techniques and methodologies in data analytics, AI, and immersive technology. Our researchers have specific application domain expertise and organisational context knowledge, which we combine with advanced technological approaches to improve human-centred decision-making and solve societal and business challenges.Our human-centred approach is a critical aspect of our research, and it reflects the diverse schools that form the Erasmus University Rotterdam and shape the Erasmian values. We believe that the link between context, strong techniques, and society is essential to make AI work for the greater good.Moreover, we facilitate and stimulate a critical debate on the ethical, social, and legal considerations around AI's design and use and its impact on society. We strongly advocate for an equal and balanced focus on context, techniques, algorithms, and human aspects to make these technologies beneficial for society at large.For more information contact: ECDA at ecda.nl\"],\n",
       " [\"ECDA is also supporting studies into the psychology of AI, generative AI (such as chatGPT), and immersive tech, which are still ongoing. These projects show that ECDA is committed to utilising data and digitalisation to create innovative solutions contributing to sustainability, well-being, and decarbonisation.4. How has the field of AI, data, and digitalisation evolved during your time at Erasmus University Rotterdam/ECDA?During my time at Erasmus University Rotterdam and ECDA, I've witnessed significant advancements in AI, data, and digitalisation. While the first steps towards AI were taken in the s, it wasn't until the last two decades that we saw a rise in AI in autonomous vehicles, image recognition, IBM Watson, AI technologies in robotics, and most recently, openAI Chat GPT (from ).Data platforms have also become increasingly important, and in , ECDA conducted an important study as part of the EU project RuggedisedOpens external on urban data platform development among European cities. The study concluded that most cities still need to move from a situation where data is stuck in different silos to a situation where data can be shared in an open urban data platform. In order to create value from urban data platforms, building an ecosystem of trust among public, private, academia, and citizens is essential. Open data standards are also a crucial requirement for interoperability and data sharing between platforms, data owners, and data users.At ECDA, we're actively supporting the Living-in-EU movement, which has laid down a clear set of guidelines and design principles for creating inclusive smart and sustainable cities fuelled by open urban data platforms and digital twins.The discussions on AI and algorithms that are currently taking place are often rooted in data discussions. Fortunately, these have already been subject to many studies at EUR and other institutions. Topics include data quality, privacy, ethics, accountability, cybersecurity, and private property.In recent years, public awareness and use of algorithms have grown significantly, with costs decreasing and AI as a service becoming more commonly available. Digitalisation is taking place across society and all disciplines, where eventually, everything will be connected via IoT. Data is our common fuel, and it's a very powerful fuel that demands new considerations, particularly with more advanced use of algorithms in our daily lives and generative AI.Lately, developments in AI, especially around generative AI, are accelerating so fast that experts are asking for a time-out for humans and legal frameworks to catch up with the possibilities and consider how society wants to move forward in the development of AI. At EUR and ECDA, we want to stimulate this dialogue around ethical and trustworthy AI via programs like AI. Many ECDA experts are directly involved in data privacy and data sharing discussions and legal implications of the EU AI act.5. What is the uniqueness of how ECDA /EUR research approaches and addresses societal AI challenges?The uniqueness of how ECDA/EUR research approaches and addresses societal AI challenges lies in our combination of deep contextual knowledge and cutting-edge techniques and methodologies in data analytics, AI, and immersive technology. Our researchers have specific application domain expertise and organisational context knowledge, which we combine with advanced technological approaches to improve human-centred decision-making and solve societal and business challenges.Our human-centred approach is a critical aspect of our research, and it reflects the diverse schools that form the Erasmus University Rotterdam and shape the Erasmian values. We believe that the link between context, strong techniques, and society is essential to make AI work for the greater good.Moreover, we facilitate and stimulate a critical debate on the ethical, social, and legal considerations around AI's design and use and its impact on society. We strongly advocate for an equal and balanced focus on context, techniques, algorithms, and human aspects to make these technologies beneficial for society at large.For more information contact: ECDA at ecda.nl\"],\n",
       " [\"During my time at Erasmus University Rotterdam and ECDA, I've witnessed significant advancements in AI, data, and digitalisation. While the first steps towards AI were taken in the s, it wasn't until the last two decades that we saw a rise in AI in autonomous vehicles, image recognition, IBM Watson, AI technologies in robotics, and most recently, openAI Chat GPT (from ).Data platforms have also become increasingly important, and in , ECDA conducted an important study as part of the EU project RuggedisedOpens external on urban data platform development among European cities. The study concluded that most cities still need to move from a situation where data is stuck in different silos to a situation where data can be shared in an open urban data platform. In order to create value from urban data platforms, building an ecosystem of trust among public, private, academia, and citizens is essential. Open data standards are also a crucial requirement for interoperability and data sharing between platforms, data owners, and data users.At ECDA, we're actively supporting the Living-in-EU movement, which has laid down a clear set of guidelines and design principles for creating inclusive smart and sustainable cities fuelled by open urban data platforms and digital twins.The discussions on AI and algorithms that are currently taking place are often rooted in data discussions. Fortunately, these have already been subject to many studies at EUR and other institutions. Topics include data quality, privacy, ethics, accountability, cybersecurity, and private property.In recent years, public awareness and use of algorithms have grown significantly, with costs decreasing and AI as a service becoming more commonly available. Digitalisation is taking place across society and all disciplines, where eventually, everything will be connected via IoT. Data is our common fuel, and it's a very powerful fuel that demands new considerations, particularly with more advanced use of algorithms in our daily lives and generative AI.Lately, developments in AI, especially around generative AI, are accelerating so fast that experts are asking for a time-out for humans and legal frameworks to catch up with the possibilities and consider how society wants to move forward in the development of AI. At EUR and ECDA, we want to stimulate this dialogue around ethical and trustworthy AI via programs like AI. Many ECDA experts are directly involved in data privacy and data sharing discussions and legal implications of the EU AI act.5. What is the uniqueness of how ECDA /EUR research approaches and addresses societal AI challenges?The uniqueness of how ECDA/EUR research approaches and addresses societal AI challenges lies in our combination of deep contextual knowledge and cutting-edge techniques and methodologies in data analytics, AI, and immersive technology. Our researchers have specific application domain expertise and organisational context knowledge, which we combine with advanced technological approaches to improve human-centred decision-making and solve societal and business challenges.Our human-centred approach is a critical aspect of our research, and it reflects the diverse schools that form the Erasmus University Rotterdam and shape the Erasmian values. We believe that the link between context, strong techniques, and society is essential to make AI work for the greater good.Moreover, we facilitate and stimulate a critical debate on the ethical, social, and legal considerations around AI's design and use and its impact on society. We strongly advocate for an equal and balanced focus on context, techniques, algorithms, and human aspects to make these technologies beneficial for society at large.For more information contact: ECDA at ecda.nl\"],\n",
       " [\"Data platforms have also become increasingly important, and in , ECDA conducted an important study as part of the EU project RuggedisedOpens external on urban data platform development among European cities. The study concluded that most cities still need to move from a situation where data is stuck in different silos to a situation where data can be shared in an open urban data platform. In order to create value from urban data platforms, building an ecosystem of trust among public, private, academia, and citizens is essential. Open data standards are also a crucial requirement for interoperability and data sharing between platforms, data owners, and data users.At ECDA, we're actively supporting the Living-in-EU movement, which has laid down a clear set of guidelines and design principles for creating inclusive smart and sustainable cities fuelled by open urban data platforms and digital twins.The discussions on AI and algorithms that are currently taking place are often rooted in data discussions. Fortunately, these have already been subject to many studies at EUR and other institutions. Topics include data quality, privacy, ethics, accountability, cybersecurity, and private property.In recent years, public awareness and use of algorithms have grown significantly, with costs decreasing and AI as a service becoming more commonly available. Digitalisation is taking place across society and all disciplines, where eventually, everything will be connected via IoT. Data is our common fuel, and it's a very powerful fuel that demands new considerations, particularly with more advanced use of algorithms in our daily lives and generative AI.Lately, developments in AI, especially around generative AI, are accelerating so fast that experts are asking for a time-out for humans and legal frameworks to catch up with the possibilities and consider how society wants to move forward in the development of AI. At EUR and ECDA, we want to stimulate this dialogue around ethical and trustworthy AI via programs like AI. Many ECDA experts are directly involved in data privacy and data sharing discussions and legal implications of the EU AI act.5. What is the uniqueness of how ECDA /EUR research approaches and addresses societal AI challenges?The uniqueness of how ECDA/EUR research approaches and addresses societal AI challenges lies in our combination of deep contextual knowledge and cutting-edge techniques and methodologies in data analytics, AI, and immersive technology. Our researchers have specific application domain expertise and organisational context knowledge, which we combine with advanced technological approaches to improve human-centred decision-making and solve societal and business challenges.Our human-centred approach is a critical aspect of our research, and it reflects the diverse schools that form the Erasmus University Rotterdam and shape the Erasmian values. We believe that the link between context, strong techniques, and society is essential to make AI work for the greater good.Moreover, we facilitate and stimulate a critical debate on the ethical, social, and legal considerations around AI's design and use and its impact on society. We strongly advocate for an equal and balanced focus on context, techniques, algorithms, and human aspects to make these technologies beneficial for society at large.For more information contact: ECDA at ecda.nl\"],\n",
       " [\"At ECDA, we're actively supporting the Living-in-EU movement, which has laid down a clear set of guidelines and design principles for creating inclusive smart and sustainable cities fuelled by open urban data platforms and digital twins.The discussions on AI and algorithms that are currently taking place are often rooted in data discussions. Fortunately, these have already been subject to many studies at EUR and other institutions. Topics include data quality, privacy, ethics, accountability, cybersecurity, and private property.In recent years, public awareness and use of algorithms have grown significantly, with costs decreasing and AI as a service becoming more commonly available. Digitalisation is taking place across society and all disciplines, where eventually, everything will be connected via IoT. Data is our common fuel, and it's a very powerful fuel that demands new considerations, particularly with more advanced use of algorithms in our daily lives and generative AI.Lately, developments in AI, especially around generative AI, are accelerating so fast that experts are asking for a time-out for humans and legal frameworks to catch up with the possibilities and consider how society wants to move forward in the development of AI. At EUR and ECDA, we want to stimulate this dialogue around ethical and trustworthy AI via programs like AI. Many ECDA experts are directly involved in data privacy and data sharing discussions and legal implications of the EU AI act.5. What is the uniqueness of how ECDA /EUR research approaches and addresses societal AI challenges?The uniqueness of how ECDA/EUR research approaches and addresses societal AI challenges lies in our combination of deep contextual knowledge and cutting-edge techniques and methodologies in data analytics, AI, and immersive technology. Our researchers have specific application domain expertise and organisational context knowledge, which we combine with advanced technological approaches to improve human-centred decision-making and solve societal and business challenges.Our human-centred approach is a critical aspect of our research, and it reflects the diverse schools that form the Erasmus University Rotterdam and shape the Erasmian values. We believe that the link between context, strong techniques, and society is essential to make AI work for the greater good.Moreover, we facilitate and stimulate a critical debate on the ethical, social, and legal considerations around AI's design and use and its impact on society. We strongly advocate for an equal and balanced focus on context, techniques, algorithms, and human aspects to make these technologies beneficial for society at large.For more information contact: ECDA at ecda.nl\"],\n",
       " [\"he discussions on AI and algorithms that are currently taking place are often rooted in data discussions. Fortunately, these have already been subject to many studies at EUR and other institutions. Topics include data quality, privacy, ethics, accountability, cybersecurity, and private property.In recent years, public awareness and use of algorithms have grown significantly, with costs decreasing and AI as a service becoming more commonly available. Digitalisation is taking place across society and all disciplines, where eventually, everything will be connected via IoT. Data is our common fuel, and it's a very powerful fuel that demands new considerations, particularly with more advanced use of algorithms in our daily lives and generative AI.Lately, developments in AI, especially around generative AI, are accelerating so fast that experts are asking for a time-out for humans and legal frameworks to catch up with the possibilities and consider how society wants to move forward in the development of AI. At EUR and ECDA, we want to stimulate this dialogue around ethical and trustworthy AI via programs like AI. Many ECDA experts are directly involved in data privacy and data sharing discussions and legal implications of the EU AI act.5. What is the uniqueness of how ECDA /EUR research approaches and addresses societal AI challenges?The uniqueness of how ECDA/EUR research approaches and addresses societal AI challenges lies in our combination of deep contextual knowledge and cutting-edge techniques and methodologies in data analytics, AI, and immersive technology. Our researchers have specific application domain expertise and organisational context knowledge, which we combine with advanced technological approaches to improve human-centred decision-making and solve societal and business challenges.Our human-centred approach is a critical aspect of our research, and it reflects the diverse schools that form the Erasmus University Rotterdam and shape the Erasmian values. We believe that the link between context, strong techniques, and society is essential to make AI work for the greater good.Moreover, we facilitate and stimulate a critical debate on the ethical, social, and legal considerations around AI's design and use and its impact on society. We strongly advocate for an equal and balanced focus on context, techniques, algorithms, and human aspects to make these technologies beneficial for society at large.For more information contact: ECDA at ecda.nl\"],\n",
       " [\"In recent years, public awareness and use of algorithms have grown significantly, with costs decreasing and AI as a service becoming more commonly available. Digitalisation is taking place across society and all disciplines, where eventually, everything will be connected via IoT. Data is our common fuel, and it's a very powerful fuel that demands new considerations, particularly with more advanced use of algorithms in our daily lives and generative AI.Lately, developments in AI, especially around generative AI, are accelerating so fast that experts are asking for a time-out for humans and legal frameworks to catch up with the possibilities and consider how society wants to move forward in the development of AI. At EUR and ECDA, we want to stimulate this dialogue around ethical and trustworthy AI via programs like AI. Many ECDA experts are directly involved in data privacy and data sharing discussions and legal implications of the EU AI act.5. What is the uniqueness of how ECDA /EUR research approaches and addresses societal AI challenges?The uniqueness of how ECDA/EUR research approaches and addresses societal AI challenges lies in our combination of deep contextual knowledge and cutting-edge techniques and methodologies in data analytics, AI, and immersive technology. Our researchers have specific application domain expertise and organisational context knowledge, which we combine with advanced technological approaches to improve human-centred decision-making and solve societal and business challenges.Our human-centred approach is a critical aspect of our research, and it reflects the diverse schools that form the Erasmus University Rotterdam and shape the Erasmian values. We believe that the link between context, strong techniques, and society is essential to make AI work for the greater good.Moreover, we facilitate and stimulate a critical debate on the ethical, social, and legal considerations around AI's design and use and its impact on society. We strongly advocate for an equal and balanced focus on context, techniques, algorithms, and human aspects to make these technologies beneficial for society at large.For more information contact: ECDA at ecda.nl\"],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['On May , Annelien Bredenoord, Rector Magnificus of the Erasmus University Rotterdam, will kick off the AI program during the Ethics & Data Ethics event.The AI program aims to connect all researchers and staff that work with artificial intelligence (AI) at the EUR, creating more insight and awareness on all the AI-related activities on campus. Furthermore, the programs purpose is to stimulate a dialogue around ethical and trustworthy AI, what it means for the Erasmus University Rotterdam, and inform all stakeholders involved, about the legislation on data & AI coming from for example the EU.Because of the importance of these topics the first AI event: Ethics & Data Ethics, will focus on the risks and potential of recent AI developments on our ethical thinking, considerations, (daily) practices and dilemmas. Three experts Prof.dr. Muel Kaptein (RSM), Joris Krijger (Volksbank) and Prof.dr. Hub Zwart (ESPhil) will discuss AI from a human perspective, what moral conundrums are created by AI, and will give us a glimpse into the possible future developments and requirements these fast-paced developments pose on individuals, organizations and legislation.The AI Ethics &Data Ethics event is the first of a series of events for which EUR faculty and staff are invited to reflect on challenges, opportunities and restrictions, with regards to the development and application of algorithms, from an Erasmus Values point of view. What are the choices we make, what is our signature in terms of accountability, with regards to our work and the way we use algorithms? What is the responsible Erasmian AI culture?During the various sessions in we capture the lessons learned and insights from cutting edge research. Please feel welcome to engage! Free Erasmus Centre for Data AnalyticsView Organizer Websiteecda.nlPolak Building, Room Y01.08 Burgemeester Oudlaan Rotterdam,Zuid Holland3062 PANetherlands+ Google Map Register Here Add to calendar'],\n",
       " ['he AI program aims to connect all researchers and staff that work with artificial intelligence (AI) at the EUR, creating more insight and awareness on all the AI-related activities on campus. Furthermore, the programs purpose is to stimulate a dialogue around ethical and trustworthy AI, what it means for the Erasmus University Rotterdam, and inform all stakeholders involved, about the legislation on data & AI coming from for example the EU.Because of the importance of these topics the first AI event: Ethics & Data Ethics, will focus on the risks and potential of recent AI developments on our ethical thinking, considerations, (daily) practices and dilemmas. Three experts Prof.dr. Muel Kaptein (RSM), Joris Krijger (Volksbank) and Prof.dr. Hub Zwart (ESPhil) will discuss AI from a human perspective, what moral conundrums are created by AI, and will give us a glimpse into the possible future developments and requirements these fast-paced developments pose on individuals, organizations and legislation.The AI Ethics &Data Ethics event is the first of a series of events for which EUR faculty and staff are invited to reflect on challenges, opportunities and restrictions, with regards to the development and application of algorithms, from an Erasmus Values point of view. What are the choices we make, what is our signature in terms of accountability, with regards to our work and the way we use algorithms? What is the responsible Erasmian AI culture?During the various sessions in we capture the lessons learned and insights from cutting edge research. Please feel welcome to engage! Free Erasmus Centre for Data AnalyticsView Organizer Websiteecda.nlPolak Building, Room Y01.08 Burgemeester Oudlaan Rotterdam,Zuid Holland3062 PANetherlands+ Google Map Register Here Add to calendar'],\n",
       " ['Because of the importance of these topics the first AI event: Ethics & Data Ethics, will focus on the risks and potential of recent AI developments on our ethical thinking, considerations, (daily) practices and dilemmas. Three experts Prof.dr. Muel Kaptein (RSM), Joris Krijger (Volksbank) and Prof.dr. Hub Zwart (ESPhil) will discuss AI from a human perspective, what moral conundrums are created by AI, and will give us a glimpse into the possible future developments and requirements these fast-paced developments pose on individuals, organizations and legislation.The AI Ethics &Data Ethics event is the first of a series of events for which EUR faculty and staff are invited to reflect on challenges, opportunities and restrictions, with regards to the development and application of algorithms, from an Erasmus Values point of view. What are the choices we make, what is our signature in terms of accountability, with regards to our work and the way we use algorithms? What is the responsible Erasmian AI culture?During the various sessions in we capture the lessons learned and insights from cutting edge research. Please feel welcome to engage! Free Erasmus Centre for Data AnalyticsView Organizer Websiteecda.nlPolak Building, Room Y01.08 Burgemeester Oudlaan Rotterdam,Zuid Holland3062 PANetherlands+ Google Map Register Here Add to calendar'],\n",
       " [],\n",
       " ['All Events This event has passed.AI: Ethics & Data Ethics May :30 :30 On May , Annelien Bredenoord, Rector Magnificus of the Erasmus University Rotterdam, will kick off the AI program during the Ethics & Data Ethics event.The AI program aims to connect all researchers and staff that work with artificial intelligence (AI) at the EUR, creating more insight and awareness on all the AI-related activities on campus. Furthermore, the programs purpose is to stimulate a dialogue around ethical and trustworthy AI, what it means for the Erasmus University Rotterdam, and inform all stakeholders involved, about the legislation on data & AI coming from for example the EU.Because of the importance of these topics the first AI event: Ethics & Data Ethics, will focus on the risks and potential of recent AI developments on our ethical thinking, considerations, (daily) practices and dilemmas. Three experts Prof.dr. Muel Kaptein (RSM), Joris Krijger (Volksbank) and Prof.dr. Hub Zwart (ESPhil) will discuss AI from a human perspective, what moral conundrums are created by AI, and will give us a glimpse into the possible future developments and requirements these fast-paced developments pose on individuals, organizations and legislation.The AI Ethics &Data Ethics event is the first of a series of events for which EUR faculty and staff are invited to reflect on challenges, opportunities and restrictions, with regards to the development and application of algorithms, from an Erasmus Values point of view. What are the choices we make, what is our signature in terms of accountability, with regards to our work and the way we use algorithms? What is the responsible Erasmian AI culture?During the various sessions in we capture the lessons learned and insights from cutting edge research. Please feel welcome to engage! Free Erasmus Centre for Data AnalyticsView Organizer Websiteecda.nlPolak Building, Room Y01.08 Burgemeester Oudlaan Rotterdam,Zuid Holland3062 PANetherlands+ Google Map Register Here Add to calendar Event Navigation Erasmus Data Summit Generative AI and Immersive Technology Smart and Sustainable Campus Sustainability Days'],\n",
       " [],\n",
       " ['By Friso van Houdt The concept AI-cology (the ecology of artificial intelligence) has been part of and will be part of the remainder of AI-MAPS. When studying the AI-cology for our use-cases, we start with a stakeholder-mapping and then we explore the role of AI for all involved stakeholders and the relationships between them. The concept does not have an identity but only a becoming. This means, the analysis of the AI-cology is not fixed but changes while being used by us during our research, in its relations to other concepts (e.g., surveillance AI-cologies), its connections to issues (e.g., public safety) and specific case studies (i.e., crowds and events, high impact crime, low trust neighborhoods). We are also aware, that we as researchers are ourselves part of the AI-cology, and thus also change with emerging understanding and insight.'],\n",
       " ['he concept AI-cology (the ecology of artificial intelligence) has been part of and will be part of the remainder of AI-MAPS. When studying the AI-cology for our use-cases, we start with a stakeholder-mapping and then we explore the role of AI for all involved stakeholders and the relationships between them. The concept does not have an identity but only a becoming. This means, the analysis of the AI-cology is not fixed but changes while being used by us during our research, in its relations to other concepts (e.g., surveillance AI-cologies), its connections to issues (e.g., public safety) and specific case studies (i.e., crowds and events, high impact crime, low trust neighborhoods). We are also aware, that we as researchers are ourselves part of the AI-cology, and thus also change with emerging understanding and insight.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['he generative AI landscape experienced a dramatic surge in , marked by notable releases such as Stable Diffusion and Midjourney for image generation, as well as ChatGPT for conversational text generation. As the generative AI revolution advances, it is poised to fundamentally transform content creation and redefine human creativity across various creative domains. In this presentation, I will discuss preliminary findings from several research projects that explore topics related to generative AI, e.g., the impact of generative AI on the productivity of designers with different experience levels; the ways in which generative AI revolutionizes the interior design workflow; and the role of automated prompt optimization algorithms in enhancing design quality. The dawn of the generative AI era brings about profound implications for the existing creator economy and highlights the need for further IS research in this burgeoning field.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Are you an EUR lecturer and want to learn from another teacher who has used ChatGPT in their education? Join us for this workshop where Rolf Viervant will share his experiences, issues, and ideas. A workshop specifically for teachers to start the conversation about how and if this tool can be used in a way that meets academic standards.'],\n",
       " ['Generative AI such as ChatGPT pose both a threat and an opportunity for academic education.While examination boards struggle to catch up with illicit use, several teachers are experimenting with the program as a legitimate tool in their examination. These first pilots seem to be promising for the possibility of using ChatGPT didactically.Based on this, it is to be expected that the use of software like this will become an accepted practice in academia. The question that follows is how it can be used in such a way that it meets academic standards. What skills do we and students require for using it critically and transparently?Based on practical examples from my own assessment experiences in the philosophy faculty, I will present some issues and ideas on this topic. Consequently, I hope to share experiences and insights together, and to explore where we might go from here.\"RegistrationYou can register for this workshop via the webform on this page.'],\n",
       " [],\n",
       " [],\n",
       " [\"While all-knowing general AI remains a futuristic concept increasingly sophisticated forms of AI are playing a growing role in our politics, institutions, economies, cultures, and daily lives. While these technologies offer great promise, there are also pervasive risks of social exclusion and inequality due to biases, black boxes, digital illiteracy divides, and many other issues.As social AI scientists, we're on a mission to demystify AI and make it more accessible to people from all walks of life. With these workshops, we want to introduce people to the possibilities and limitations of generative AI tools like Chat GPT, HuggingChat, Blockade Labs, and DALL-E, and encourage creative and reflective uses of these tools.But it's not just about playing with cool new tech - we also need to think about the future we want to create with AI technology. That's why our goal is to develop justice driven future scenarios by using and reflecting on these tools. By working together with participants, we explore different ideas, AI-technologies and uses, priorities, and conceptions of justice in an effort to help shape a more inclusive and sustainable AI transition.The output of each workshop is unique, with text-written scenarios and visual material. Ultimately, the outcomes of these workshops will be turned into an interactive work of art that reflects co-created visions for more just technological futures\"],\n",
       " [\"As social AI scientists, we're on a mission to demystify AI and make it more accessible to people from all walks of life. With these workshops, we want to introduce people to the possibilities and limitations of generative AI tools like Chat GPT, HuggingChat, Blockade Labs, and DALL-E, and encourage creative and reflective uses of these tools.But it's not just about playing with cool new tech - we also need to think about the future we want to create with AI technology. That's why our goal is to develop justice driven future scenarios by using and reflecting on these tools. By working together with participants, we explore different ideas, AI-technologies and uses, priorities, and conceptions of justice in an effort to help shape a more inclusive and sustainable AI transition.The output of each workshop is unique, with text-written scenarios and visual material. Ultimately, the outcomes of these workshops will be turned into an interactive work of art that reflects co-created visions for more just technological futures\"],\n",
       " [\"But it's not just about playing with cool new tech - we also need to think about the future we want to create with AI technology. That's why our goal is to develop justice driven future scenarios by using and reflecting on these tools. By working together with participants, we explore different ideas, AI-technologies and uses, priorities, and conceptions of justice in an effort to help shape a more inclusive and sustainable AI transition.The output of each workshop is unique, with text-written scenarios and visual material. Ultimately, the outcomes of these workshops will be turned into an interactive work of art that reflects co-created visions for more just technological futures\"],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['But first, lets talk about clusters! ESHCC has a research institute called ERMeCC, the Erasmus Research Institute for Media, Culture, History and Society. The institute has smaller subgroups called clusters, focusing on a particular theme or area of research. The topics generally span the three departments in our faculty: History, Arts & Culture Studies, and Media & Communication. If you are a PhD candidate in our faculty and not yet involved in cluster, you might be interested to join one. We believe its a great way to connect with colleagues and broaden our perspectives.A while ago, we, Hoan and Tessa, founded the ROCCS cluster after teaching a together in an IBCoM course. We enjoyed our conversations about many of the topics and practical examples from this course and wanted to have a format where we could continue these discussions and even involve others! ROCCS connects researchers of various disciplines who aim to address the dynamic interplay of organizations, media, and publics, in the context of contemporary societal challenges. After our kick-off event in June with attendees from multiple faculties and universities, our group has continued to grow. We organize regular coffee moments to catch up, to stay up to date in the field and each other\\'s work.to collaborate on new research projects. We also present our work at multiple ERMeCC lunch seminars, organized our first themed session, and we have discussed our ideas for the next big ROCCS event, so stay tuned!Now, back to our themed discussion! We thought it would be interesting to discuss current trends in the working world since the Covid pandemic and to approach it from the different perspectives of our members. Here are our takeaways:1. Quiet quitting is not a new phenomenon. Quiet quitting emerged as a \"trend in the workforce, especially as part of the Great Resignation during which many people left their jobs. However, it is not actually that new of a phenomenon. The idea of doing the bare minimum at work closely relates to the idea of work to rule, the -to-5 mentality, and unions.2. Rather, to understand this new (or not so new) work phenomenon, we need to consider the role of technology. Technology reorganized how we do our work and relate to each other in different ways. When considering employer-employee relationships, we noted that there has been an uptick of bossware during and after Covid, to monitor people who had to work from home.3. Quiet quitting is not possible for every worker, so they resort to resenteeism. For example, platform workers are closely monitored and are under algorithmic control. They may therefore not be able to get away with doing the bare minimum, so they do not work the minimum but do voice their discontent.4. ChatGPT may lead to more quiet quitting. Naturally, ChatGPT could not be excluded from the discussion on technology. In many contexts, ChatGPT can be very helpful in doing work more efficiently and thus minimize work effort. However, in some sectors it has also been a factor for demotivation. Will (some) jobs disappear now that ChatGPT has shown great promise in writing texts or even writing code.A different perspective is required for advertising and marketing professionals. In this field, there is already a tendency towards freelance working. Platforms and ChatGPT can support freelancers in doing their work more efficiently, though worries exist that the volume of work may diminish due to AI tools. Such worries may affect how people experience their job and their attitude to staying/leaving their position.5. Internal communication could play an important role in responding to trends such as quiet quitting and resenteeism. Using this perspective, organizations could focus on creating understanding of how these trends emerge and determine strategies for improving the connection with workers.6. We need to consider the role of work culture. Burnout literature points at the importance of investment and rewards work, thus the emotional investment from workers needs to be balanced out. Additionally, these trends are not a generational issue, where younger and older generations are opposed. Each generation has different characteristics, where younger generations have changed expectations with regards to work and workplaces, and older generations deal with lifespan challenges.7. Approaching trends in work and organizations from an immigration perspective adds valuable insights. Immigrated workers have no chance to quit because of how it is tied to the visa or permits. While this isnt the case for those who move for work within the EU, there are still cultural elements that can play a role. If immigrant workers experienced challenges such as social insecurity abroad, they might bring this mindset and related worries to (in this case) the Netherlands.If we were to study this topic, what kind of questions would we ask? To conclude the themed session, we asked ourselves how we would conduct research'],\n",
       " ['A while ago, we, Hoan and Tessa, founded the ROCCS cluster after teaching a together in an IBCoM course. We enjoyed our conversations about many of the topics and practical examples from this course and wanted to have a format where we could continue these discussions and even involve others! ROCCS connects researchers of various disciplines who aim to address the dynamic interplay of organizations, media, and publics, in the context of contemporary societal challenges. After our kick-off event in June with attendees from multiple faculties and universities, our group has continued to grow. We organize regular coffee moments to catch up, to stay up to date in the field and each other\\'s work.to collaborate on new research projects. We also present our work at multiple ERMeCC lunch seminars, organized our first themed session, and we have discussed our ideas for the next big ROCCS event, so stay tuned!Now, back to our themed discussion! We thought it would be interesting to discuss current trends in the working world since the Covid pandemic and to approach it from the different perspectives of our members. Here are our takeaways:1. Quiet quitting is not a new phenomenon. Quiet quitting emerged as a \"trend in the workforce, especially as part of the Great Resignation during which many people left their jobs. However, it is not actually that new of a phenomenon. The idea of doing the bare minimum at work closely relates to the idea of work to rule, the -to-5 mentality, and unions.2. Rather, to understand this new (or not so new) work phenomenon, we need to consider the role of technology. Technology reorganized how we do our work and relate to each other in different ways. When considering employer-employee relationships, we noted that there has been an uptick of bossware during and after Covid, to monitor people who had to work from home.3. Quiet quitting is not possible for every worker, so they resort to resenteeism. For example, platform workers are closely monitored and are under algorithmic control. They may therefore not be able to get away with doing the bare minimum, so they do not work the minimum but do voice their discontent.4. ChatGPT may lead to more quiet quitting. Naturally, ChatGPT could not be excluded from the discussion on technology. In many contexts, ChatGPT can be very helpful in doing work more efficiently and thus minimize work effort. However, in some sectors it has also been a factor for demotivation. Will (some) jobs disappear now that ChatGPT has shown great promise in writing texts or even writing code.A different perspective is required for advertising and marketing professionals. In this field, there is already a tendency towards freelance working. Platforms and ChatGPT can support freelancers in doing their work more efficiently, though worries exist that the volume of work may diminish due to AI tools. Such worries may affect how people experience their job and their attitude to staying/leaving their position.5. Internal communication could play an important role in responding to trends such as quiet quitting and resenteeism. Using this perspective, organizations could focus on creating understanding of how these trends emerge and determine strategies for improving the connection with workers.6. We need to consider the role of work culture. Burnout literature points at the importance of investment and rewards work, thus the emotional investment from workers needs to be balanced out. Additionally, these trends are not a generational issue, where younger and older generations are opposed. Each generation has different characteristics, where younger generations have changed expectations with regards to work and workplaces, and older generations deal with lifespan challenges.7. Approaching trends in work and organizations from an immigration perspective adds valuable insights. Immigrated workers have no chance to quit because of how it is tied to the visa or permits. While this isnt the case for those who move for work within the EU, there are still cultural elements that can play a role. If immigrant workers experienced challenges such as social insecurity abroad, they might bring this mindset and related worries to (in this case) the Netherlands.If we were to study this topic, what kind of questions would we ask? To conclude the themed session, we asked ourselves how we would conduct research on quiet quitting and/or resenteeism.Research can focus on different aspects and interrelation between the micro-, meso-, and macro-level. This will help to gain understanding of how these trends, or phenomena, emerge, gain traction, and persist or dissipate. For example, on a macro-level, research might focus on how national policies related to social security, job protection, holiday and parental leave, can be influential in shaping attitudes towards work. On a meso-level, research could focus on organizations and what risk factors might exist that feed into the phenomena'],\n",
       " ['Now, back to our themed discussion! We thought it would be interesting to discuss current trends in the working world since the Covid pandemic and to approach it from the different perspectives of our members. Here are our takeaways:1. Quiet quitting is not a new phenomenon. Quiet quitting emerged as a \"trend in the workforce, especially as part of the Great Resignation during which many people left their jobs. However, it is not actually that new of a phenomenon. The idea of doing the bare minimum at work closely relates to the idea of work to rule, the -to-5 mentality, and unions.2. Rather, to understand this new (or not so new) work phenomenon, we need to consider the role of technology. Technology reorganized how we do our work and relate to each other in different ways. When considering employer-employee relationships, we noted that there has been an uptick of bossware during and after Covid, to monitor people who had to work from home.3. Quiet quitting is not possible for every worker, so they resort to resenteeism. For example, platform workers are closely monitored and are under algorithmic control. They may therefore not be able to get away with doing the bare minimum, so they do not work the minimum but do voice their discontent.4. ChatGPT may lead to more quiet quitting. Naturally, ChatGPT could not be excluded from the discussion on technology. In many contexts, ChatGPT can be very helpful in doing work more efficiently and thus minimize work effort. However, in some sectors it has also been a factor for demotivation. Will (some) jobs disappear now that ChatGPT has shown great promise in writing texts or even writing code.A different perspective is required for advertising and marketing professionals. In this field, there is already a tendency towards freelance working. Platforms and ChatGPT can support freelancers in doing their work more efficiently, though worries exist that the volume of work may diminish due to AI tools. Such worries may affect how people experience their job and their attitude to staying/leaving their position.5. Internal communication could play an important role in responding to trends such as quiet quitting and resenteeism. Using this perspective, organizations could focus on creating understanding of how these trends emerge and determine strategies for improving the connection with workers.6. We need to consider the role of work culture. Burnout literature points at the importance of investment and rewards work, thus the emotional investment from workers needs to be balanced out. Additionally, these trends are not a generational issue, where younger and older generations are opposed. Each generation has different characteristics, where younger generations have changed expectations with regards to work and workplaces, and older generations deal with lifespan challenges.7. Approaching trends in work and organizations from an immigration perspective adds valuable insights. Immigrated workers have no chance to quit because of how it is tied to the visa or permits. While this isnt the case for those who move for work within the EU, there are still cultural elements that can play a role. If immigrant workers experienced challenges such as social insecurity abroad, they might bring this mindset and related worries to (in this case) the Netherlands.If we were to study this topic, what kind of questions would we ask? To conclude the themed session, we asked ourselves how we would conduct research on quiet quitting and/or resenteeism.Research can focus on different aspects and interrelation between the micro-, meso-, and macro-level. This will help to gain understanding of how these trends, or phenomena, emerge, gain traction, and persist or dissipate. For example, on a macro-level, research might focus on how national policies related to social security, job protection, holiday and parental leave, can be influential in shaping attitudes towards work. On a meso-level, research could focus on organizations and what risk factors might exist that feed into the phenomena that we see now. On a micro-level, research might consider generational differences, cultural differences, or other similar factors that shape attitudes toward work. To give a more extensive example, a stream of research could focus on the role of work and organizations in the everyday lives of people. Are the ways of working and forms of organizing still fitting for how we shape and are shaped by society? Perhaps novel ways of organizing may offer a suitable place for changing attitudes towards work. For example, the idea of cooperatives has gained (new) life. In part, the attractiveness of cooperatives may stem from the mutual shaping of management, where workers can be more involved in decision making and trust can be fostered. Its a fine balance, because cooperation takes extra time and effort; sometimes decisions need to be made more efficiently and there can be too many loud or divergent voices to'],\n",
       " ['. Quiet quitting is not a new phenomenon. Quiet quitting emerged as a \"trend in the workforce, especially as part of the Great Resignation during which many people left their jobs. However, it is not actually that new of a phenomenon. The idea of doing the bare minimum at work closely relates to the idea of work to rule, the -to-5 mentality, and unions.2. Rather, to understand this new (or not so new) work phenomenon, we need to consider the role of technology. Technology reorganized how we do our work and relate to each other in different ways. When considering employer-employee relationships, we noted that there has been an uptick of bossware during and after Covid, to monitor people who had to work from home.3. Quiet quitting is not possible for every worker, so they resort to resenteeism. For example, platform workers are closely monitored and are under algorithmic control. They may therefore not be able to get away with doing the bare minimum, so they do not work the minimum but do voice their discontent.4. ChatGPT may lead to more quiet quitting. Naturally, ChatGPT could not be excluded from the discussion on technology. In many contexts, ChatGPT can be very helpful in doing work more efficiently and thus minimize work effort. However, in some sectors it has also been a factor for demotivation. Will (some) jobs disappear now that ChatGPT has shown great promise in writing texts or even writing code.A different perspective is required for advertising and marketing professionals. In this field, there is already a tendency towards freelance working. Platforms and ChatGPT can support freelancers in doing their work more efficiently, though worries exist that the volume of work may diminish due to AI tools. Such worries may affect how people experience their job and their attitude to staying/leaving their position.5. Internal communication could play an important role in responding to trends such as quiet quitting and resenteeism. Using this perspective, organizations could focus on creating understanding of how these trends emerge and determine strategies for improving the connection with workers.6. We need to consider the role of work culture. Burnout literature points at the importance of investment and rewards work, thus the emotional investment from workers needs to be balanced out. Additionally, these trends are not a generational issue, where younger and older generations are opposed. Each generation has different characteristics, where younger generations have changed expectations with regards to work and workplaces, and older generations deal with lifespan challenges.7. Approaching trends in work and organizations from an immigration perspective adds valuable insights. Immigrated workers have no chance to quit because of how it is tied to the visa or permits. While this isnt the case for those who move for work within the EU, there are still cultural elements that can play a role. If immigrant workers experienced challenges such as social insecurity abroad, they might bring this mindset and related worries to (in this case) the Netherlands.If we were to study this topic, what kind of questions would we ask? To conclude the themed session, we asked ourselves how we would conduct research on quiet quitting and/or resenteeism.Research can focus on different aspects and interrelation between the micro-, meso-, and macro-level. This will help to gain understanding of how these trends, or phenomena, emerge, gain traction, and persist or dissipate. For example, on a macro-level, research might focus on how national policies related to social security, job protection, holiday and parental leave, can be influential in shaping attitudes towards work. On a meso-level, research could focus on organizations and what risk factors might exist that feed into the phenomena that we see now. On a micro-level, research might consider generational differences, cultural differences, or other similar factors that shape attitudes toward work. To give a more extensive example, a stream of research could focus on the role of work and organizations in the everyday lives of people. Are the ways of working and forms of organizing still fitting for how we shape and are shaped by society? Perhaps novel ways of organizing may offer a suitable place for changing attitudes towards work. For example, the idea of cooperatives has gained (new) life. In part, the attractiveness of cooperatives may stem from the mutual shaping of management, where workers can be more involved in decision making and trust can be fostered. Its a fine balance, because cooperation takes extra time and effort; sometimes decisions need to be made more efficiently and there can be too many loud or divergent voices to deal with.Thus, the number of research ideas seems to be boundless, and we look forward to seeing what directions scholarship will take! If you are interested in the ROCCS cluster, or even want to join, please contact Tessa or Hoan.'],\n",
       " ['. Rather, to understand this new (or not so new) work phenomenon, we need to consider the role of technology. Technology reorganized how we do our work and relate to each other in different ways. When considering employer-employee relationships, we noted that there has been an uptick of bossware during and after Covid, to monitor people who had to work from home.3. Quiet quitting is not possible for every worker, so they resort to resenteeism. For example, platform workers are closely monitored and are under algorithmic control. They may therefore not be able to get away with doing the bare minimum, so they do not work the minimum but do voice their discontent.4. ChatGPT may lead to more quiet quitting. Naturally, ChatGPT could not be excluded from the discussion on technology. In many contexts, ChatGPT can be very helpful in doing work more efficiently and thus minimize work effort. However, in some sectors it has also been a factor for demotivation. Will (some) jobs disappear now that ChatGPT has shown great promise in writing texts or even writing code.A different perspective is required for advertising and marketing professionals. In this field, there is already a tendency towards freelance working. Platforms and ChatGPT can support freelancers in doing their work more efficiently, though worries exist that the volume of work may diminish due to AI tools. Such worries may affect how people experience their job and their attitude to staying/leaving their position.5. Internal communication could play an important role in responding to trends such as quiet quitting and resenteeism. Using this perspective, organizations could focus on creating understanding of how these trends emerge and determine strategies for improving the connection with workers.6. We need to consider the role of work culture. Burnout literature points at the importance of investment and rewards work, thus the emotional investment from workers needs to be balanced out. Additionally, these trends are not a generational issue, where younger and older generations are opposed. Each generation has different characteristics, where younger generations have changed expectations with regards to work and workplaces, and older generations deal with lifespan challenges.7. Approaching trends in work and organizations from an immigration perspective adds valuable insights. Immigrated workers have no chance to quit because of how it is tied to the visa or permits. While this isnt the case for those who move for work within the EU, there are still cultural elements that can play a role. If immigrant workers experienced challenges such as social insecurity abroad, they might bring this mindset and related worries to (in this case) the Netherlands.If we were to study this topic, what kind of questions would we ask? To conclude the themed session, we asked ourselves how we would conduct research on quiet quitting and/or resenteeism.Research can focus on different aspects and interrelation between the micro-, meso-, and macro-level. This will help to gain understanding of how these trends, or phenomena, emerge, gain traction, and persist or dissipate. For example, on a macro-level, research might focus on how national policies related to social security, job protection, holiday and parental leave, can be influential in shaping attitudes towards work. On a meso-level, research could focus on organizations and what risk factors might exist that feed into the phenomena that we see now. On a micro-level, research might consider generational differences, cultural differences, or other similar factors that shape attitudes toward work. To give a more extensive example, a stream of research could focus on the role of work and organizations in the everyday lives of people. Are the ways of working and forms of organizing still fitting for how we shape and are shaped by society? Perhaps novel ways of organizing may offer a suitable place for changing attitudes towards work. For example, the idea of cooperatives has gained (new) life. In part, the attractiveness of cooperatives may stem from the mutual shaping of management, where workers can be more involved in decision making and trust can be fostered. Its a fine balance, because cooperation takes extra time and effort; sometimes decisions need to be made more efficiently and there can be too many loud or divergent voices to deal with.Thus, the number of research ideas seems to be boundless, and we look forward to seeing what directions scholarship will take! If you are interested in the ROCCS cluster, or even want to join, please contact Tessa or Hoan.'],\n",
       " ['. Quiet quitting is not possible for every worker, so they resort to resenteeism. For example, platform workers are closely monitored and are under algorithmic control. They may therefore not be able to get away with doing the bare minimum, so they do not work the minimum but do voice their discontent.4. ChatGPT may lead to more quiet quitting. Naturally, ChatGPT could not be excluded from the discussion on technology. In many contexts, ChatGPT can be very helpful in doing work more efficiently and thus minimize work effort. However, in some sectors it has also been a factor for demotivation. Will (some) jobs disappear now that ChatGPT has shown great promise in writing texts or even writing code.A different perspective is required for advertising and marketing professionals. In this field, there is already a tendency towards freelance working. Platforms and ChatGPT can support freelancers in doing their work more efficiently, though worries exist that the volume of work may diminish due to AI tools. Such worries may affect how people experience their job and their attitude to staying/leaving their position.5. Internal communication could play an important role in responding to trends such as quiet quitting and resenteeism. Using this perspective, organizations could focus on creating understanding of how these trends emerge and determine strategies for improving the connection with workers.6. We need to consider the role of work culture. Burnout literature points at the importance of investment and rewards work, thus the emotional investment from workers needs to be balanced out. Additionally, these trends are not a generational issue, where younger and older generations are opposed. Each generation has different characteristics, where younger generations have changed expectations with regards to work and workplaces, and older generations deal with lifespan challenges.7. Approaching trends in work and organizations from an immigration perspective adds valuable insights. Immigrated workers have no chance to quit because of how it is tied to the visa or permits. While this isnt the case for those who move for work within the EU, there are still cultural elements that can play a role. If immigrant workers experienced challenges such as social insecurity abroad, they might bring this mindset and related worries to (in this case) the Netherlands.If we were to study this topic, what kind of questions would we ask? To conclude the themed session, we asked ourselves how we would conduct research on quiet quitting and/or resenteeism.Research can focus on different aspects and interrelation between the micro-, meso-, and macro-level. This will help to gain understanding of how these trends, or phenomena, emerge, gain traction, and persist or dissipate. For example, on a macro-level, research might focus on how national policies related to social security, job protection, holiday and parental leave, can be influential in shaping attitudes towards work. On a meso-level, research could focus on organizations and what risk factors might exist that feed into the phenomena that we see now. On a micro-level, research might consider generational differences, cultural differences, or other similar factors that shape attitudes toward work. To give a more extensive example, a stream of research could focus on the role of work and organizations in the everyday lives of people. Are the ways of working and forms of organizing still fitting for how we shape and are shaped by society? Perhaps novel ways of organizing may offer a suitable place for changing attitudes towards work. For example, the idea of cooperatives has gained (new) life. In part, the attractiveness of cooperatives may stem from the mutual shaping of management, where workers can be more involved in decision making and trust can be fostered. Its a fine balance, because cooperation takes extra time and effort; sometimes decisions need to be made more efficiently and there can be too many loud or divergent voices to deal with.Thus, the number of research ideas seems to be boundless, and we look forward to seeing what directions scholarship will take! If you are interested in the ROCCS cluster, or even want to join, please contact Tessa or Hoan.'],\n",
       " ['. ChatGPT may lead to more quiet quitting. Naturally, ChatGPT could not be excluded from the discussion on technology. In many contexts, ChatGPT can be very helpful in doing work more efficiently and thus minimize work effort. However, in some sectors it has also been a factor for demotivation. Will (some) jobs disappear now that ChatGPT has shown great promise in writing texts or even writing code.A different perspective is required for advertising and marketing professionals. In this field, there is already a tendency towards freelance working. Platforms and ChatGPT can support freelancers in doing their work more efficiently, though worries exist that the volume of work may diminish due to AI tools. Such worries may affect how people experience their job and their attitude to staying/leaving their position.5. Internal communication could play an important role in responding to trends such as quiet quitting and resenteeism. Using this perspective, organizations could focus on creating understanding of how these trends emerge and determine strategies for improving the connection with workers.6. We need to consider the role of work culture. Burnout literature points at the importance of investment and rewards work, thus the emotional investment from workers needs to be balanced out. Additionally, these trends are not a generational issue, where younger and older generations are opposed. Each generation has different characteristics, where younger generations have changed expectations with regards to work and workplaces, and older generations deal with lifespan challenges.7. Approaching trends in work and organizations from an immigration perspective adds valuable insights. Immigrated workers have no chance to quit because of how it is tied to the visa or permits. While this isnt the case for those who move for work within the EU, there are still cultural elements that can play a role. If immigrant workers experienced challenges such as social insecurity abroad, they might bring this mindset and related worries to (in this case) the Netherlands.If we were to study this topic, what kind of questions would we ask? To conclude the themed session, we asked ourselves how we would conduct research on quiet quitting and/or resenteeism.Research can focus on different aspects and interrelation between the micro-, meso-, and macro-level. This will help to gain understanding of how these trends, or phenomena, emerge, gain traction, and persist or dissipate. For example, on a macro-level, research might focus on how national policies related to social security, job protection, holiday and parental leave, can be influential in shaping attitudes towards work. On a meso-level, research could focus on organizations and what risk factors might exist that feed into the phenomena that we see now. On a micro-level, research might consider generational differences, cultural differences, or other similar factors that shape attitudes toward work. To give a more extensive example, a stream of research could focus on the role of work and organizations in the everyday lives of people. Are the ways of working and forms of organizing still fitting for how we shape and are shaped by society? Perhaps novel ways of organizing may offer a suitable place for changing attitudes towards work. For example, the idea of cooperatives has gained (new) life. In part, the attractiveness of cooperatives may stem from the mutual shaping of management, where workers can be more involved in decision making and trust can be fostered. Its a fine balance, because cooperation takes extra time and effort; sometimes decisions need to be made more efficiently and there can be too many loud or divergent voices to deal with.Thus, the number of research ideas seems to be boundless, and we look forward to seeing what directions scholarship will take! If you are interested in the ROCCS cluster, or even want to join, please contact Tessa or Hoan.'],\n",
       " ['A different perspective is required for advertising and marketing professionals. In this field, there is already a tendency towards freelance working. Platforms and ChatGPT can support freelancers in doing their work more efficiently, though worries exist that the volume of work may diminish due to AI tools. Such worries may affect how people experience their job and their attitude to staying/leaving their position.5. Internal communication could play an important role in responding to trends such as quiet quitting and resenteeism. Using this perspective, organizations could focus on creating understanding of how these trends emerge and determine strategies for improving the connection with workers.6. We need to consider the role of work culture. Burnout literature points at the importance of investment and rewards work, thus the emotional investment from workers needs to be balanced out. Additionally, these trends are not a generational issue, where younger and older generations are opposed. Each generation has different characteristics, where younger generations have changed expectations with regards to work and workplaces, and older generations deal with lifespan challenges.7. Approaching trends in work and organizations from an immigration perspective adds valuable insights. Immigrated workers have no chance to quit because of how it is tied to the visa or permits. While this isnt the case for those who move for work within the EU, there are still cultural elements that can play a role. If immigrant workers experienced challenges such as social insecurity abroad, they might bring this mindset and related worries to (in this case) the Netherlands.If we were to study this topic, what kind of questions would we ask? To conclude the themed session, we asked ourselves how we would conduct research on quiet quitting and/or resenteeism.Research can focus on different aspects and interrelation between the micro-, meso-, and macro-level. This will help to gain understanding of how these trends, or phenomena, emerge, gain traction, and persist or dissipate. For example, on a macro-level, research might focus on how national policies related to social security, job protection, holiday and parental leave, can be influential in shaping attitudes towards work. On a meso-level, research could focus on organizations and what risk factors might exist that feed into the phenomena that we see now. On a micro-level, research might consider generational differences, cultural differences, or other similar factors that shape attitudes toward work. To give a more extensive example, a stream of research could focus on the role of work and organizations in the everyday lives of people. Are the ways of working and forms of organizing still fitting for how we shape and are shaped by society? Perhaps novel ways of organizing may offer a suitable place for changing attitudes towards work. For example, the idea of cooperatives has gained (new) life. In part, the attractiveness of cooperatives may stem from the mutual shaping of management, where workers can be more involved in decision making and trust can be fostered. Its a fine balance, because cooperation takes extra time and effort; sometimes decisions need to be made more efficiently and there can be too many loud or divergent voices to deal with.Thus, the number of research ideas seems to be boundless, and we look forward to seeing what directions scholarship will take! If you are interested in the ROCCS cluster, or even want to join, please contact Tessa or Hoan.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Gabrielle explains: \"To start, a chatbot is a computer program that interacts with people who are using it, for a specific purpose. And in this case, this is a chatbot for academic goal setting. The chatbot we built is a text-based chatbot, which means input and output of the chatbot are written. It is also a rule-based chatbot, which means it relies on a set of pre-determined rules for responses. And these rules make the chatbot focus on its task: to help students through the goal setting process, which has clear phases.\"ScalabilityIn the context of goal setting, research has found that a personalized intervention carried out by a person is generally more effective than a standardized goal setting survey that a student is given to fill out. For one teacher to sit down with every student of their course is very difficult in large Bachelor or Master programmes. \"However,\" Gabrielle explains, \"the benefit of a chatbot is that it provides a solution to easily scale a more personalized goal setting procedure.\"Goalsetting cycleThe development of the chatbot focused on the cycle of goal setting, which consist of three phases: the forethought phase, the performance phase, and the reflection phase. In the forethought phase, the chatbot guides the student through setting SMIP- smart, measurable, important, and multisource- goals (an adaptation of the SMART goal approach). Then, the student goes through the performance phase, where they work to realize their goals and keep track of their progress. Afterwards, in the reflection phase, the chatbot helps the student reflect and adapt their future goals accordingly. Gabrielle reflects on this: \"I believe that setting up the chatbot with this structure, provides the most effective way for the student to set more important and achievable goals, and to learn from what didnt go to plan, as well as celebrate their successes.\"Pilot studyGabrielle has conducted a pilot study with Bachelor of Psychology students at ESSB. The feedback from this pilot study was positive, with all students saying the chatbot was easy to use, and of the students saying they preferred the chatbot to doing a survey to set goals. She will now test the chatbot for the duration of a full block- five weeks- on a larger number of ESSB Bachelor students.Technology driven support to studentsWhen asked about the future, Gabrielle sees the chatbot as a very scalable and powerful tool for goal setting, but also for research as it can gather a large amount of data. \"Because the more data the chatbot gathers, the more it will be able to improve. We aim to work on a machine learning module to implement in the chatbot, once enough data is gathered. This will allow the chatbot to assess whether a goal is of high quality by itself, rather than a moderator, such as a teacher, carrying out that process. My long-term goal is to use learning analytics to support the development of this chatbot, and to explore how technology can be leveraged to improve the support it can offer to students,\" she concludes.'],\n",
       " ['In the context of goal setting, research has found that a personalized intervention carried out by a person is generally more effective than a standardized goal setting survey that a student is given to fill out. For one teacher to sit down with every student of their course is very difficult in large Bachelor or Master programmes. \"However,\" Gabrielle explains, \"the benefit of a chatbot is that it provides a solution to easily scale a more personalized goal setting procedure.\"Goalsetting cycleThe development of the chatbot focused on the cycle of goal setting, which consist of three phases: the forethought phase, the performance phase, and the reflection phase. In the forethought phase, the chatbot guides the student through setting SMIP- smart, measurable, important, and multisource- goals (an adaptation of the SMART goal approach). Then, the student goes through the performance phase, where they work to realize their goals and keep track of their progress. Afterwards, in the reflection phase, the chatbot helps the student reflect and adapt their future goals accordingly. Gabrielle reflects on this: \"I believe that setting up the chatbot with this structure, provides the most effective way for the student to set more important and achievable goals, and to learn from what didnt go to plan, as well as celebrate their successes.\"Pilot studyGabrielle has conducted a pilot study with Bachelor of Psychology students at ESSB. The feedback from this pilot study was positive, with all students saying the chatbot was easy to use, and of the students saying they preferred the chatbot to doing a survey to set goals. She will now test the chatbot for the duration of a full block- five weeks- on a larger number of ESSB Bachelor students.Technology driven support to studentsWhen asked about the future, Gabrielle sees the chatbot as a very scalable and powerful tool for goal setting, but also for research as it can gather a large amount of data. \"Because the more data the chatbot gathers, the more it will be able to improve. We aim to work on a machine learning module to implement in the chatbot, once enough data is gathered. This will allow the chatbot to assess whether a goal is of high quality by itself, rather than a moderator, such as a teacher, carrying out that process. My long-term goal is to use learning analytics to support the development of this chatbot, and to explore how technology can be leveraged to improve the support it can offer to students,\" she concludes.'],\n",
       " ['he development of the chatbot focused on the cycle of goal setting, which consist of three phases: the forethought phase, the performance phase, and the reflection phase. In the forethought phase, the chatbot guides the student through setting SMIP- smart, measurable, important, and multisource- goals (an adaptation of the SMART goal approach). Then, the student goes through the performance phase, where they work to realize their goals and keep track of their progress. Afterwards, in the reflection phase, the chatbot helps the student reflect and adapt their future goals accordingly. Gabrielle reflects on this: \"I believe that setting up the chatbot with this structure, provides the most effective way for the student to set more important and achievable goals, and to learn from what didnt go to plan, as well as celebrate their successes.\"Pilot studyGabrielle has conducted a pilot study with Bachelor of Psychology students at ESSB. The feedback from this pilot study was positive, with all students saying the chatbot was easy to use, and of the students saying they preferred the chatbot to doing a survey to set goals. She will now test the chatbot for the duration of a full block- five weeks- on a larger number of ESSB Bachelor students.Technology driven support to studentsWhen asked about the future, Gabrielle sees the chatbot as a very scalable and powerful tool for goal setting, but also for research as it can gather a large amount of data. \"Because the more data the chatbot gathers, the more it will be able to improve. We aim to work on a machine learning module to implement in the chatbot, once enough data is gathered. This will allow the chatbot to assess whether a goal is of high quality by itself, rather than a moderator, such as a teacher, carrying out that process. My long-term goal is to use learning analytics to support the development of this chatbot, and to explore how technology can be leveraged to improve the support it can offer to students,\" she concludes.'],\n",
       " ['Gabrielle has conducted a pilot study with Bachelor of Psychology students at ESSB. The feedback from this pilot study was positive, with all students saying the chatbot was easy to use, and of the students saying they preferred the chatbot to doing a survey to set goals. She will now test the chatbot for the duration of a full block- five weeks- on a larger number of ESSB Bachelor students.Technology driven support to studentsWhen asked about the future, Gabrielle sees the chatbot as a very scalable and powerful tool for goal setting, but also for research as it can gather a large amount of data. \"Because the more data the chatbot gathers, the more it will be able to improve. We aim to work on a machine learning module to implement in the chatbot, once enough data is gathered. This will allow the chatbot to assess whether a goal is of high quality by itself, rather than a moderator, such as a teacher, carrying out that process. My long-term goal is to use learning analytics to support the development of this chatbot, and to explore how technology can be leveraged to improve the support it can offer to students,\" she concludes.'],\n",
       " ['When asked about the future, Gabrielle sees the chatbot as a very scalable and powerful tool for goal setting, but also for research as it can gather a large amount of data. \"Because the more data the chatbot gathers, the more it will be able to improve. We aim to work on a machine learning module to implement in the chatbot, once enough data is gathered. This will allow the chatbot to assess whether a goal is of high quality by itself, rather than a moderator, such as a teacher, carrying out that process. My long-term goal is to use learning analytics to support the development of this chatbot, and to explore how technology can be leveraged to improve the support it can offer to students,\" she concludes.'],\n",
       " [],\n",
       " ['Are you an academic staff and want to learn about the possibilities and potential applications of ChatGPT in higher education? Then join this two-hour workshop where you will work directly with ChatGPT with us and a group of colleagues, exploring various applications and implications in educational contexts.'],\n",
       " [\"At the end of the workshop you will be better able to assess the opportunities and challenges of ChatGPT for higher education. You will gain practical experience and leave with a better understanding of ChatGPT's potential impact on learning and teaching. The workshop is taught by Jonathan & Milan from ErasmusXOpens external. [This description is written by ChatGPT and edited by the facilitators.] Preparation Make sure that you create a ChatGPT account prior to the workshop. You can do this by going to chat.openai.comOpens external and logging in. Would you rather not create an account? Please contact info.erasmusx.nl and they will look for a solution for you. Bring your laptop so that you can experiment with ChatGPT during the workshop. A few days before the workshop you will receive a pre-survey, and after the workshop a post-survey. The results of this can be shared with you later!Sign upSign up is no longer possible.\"],\n",
       " ['he workshop is given by Jonathan & Milan from ErasmusXOpens external.[This description is written by ChatGPT and edited by the facilitators.]PreparationMake sure you create a ChatGPT account before the workshop. You can do this by going to chat.openai.comOpens external and logging in. Would you rather not create an account? Please contact info.erasmusx.nl and they will look for a solution for you. Bring your laptop so that you can experiment with ChatGPT during the workshop. A few days before the workshop you will receive a pre-survey, and after the workshop a post-survey. The results of this can be shared with you later!Sign upSign up is no longer possible.'],\n",
       " ['[This description is written by ChatGPT and edited by the facilitators.]PreparationBe sure to create a ChatGPT account prior to the workshop. You can do this by going to chat.openai.comOpens external and logging in. Would you rather not create an account? Please contact info.erasmusx.nl and they will look for a solution for you. Bring your laptop so that you can experiment with ChatGPT during the workshop. A few days before the workshop you will receive a pre-survey, and after the workshop a post-survey. The results of this can be shared with you later!Sign upSign up is no longer possible.'],\n",
       " [],\n",
       " ['Students in higher education face several challenges, related to (a) higher numbers in large classrooms (b) a lack of individual support and (c) changes in the curriculum. Research shows that students in higher education increasingly experience psychological complaints. The current model of mental health care in general, and the current system of study advisers and student psychologists in particular, is not designed for large numbers of students. A scalable solution for the prevention of wellness problems is online coaching and therapy.In the proposed project an online coaching process using a chatbot will be added to an existing intervention, that has proved to work very well in terms of student well-being and study success, namely a goalsetting intervention (Schippers, Scheepers, & Peterson, ). The chatbot can offer customized personalized help. For students who dont have many study problems, setting goals and online coaching might be enough. Students with more problems can profit from online cognitive behavioral therapy, and (with more serious complaints) referral to a study adviser or student psychologist.GoalThis proposal is aimed at developing and evaluating an intervention that aims to improve student welfare and increase resilience and academic performance of students through a combination of setting goals, feedback by a digital coach and online coaching to follow up on the goals.ResultWhen the project has finished, the results will be published.'],\n",
       " ['In the proposed project an online coaching process using a chatbot will be added to an existing intervention, that has proved to work very well in terms of student well-being and study success, namely a goalsetting intervention (Schippers, Scheepers, & Peterson, ). The chatbot can offer customized personalized help. For students who dont have many study problems, setting goals and online coaching might be enough. Students with more problems can profit from online cognitive behavioral therapy, and (with more serious complaints) referral to a study adviser or student psychologist.GoalThis proposal is aimed at developing and evaluating an intervention that aims to improve student welfare and increase resilience and academic performance of students through a combination of setting goals, feedback by a digital coach and online coaching to follow up on the goals.ResultWhen the project has finished, the results will be published.'],\n",
       " ['\"Writing a summary of the argumentative structure of a classic text has been an assignment in the philosophy bachelor for years. This year, the sudden rise of ChatGPT made this trusty form of assessment instantly obsolete. Instead of a ban and police measures, we chose to try the opposite: making ChatGPT an integral part of the assignment. The students were asked to use the help of the program in creating a thoroughly substantiated academic summary. One aim is to start developing insights in the possibilities and limitations of this program in academia: both for the students, and for us. In this presentation I will share the insights of the experiment so far.\"'],\n",
       " ['During this lunch at the Erasmus Education Lab, Rolf Viervant (ESPhil) will share the insights of using ChatGPT within the philosophy bachelor.'],\n",
       " [\"As the AI business developer for Erasmus University Rotterdam (EUR), my role involves connecting researchers at EUR to external stakeholders, scouting for opportunities for AI research, and supporting subsidy applications.Once a researcher approaches me with the request to search for external stakeholders for their current or future research projects, I define the request and formulate it in a manner to entice action from external partners. Then, I reach out to externals and schedule an initial meeting between them and the researchers to define further and align. I also support contract research, where external companies collaborate with EUR researchers or where researchers have existing contacts with external companies that lead to potential contract research opportunities. For subsidy applications, I am responsible for ensuring the parties are onboarded in time; the right stakeholders are engaged; and timely intervention in case some leads are missed or not picked up.I am also involved in defining and leading the development of strategic priorities for AI at EUR from a business development perspective in collaboration with Erasmus Research Services (ERS) management and other EUR stakeholders. For example, I acted on the strategic opportunity to include fintech, energy and port in Convergence AIOpens external multi-year plans. I am developing the plans for the Convergence centre for fintech with input from researchers. I also scoped out three areas of future work research within the EUR, including platform economy, robotics and automation, and labor productivity and research in AI ethics to enable stronger connections and representation of our research.In addition, I work on internal alignment with stakeholders on AI within EUR, supporting programs such as ECDAOpens external and AI external. My work also involves representing and aligning with Convergence AI activities, where I initiated discussions of multi-year plans around energy, port, and fintech. In short, my job is to connect people and opportunities, align interests, and facilitate know-how to bring together the best external partners for researchers at EUR.2. Can you discuss any notable collaborations or projects that have come out of these partnerships?During my time as the business developer for AI-MAPS ELSA Labs, we were able to secure Million in funding and establish partnerships with several internal and external parties in AI, surveillance, privacy, policing and law. One highlight from this project included securing three critically important partners for the proposal with just four days until the deadline: a G partner, a major international industry partner and the leading European human rights organization.Additionally, I led the collaboration between EUR and TU Delft for the launch of Zuid Holland SME AI clinics within the NWO funded ROBUST programOpens external, from which EUR also has its first ICAI Labs. The clinic aims to help small- to medium-sized enterprises (SMEs)/MKBs in the Netherlands overcome hurdles in adopting data science technologies.I am working on developing a Convergence center for fintech, which will focus on generating synthetic and encrypted data sets for use in test cases, text mining for large language models in financial research, and econometrics, and building an IT infrastructure to enable secure data sharing and computations across partners, including external companies.I am also proud to have helped EUR become an associate partner for TTT.AIOpens external, a national project focused on supporting AI startups from universities, and to have developed a proposal for the GroenvermogenOpens external, WP2 call on Hydrogen Transport and Storage, where EUR is now a consortium member. Lastly, I led EUR's community partnership for the World AI Summit Opens external, which will help us gain broader exposure for EUR AI research.3. What are the developments in the field of AI that EUR could capitalize on?We are currently living in a defining moment in AI history with the confluence of increasing computing power, availability of data which is being collected at a massive scale and algorithmic advancements. While this has been brewing since around early s with the popularity of deep learning, the launch of ChatGPT has made AI accessible and even fun (in some cases) to use for the masses with impact of all domains whether it is writing articles or developing a new website.With this there are new concerns around the LLMs (Large Language Models) like GPT-4, which powers ChatGPT, and the almost race against time in which tech giants are commercializing developments. The promise of LLMs is the ability to generate content which in most cases is indistinguishable from human-level content. One of the biggest criticisms is do these developed LLMs help solve any real-world problems?. With future developments, we could see algorithms being managed and monitored by other algorithms and the development of aut\"],\n",
       " [\"Once a researcher approaches me with the request to search for external stakeholders for their current or future research projects, I define the request and formulate it in a manner to entice action from external partners. Then, I reach out to externals and schedule an initial meeting between them and the researchers to define further and align. I also support contract research, where external companies collaborate with EUR researchers or where researchers have existing contacts with external companies that lead to potential contract research opportunities. For subsidy applications, I am responsible for ensuring the parties are onboarded in time; the right stakeholders are engaged; and timely intervention in case some leads are missed or not picked up.I am also involved in defining and leading the development of strategic priorities for AI at EUR from a business development perspective in collaboration with Erasmus Research Services (ERS) management and other EUR stakeholders. For example, I acted on the strategic opportunity to include fintech, energy and port in Convergence AIOpens external multi-year plans. I am developing the plans for the Convergence centre for fintech with input from researchers. I also scoped out three areas of future work research within the EUR, including platform economy, robotics and automation, and labor productivity and research in AI ethics to enable stronger connections and representation of our research.In addition, I work on internal alignment with stakeholders on AI within EUR, supporting programs such as ECDAOpens external and AI external. My work also involves representing and aligning with Convergence AI activities, where I initiated discussions of multi-year plans around energy, port, and fintech. In short, my job is to connect people and opportunities, align interests, and facilitate know-how to bring together the best external partners for researchers at EUR.2. Can you discuss any notable collaborations or projects that have come out of these partnerships?During my time as the business developer for AI-MAPS ELSA Labs, we were able to secure Million in funding and establish partnerships with several internal and external parties in AI, surveillance, privacy, policing and law. One highlight from this project included securing three critically important partners for the proposal with just four days until the deadline: a G partner, a major international industry partner and the leading European human rights organization.Additionally, I led the collaboration between EUR and TU Delft for the launch of Zuid Holland SME AI clinics within the NWO funded ROBUST programOpens external, from which EUR also has its first ICAI Labs. The clinic aims to help small- to medium-sized enterprises (SMEs)/MKBs in the Netherlands overcome hurdles in adopting data science technologies.I am working on developing a Convergence center for fintech, which will focus on generating synthetic and encrypted data sets for use in test cases, text mining for large language models in financial research, and econometrics, and building an IT infrastructure to enable secure data sharing and computations across partners, including external companies.I am also proud to have helped EUR become an associate partner for TTT.AIOpens external, a national project focused on supporting AI startups from universities, and to have developed a proposal for the GroenvermogenOpens external, WP2 call on Hydrogen Transport and Storage, where EUR is now a consortium member. Lastly, I led EUR's community partnership for the World AI Summit Opens external, which will help us gain broader exposure for EUR AI research.3. What are the developments in the field of AI that EUR could capitalize on?We are currently living in a defining moment in AI history with the confluence of increasing computing power, availability of data which is being collected at a massive scale and algorithmic advancements. While this has been brewing since around early s with the popularity of deep learning, the launch of ChatGPT has made AI accessible and even fun (in some cases) to use for the masses with impact of all domains whether it is writing articles or developing a new website.With this there are new concerns around the LLMs (Large Language Models) like GPT-4, which powers ChatGPT, and the almost race against time in which tech giants are commercializing developments. The promise of LLMs is the ability to generate content which in most cases is indistinguishable from human-level content. One of the biggest criticisms is do these developed LLMs help solve any real-world problems?. With future developments, we could see algorithms being managed and monitored by other algorithms and the development of autonomous agents capable of executing tasks without human intervention.Broadly I think EUR is very well positioned to address three key areasur community understanding and relationship with AI I believe we as EUR are uni\"],\n",
       " [\"I am also involved in defining and leading the development of strategic priorities for AI at EUR from a business development perspective in collaboration with Erasmus Research Services (ERS) management and other EUR stakeholders. For example, I acted on the strategic opportunity to include fintech, energy and port in Convergence AIOpens external multi-year plans. I am developing the plans for the Convergence centre for fintech with input from researchers. I also scoped out three areas of future work research within the EUR, including platform economy, robotics and automation, and labor productivity and research in AI ethics to enable stronger connections and representation of our research.In addition, I work on internal alignment with stakeholders on AI within EUR, supporting programs such as ECDAOpens external and AI external. My work also involves representing and aligning with Convergence AI activities, where I initiated discussions of multi-year plans around energy, port, and fintech. In short, my job is to connect people and opportunities, align interests, and facilitate know-how to bring together the best external partners for researchers at EUR.2. Can you discuss any notable collaborations or projects that have come out of these partnerships?During my time as the business developer for AI-MAPS ELSA Labs, we were able to secure Million in funding and establish partnerships with several internal and external parties in AI, surveillance, privacy, policing and law. One highlight from this project included securing three critically important partners for the proposal with just four days until the deadline: a G partner, a major international industry partner and the leading European human rights organization.Additionally, I led the collaboration between EUR and TU Delft for the launch of Zuid Holland SME AI clinics within the NWO funded ROBUST programOpens external, from which EUR also has its first ICAI Labs. The clinic aims to help small- to medium-sized enterprises (SMEs)/MKBs in the Netherlands overcome hurdles in adopting data science technologies.I am working on developing a Convergence center for fintech, which will focus on generating synthetic and encrypted data sets for use in test cases, text mining for large language models in financial research, and econometrics, and building an IT infrastructure to enable secure data sharing and computations across partners, including external companies.I am also proud to have helped EUR become an associate partner for TTT.AIOpens external, a national project focused on supporting AI startups from universities, and to have developed a proposal for the GroenvermogenOpens external, WP2 call on Hydrogen Transport and Storage, where EUR is now a consortium member. Lastly, I led EUR's community partnership for the World AI Summit Opens external, which will help us gain broader exposure for EUR AI research.3. What are the developments in the field of AI that EUR could capitalize on?We are currently living in a defining moment in AI history with the confluence of increasing computing power, availability of data which is being collected at a massive scale and algorithmic advancements. While this has been brewing since around early s with the popularity of deep learning, the launch of ChatGPT has made AI accessible and even fun (in some cases) to use for the masses with impact of all domains whether it is writing articles or developing a new website.With this there are new concerns around the LLMs (Large Language Models) like GPT-4, which powers ChatGPT, and the almost race against time in which tech giants are commercializing developments. The promise of LLMs is the ability to generate content which in most cases is indistinguishable from human-level content. One of the biggest criticisms is do these developed LLMs help solve any real-world problems?. With future developments, we could see algorithms being managed and monitored by other algorithms and the development of autonomous agents capable of executing tasks without human intervention.Broadly I think EUR is very well positioned to address three key areasur community understanding and relationship with AI I believe we as EUR are uniquely positioned to educate, create, and nurture the understanding broader society has with AI whether it is addressing financial inclusion, energy poverty, arts and culture, communication, AI in education etc. We can also play a key role in defining how the employment of the future would look like with more and more white-collar tasks being done or supplemented by AI.Legal and ethical aspects around AI In many ways, LLMs are black boxes spitting out fabricated information and/ or untrue information in some cases and ripe for misuse by malicious actors. With our law, philosophy, management, history, culture, and communication schools we have the expertise to be at the forefront of addressing the complex legal and ethical questions that arise with thi\"],\n",
       " [\"In addition, I work on internal alignment with stakeholders on AI within EUR, supporting programs such as ECDAOpens external and AI external. My work also involves representing and aligning with Convergence AI activities, where I initiated discussions of multi-year plans around energy, port, and fintech. In short, my job is to connect people and opportunities, align interests, and facilitate know-how to bring together the best external partners for researchers at EUR.2. Can you discuss any notable collaborations or projects that have come out of these partnerships?During my time as the business developer for AI-MAPS ELSA Labs, we were able to secure Million in funding and establish partnerships with several internal and external parties in AI, surveillance, privacy, policing and law. One highlight from this project included securing three critically important partners for the proposal with just four days until the deadline: a G partner, a major international industry partner and the leading European human rights organization.Additionally, I led the collaboration between EUR and TU Delft for the launch of Zuid Holland SME AI clinics within the NWO funded ROBUST programOpens external, from which EUR also has its first ICAI Labs. The clinic aims to help small- to medium-sized enterprises (SMEs)/MKBs in the Netherlands overcome hurdles in adopting data science technologies.I am working on developing a Convergence center for fintech, which will focus on generating synthetic and encrypted data sets for use in test cases, text mining for large language models in financial research, and econometrics, and building an IT infrastructure to enable secure data sharing and computations across partners, including external companies.I am also proud to have helped EUR become an associate partner for TTT.AIOpens external, a national project focused on supporting AI startups from universities, and to have developed a proposal for the GroenvermogenOpens external, WP2 call on Hydrogen Transport and Storage, where EUR is now a consortium member. Lastly, I led EUR's community partnership for the World AI Summit Opens external, which will help us gain broader exposure for EUR AI research.3. What are the developments in the field of AI that EUR could capitalize on?We are currently living in a defining moment in AI history with the confluence of increasing computing power, availability of data which is being collected at a massive scale and algorithmic advancements. While this has been brewing since around early s with the popularity of deep learning, the launch of ChatGPT has made AI accessible and even fun (in some cases) to use for the masses with impact of all domains whether it is writing articles or developing a new website.With this there are new concerns around the LLMs (Large Language Models) like GPT-4, which powers ChatGPT, and the almost race against time in which tech giants are commercializing developments. The promise of LLMs is the ability to generate content which in most cases is indistinguishable from human-level content. One of the biggest criticisms is do these developed LLMs help solve any real-world problems?. With future developments, we could see algorithms being managed and monitored by other algorithms and the development of autonomous agents capable of executing tasks without human intervention.Broadly I think EUR is very well positioned to address three key areasur community understanding and relationship with AI I believe we as EUR are uniquely positioned to educate, create, and nurture the understanding broader society has with AI whether it is addressing financial inclusion, energy poverty, arts and culture, communication, AI in education etc. We can also play a key role in defining how the employment of the future would look like with more and more white-collar tasks being done or supplemented by AI.Legal and ethical aspects around AI In many ways, LLMs are black boxes spitting out fabricated information and/ or untrue information in some cases and ripe for misuse by malicious actors. With our law, philosophy, management, history, culture, and communication schools we have the expertise to be at the forefront of addressing the complex legal and ethical questions that arise with this boom in AI. Unique is also our perspectives on the environmental impact and ensuring the windfall from these developments is distributed equally to communities (inclusive prosperity).What does it mean to be human? With near human capabilities of LLMs in some tasks, from a more philosophical perspective the question also arises what defines us as humans. At EUR, we would be able to look at it from a socio-cultural perspective while addressing the fundamental shifts that would happen due to AI.4. What is needed for EUR to unmissable in the field of AI?There is stellar research being done at EUR around the broader impact of AI on and in society and our impact would be greater through stro\"],\n",
       " [\"During my time as the business developer for AI-MAPS ELSA Labs, we were able to secure Million in funding and establish partnerships with several internal and external parties in AI, surveillance, privacy, policing and law. One highlight from this project included securing three critically important partners for the proposal with just four days until the deadline: a G partner, a major international industry partner and the leading European human rights organization.Additionally, I led the collaboration between EUR and TU Delft for the launch of Zuid Holland SME AI clinics within the NWO funded ROBUST programOpens external, from which EUR also has its first ICAI Labs. The clinic aims to help small- to medium-sized enterprises (SMEs)/MKBs in the Netherlands overcome hurdles in adopting data science technologies.I am working on developing a Convergence center for fintech, which will focus on generating synthetic and encrypted data sets for use in test cases, text mining for large language models in financial research, and econometrics, and building an IT infrastructure to enable secure data sharing and computations across partners, including external companies.I am also proud to have helped EUR become an associate partner for TTT.AIOpens external, a national project focused on supporting AI startups from universities, and to have developed a proposal for the GroenvermogenOpens external, WP2 call on Hydrogen Transport and Storage, where EUR is now a consortium member. Lastly, I led EUR's community partnership for the World AI Summit Opens external, which will help us gain broader exposure for EUR AI research.3. What are the developments in the field of AI that EUR could capitalize on?We are currently living in a defining moment in AI history with the confluence of increasing computing power, availability of data which is being collected at a massive scale and algorithmic advancements. While this has been brewing since around early s with the popularity of deep learning, the launch of ChatGPT has made AI accessible and even fun (in some cases) to use for the masses with impact of all domains whether it is writing articles or developing a new website.With this there are new concerns around the LLMs (Large Language Models) like GPT-4, which powers ChatGPT, and the almost race against time in which tech giants are commercializing developments. The promise of LLMs is the ability to generate content which in most cases is indistinguishable from human-level content. One of the biggest criticisms is do these developed LLMs help solve any real-world problems?. With future developments, we could see algorithms being managed and monitored by other algorithms and the development of autonomous agents capable of executing tasks without human intervention.Broadly I think EUR is very well positioned to address three key areasur community understanding and relationship with AI I believe we as EUR are uniquely positioned to educate, create, and nurture the understanding broader society has with AI whether it is addressing financial inclusion, energy poverty, arts and culture, communication, AI in education etc. We can also play a key role in defining how the employment of the future would look like with more and more white-collar tasks being done or supplemented by AI.Legal and ethical aspects around AI In many ways, LLMs are black boxes spitting out fabricated information and/ or untrue information in some cases and ripe for misuse by malicious actors. With our law, philosophy, management, history, culture, and communication schools we have the expertise to be at the forefront of addressing the complex legal and ethical questions that arise with this boom in AI. Unique is also our perspectives on the environmental impact and ensuring the windfall from these developments is distributed equally to communities (inclusive prosperity).What does it mean to be human? With near human capabilities of LLMs in some tasks, from a more philosophical perspective the question also arises what defines us as humans. At EUR, we would be able to look at it from a socio-cultural perspective while addressing the fundamental shifts that would happen due to AI.4. What is needed for EUR to unmissable in the field of AI?There is stellar research being done at EUR around the broader impact of AI on and in society and our impact would be greater through stronger representation of EUR on events around AI, national and international, stronger internal alignment, better organization to overcome siloed initiatives, strengthening incentives for researchers to work in interdisciplinary manner, expanding the number of researchers around key strategic areas related to AI and broadening the support provided to researchers to capitalize on the initiatives. By implementing these measures, EUR can make a significant contribution towards shaping the future of AI in society and paving the way for a more collaborative and impactful researc\"],\n",
       " [\"Additionally, I led the collaboration between EUR and TU Delft for the launch of Zuid Holland SME AI clinics within the NWO funded ROBUST programOpens external, from which EUR also has its first ICAI Labs. The clinic aims to help small- to medium-sized enterprises (SMEs)/MKBs in the Netherlands overcome hurdles in adopting data science technologies.I am working on developing a Convergence center for fintech, which will focus on generating synthetic and encrypted data sets for use in test cases, text mining for large language models in financial research, and econometrics, and building an IT infrastructure to enable secure data sharing and computations across partners, including external companies.I am also proud to have helped EUR become an associate partner for TTT.AIOpens external, a national project focused on supporting AI startups from universities, and to have developed a proposal for the GroenvermogenOpens external, WP2 call on Hydrogen Transport and Storage, where EUR is now a consortium member. Lastly, I led EUR's community partnership for the World AI Summit Opens external, which will help us gain broader exposure for EUR AI research.3. What are the developments in the field of AI that EUR could capitalize on?We are currently living in a defining moment in AI history with the confluence of increasing computing power, availability of data which is being collected at a massive scale and algorithmic advancements. While this has been brewing since around early s with the popularity of deep learning, the launch of ChatGPT has made AI accessible and even fun (in some cases) to use for the masses with impact of all domains whether it is writing articles or developing a new website.With this there are new concerns around the LLMs (Large Language Models) like GPT-4, which powers ChatGPT, and the almost race against time in which tech giants are commercializing developments. The promise of LLMs is the ability to generate content which in most cases is indistinguishable from human-level content. One of the biggest criticisms is do these developed LLMs help solve any real-world problems?. With future developments, we could see algorithms being managed and monitored by other algorithms and the development of autonomous agents capable of executing tasks without human intervention.Broadly I think EUR is very well positioned to address three key areasur community understanding and relationship with AI I believe we as EUR are uniquely positioned to educate, create, and nurture the understanding broader society has with AI whether it is addressing financial inclusion, energy poverty, arts and culture, communication, AI in education etc. We can also play a key role in defining how the employment of the future would look like with more and more white-collar tasks being done or supplemented by AI.Legal and ethical aspects around AI In many ways, LLMs are black boxes spitting out fabricated information and/ or untrue information in some cases and ripe for misuse by malicious actors. With our law, philosophy, management, history, culture, and communication schools we have the expertise to be at the forefront of addressing the complex legal and ethical questions that arise with this boom in AI. Unique is also our perspectives on the environmental impact and ensuring the windfall from these developments is distributed equally to communities (inclusive prosperity).What does it mean to be human? With near human capabilities of LLMs in some tasks, from a more philosophical perspective the question also arises what defines us as humans. At EUR, we would be able to look at it from a socio-cultural perspective while addressing the fundamental shifts that would happen due to AI.4. What is needed for EUR to unmissable in the field of AI?There is stellar research being done at EUR around the broader impact of AI on and in society and our impact would be greater through stronger representation of EUR on events around AI, national and international, stronger internal alignment, better organization to overcome siloed initiatives, strengthening incentives for researchers to work in interdisciplinary manner, expanding the number of researchers around key strategic areas related to AI and broadening the support provided to researchers to capitalize on the initiatives. By implementing these measures, EUR can make a significant contribution towards shaping the future of AI in society and paving the way for a more collaborative and impactful research community.For more information contact: ERS Business Development & Knowledge Transfer Team kto.nl\"],\n",
       " [\"I am working on developing a Convergence center for fintech, which will focus on generating synthetic and encrypted data sets for use in test cases, text mining for large language models in financial research, and econometrics, and building an IT infrastructure to enable secure data sharing and computations across partners, including external companies.I am also proud to have helped EUR become an associate partner for TTT.AIOpens external, a national project focused on supporting AI startups from universities, and to have developed a proposal for the GroenvermogenOpens external, WP2 call on Hydrogen Transport and Storage, where EUR is now a consortium member. Lastly, I led EUR's community partnership for the World AI Summit Opens external, which will help us gain broader exposure for EUR AI research.3. What are the developments in the field of AI that EUR could capitalize on?We are currently living in a defining moment in AI history with the confluence of increasing computing power, availability of data which is being collected at a massive scale and algorithmic advancements. While this has been brewing since around early s with the popularity of deep learning, the launch of ChatGPT has made AI accessible and even fun (in some cases) to use for the masses with impact of all domains whether it is writing articles or developing a new website.With this there are new concerns around the LLMs (Large Language Models) like GPT-4, which powers ChatGPT, and the almost race against time in which tech giants are commercializing developments. The promise of LLMs is the ability to generate content which in most cases is indistinguishable from human-level content. One of the biggest criticisms is do these developed LLMs help solve any real-world problems?. With future developments, we could see algorithms being managed and monitored by other algorithms and the development of autonomous agents capable of executing tasks without human intervention.Broadly I think EUR is very well positioned to address three key areasur community understanding and relationship with AI I believe we as EUR are uniquely positioned to educate, create, and nurture the understanding broader society has with AI whether it is addressing financial inclusion, energy poverty, arts and culture, communication, AI in education etc. We can also play a key role in defining how the employment of the future would look like with more and more white-collar tasks being done or supplemented by AI.Legal and ethical aspects around AI In many ways, LLMs are black boxes spitting out fabricated information and/ or untrue information in some cases and ripe for misuse by malicious actors. With our law, philosophy, management, history, culture, and communication schools we have the expertise to be at the forefront of addressing the complex legal and ethical questions that arise with this boom in AI. Unique is also our perspectives on the environmental impact and ensuring the windfall from these developments is distributed equally to communities (inclusive prosperity).What does it mean to be human? With near human capabilities of LLMs in some tasks, from a more philosophical perspective the question also arises what defines us as humans. At EUR, we would be able to look at it from a socio-cultural perspective while addressing the fundamental shifts that would happen due to AI.4. What is needed for EUR to unmissable in the field of AI?There is stellar research being done at EUR around the broader impact of AI on and in society and our impact would be greater through stronger representation of EUR on events around AI, national and international, stronger internal alignment, better organization to overcome siloed initiatives, strengthening incentives for researchers to work in interdisciplinary manner, expanding the number of researchers around key strategic areas related to AI and broadening the support provided to researchers to capitalize on the initiatives. By implementing these measures, EUR can make a significant contribution towards shaping the future of AI in society and paving the way for a more collaborative and impactful research community.For more information contact: ERS Business Development & Knowledge Transfer Team kto.nl\"],\n",
       " [\"I am also proud to have helped EUR become an associate partner for TTT.AIOpens external, a national project focused on supporting AI startups from universities, and to have developed a proposal for the GroenvermogenOpens external, WP2 call on Hydrogen Transport and Storage, where EUR is now a consortium member. Lastly, I led EUR's community partnership for the World AI Summit Opens external, which will help us gain broader exposure for EUR AI research.3. What are the developments in the field of AI that EUR could capitalize on?We are currently living in a defining moment in AI history with the confluence of increasing computing power, availability of data which is being collected at a massive scale and algorithmic advancements. While this has been brewing since around early s with the popularity of deep learning, the launch of ChatGPT has made AI accessible and even fun (in some cases) to use for the masses with impact of all domains whether it is writing articles or developing a new website.With this there are new concerns around the LLMs (Large Language Models) like GPT-4, which powers ChatGPT, and the almost race against time in which tech giants are commercializing developments. The promise of LLMs is the ability to generate content which in most cases is indistinguishable from human-level content. One of the biggest criticisms is do these developed LLMs help solve any real-world problems?. With future developments, we could see algorithms being managed and monitored by other algorithms and the development of autonomous agents capable of executing tasks without human intervention.Broadly I think EUR is very well positioned to address three key areasur community understanding and relationship with AI I believe we as EUR are uniquely positioned to educate, create, and nurture the understanding broader society has with AI whether it is addressing financial inclusion, energy poverty, arts and culture, communication, AI in education etc. We can also play a key role in defining how the employment of the future would look like with more and more white-collar tasks being done or supplemented by AI.Legal and ethical aspects around AI In many ways, LLMs are black boxes spitting out fabricated information and/ or untrue information in some cases and ripe for misuse by malicious actors. With our law, philosophy, management, history, culture, and communication schools we have the expertise to be at the forefront of addressing the complex legal and ethical questions that arise with this boom in AI. Unique is also our perspectives on the environmental impact and ensuring the windfall from these developments is distributed equally to communities (inclusive prosperity).What does it mean to be human? With near human capabilities of LLMs in some tasks, from a more philosophical perspective the question also arises what defines us as humans. At EUR, we would be able to look at it from a socio-cultural perspective while addressing the fundamental shifts that would happen due to AI.4. What is needed for EUR to unmissable in the field of AI?There is stellar research being done at EUR around the broader impact of AI on and in society and our impact would be greater through stronger representation of EUR on events around AI, national and international, stronger internal alignment, better organization to overcome siloed initiatives, strengthening incentives for researchers to work in interdisciplinary manner, expanding the number of researchers around key strategic areas related to AI and broadening the support provided to researchers to capitalize on the initiatives. By implementing these measures, EUR can make a significant contribution towards shaping the future of AI in society and paving the way for a more collaborative and impactful research community.For more information contact: ERS Business Development & Knowledge Transfer Team kto.nl\"],\n",
       " ['We are currently living in a defining moment in AI history with the confluence of increasing computing power, availability of data which is being collected at a massive scale and algorithmic advancements. While this has been brewing since around early s with the popularity of deep learning, the launch of ChatGPT has made AI accessible and even fun (in some cases) to use for the masses with impact of all domains whether it is writing articles or developing a new website.With this there are new concerns around the LLMs (Large Language Models) like GPT-4, which powers ChatGPT, and the almost race against time in which tech giants are commercializing developments. The promise of LLMs is the ability to generate content which in most cases is indistinguishable from human-level content. One of the biggest criticisms is do these developed LLMs help solve any real-world problems?. With future developments, we could see algorithms being managed and monitored by other algorithms and the development of autonomous agents capable of executing tasks without human intervention.Broadly I think EUR is very well positioned to address three key areasur community understanding and relationship with AI I believe we as EUR are uniquely positioned to educate, create, and nurture the understanding broader society has with AI whether it is addressing financial inclusion, energy poverty, arts and culture, communication, AI in education etc. We can also play a key role in defining how the employment of the future would look like with more and more white-collar tasks being done or supplemented by AI.Legal and ethical aspects around AI In many ways, LLMs are black boxes spitting out fabricated information and/ or untrue information in some cases and ripe for misuse by malicious actors. With our law, philosophy, management, history, culture, and communication schools we have the expertise to be at the forefront of addressing the complex legal and ethical questions that arise with this boom in AI. Unique is also our perspectives on the environmental impact and ensuring the windfall from these developments is distributed equally to communities (inclusive prosperity).What does it mean to be human? With near human capabilities of LLMs in some tasks, from a more philosophical perspective the question also arises what defines us as humans. At EUR, we would be able to look at it from a socio-cultural perspective while addressing the fundamental shifts that would happen due to AI.4. What is needed for EUR to unmissable in the field of AI?There is stellar research being done at EUR around the broader impact of AI on and in society and our impact would be greater through stronger representation of EUR on events around AI, national and international, stronger internal alignment, better organization to overcome siloed initiatives, strengthening incentives for researchers to work in interdisciplinary manner, expanding the number of researchers around key strategic areas related to AI and broadening the support provided to researchers to capitalize on the initiatives. By implementing these measures, EUR can make a significant contribution towards shaping the future of AI in society and paving the way for a more collaborative and impactful research community.For more information contact: ERS Business Development & Knowledge Transfer Team kto.nl'],\n",
       " ['With this there are new concerns around the LLMs (Large Language Models) like GPT-4, which powers ChatGPT, and the almost race against time in which tech giants are commercializing developments. The promise of LLMs is the ability to generate content which in most cases is indistinguishable from human-level content. One of the biggest criticisms is do these developed LLMs help solve any real-world problems?. With future developments, we could see algorithms being managed and monitored by other algorithms and the development of autonomous agents capable of executing tasks without human intervention.Broadly I think EUR is very well positioned to address three key areasur community understanding and relationship with AI I believe we as EUR are uniquely positioned to educate, create, and nurture the understanding broader society has with AI whether it is addressing financial inclusion, energy poverty, arts and culture, communication, AI in education etc. We can also play a key role in defining how the employment of the future would look like with more and more white-collar tasks being done or supplemented by AI.Legal and ethical aspects around AI In many ways, LLMs are black boxes spitting out fabricated information and/ or untrue information in some cases and ripe for misuse by malicious actors. With our law, philosophy, management, history, culture, and communication schools we have the expertise to be at the forefront of addressing the complex legal and ethical questions that arise with this boom in AI. Unique is also our perspectives on the environmental impact and ensuring the windfall from these developments is distributed equally to communities (inclusive prosperity).What does it mean to be human? With near human capabilities of LLMs in some tasks, from a more philosophical perspective the question also arises what defines us as humans. At EUR, we would be able to look at it from a socio-cultural perspective while addressing the fundamental shifts that would happen due to AI.4. What is needed for EUR to unmissable in the field of AI?There is stellar research being done at EUR around the broader impact of AI on and in society and our impact would be greater through stronger representation of EUR on events around AI, national and international, stronger internal alignment, better organization to overcome siloed initiatives, strengthening incentives for researchers to work in interdisciplinary manner, expanding the number of researchers around key strategic areas related to AI and broadening the support provided to researchers to capitalize on the initiatives. By implementing these measures, EUR can make a significant contribution towards shaping the future of AI in society and paving the way for a more collaborative and impactful research community.For more information contact: ERS Business Development & Knowledge Transfer Team kto.nl'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Following Eduard, Kim van Broekhoven presented the educational implications of ChatGPT and generative AI in an academic context. Kim highlighted the fact that, although it gives the impression that it understands as a human could understand, ChatGPT and other AI can only replicate and generate output- but not understand it as a human would. Kim mentioned that AI provides the opportunity of moving away from assembly-line style working, as students can use it as a tool to expand their capabilities and solve wicked problems. She also sees opportunities for students to learn using ChatGPT, such as learning by teaching- using ChatGPT to generate output that then students have to critically analyze and assess how correct it is. However, she also sees a lot of limitations and potential problems that come with students using and relying on ChatGPT, such as damage to academic writing skills. Overall, Kim concluded with a point to sum up an academic perspective on ChatGPT: AI can help with the product, but not the process, in academia.Student perspectives on ChatGPTThe event then concluded with a panel discussion, where the students and the panelists discussed their views and questions about ChatGPT. The discussion focused a lot on whether the use of ChatGPT is something that can be prevented, or is it now part of our lives and here to stay. The consensus from both the professional and academic side is that no matter how hard someone works to gatekeep its use, it will keep developing to be able to overtake software that is supposed to prevent it. Students also asked if to get good results, ChatGPT is needed. Kim mentioned a research paper in which students who did use ChatGPT on average scored better, however for high performing students ChatGPT didnt enhance their performance by much- but it did for low performing students. This shows that ChatGPT has the potential to narrow down the range of scores in academic performance.ConclusionAll in all, the event was a successful and insightful look into ChatGPT and generative AI in education. While no one has a clear answer about what ChatGPT should and shouldnt be used for, everyone has an opinion on it.'],\n",
       " ['he event then concluded with a panel discussion, where the students and the panelists discussed their views and questions about ChatGPT. The discussion focused a lot on whether the use of ChatGPT is something that can be prevented, or is it now part of our lives and here to stay. The consensus from both the professional and academic side is that no matter how hard someone works to gatekeep its use, it will keep developing to be able to overtake software that is supposed to prevent it. Students also asked if to get good results, ChatGPT is needed. Kim mentioned a research paper in which students who did use ChatGPT on average scored better, however for high performing students ChatGPT didnt enhance their performance by much- but it did for low performing students. This shows that ChatGPT has the potential to narrow down the range of scores in academic performance.ConclusionAll in all, the event was a successful and insightful look into ChatGPT and generative AI in education. While no one has a clear answer about what ChatGPT should and shouldnt be used for, everyone has an opinion on it.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [\"here are many exciting developments happening in the field of Artificial Intelligence (AI). What implications does this have for education at Erasmus University Rotterdam (EUR)? On this page, you will find an overview of relevant information and developments within our university. This information has been gathered from contributions by experts, users, and task forces. AI has been on everyone's mind for a while now, with developments following each other at lightning speed. For this reason, this page will be updated regularly.\"],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['For the most part, students were enthusiastic and interested in using ChatGPT for the assignment. There were a couple of students who were hesitant about the programme, Rolf mentioned, but they were a small minority who were concerned that this would replace the standard working process.In the first part of the assignment, students were shocked at how well the AI was able to produce a complete summary of the text within the strict word count of the assignment. But during the second and third part, as the students began to study the text more and understand it better, there was a shock in the opposite direction- students were shocked at how many mistakes the AI would make. The biggest drawback is the implicit assumptions that the AI incorporates, Rolf explains. If a student doesnt know the text that well, they cant spot these biases but the more they know the text, the easier it is for them to see how an AI like ChatGPT easily incorporates these biases into its output.Takeaways and next stepsOverall, Rolf believes that AI and programs like ChatGPT are here to stay. He does see some significant drawbacks in them, such as the implicit assumptions and wrong information it provides at times. However, he believes that we cannot simply ignore and look away from such developments. We need to actively look for the best ways to use them in an academically sound manner. When asked, he says he would like to keep it as part of his course next year. However, he is aware that AI is developing and changing at an extremely fast pace, so he is unsure of how it will look to incorporate it into a future course.Overall, he believes that there is a lot of potential for AI in education, across faculties and disciplines, based on the broad (although sometimes flawed) knowledge it provides, as well as the academic skills that are developed in learning how to use and work with this type of programme. Hes not sure that its great for a deep understanding of a subject matter (which is often needed for philosophy courses) but its great for a general understanding to help students get started.'],\n",
       " ['In the first part of the assignment, students were shocked at how well the AI was able to produce a complete summary of the text within the strict word count of the assignment. But during the second and third part, as the students began to study the text more and understand it better, there was a shock in the opposite direction- students were shocked at how many mistakes the AI would make. The biggest drawback is the implicit assumptions that the AI incorporates, Rolf explains. If a student doesnt know the text that well, they cant spot these biases but the more they know the text, the easier it is for them to see how an AI like ChatGPT easily incorporates these biases into its output.Takeaways and next stepsOverall, Rolf believes that AI and programs like ChatGPT are here to stay. He does see some significant drawbacks in them, such as the implicit assumptions and wrong information it provides at times. However, he believes that we cannot simply ignore and look away from such developments. We need to actively look for the best ways to use them in an academically sound manner. When asked, he says he would like to keep it as part of his course next year. However, he is aware that AI is developing and changing at an extremely fast pace, so he is unsure of how it will look to incorporate it into a future course.Overall, he believes that there is a lot of potential for AI in education, across faculties and disciplines, based on the broad (although sometimes flawed) knowledge it provides, as well as the academic skills that are developed in learning how to use and work with this type of programme. Hes not sure that its great for a deep understanding of a subject matter (which is often needed for philosophy courses) but its great for a general understanding to help students get started.'],\n",
       " ['Overall, Rolf believes that AI and programs like ChatGPT are here to stay. He does see some significant drawbacks in them, such as the implicit assumptions and wrong information it provides at times. However, he believes that we cannot simply ignore and look away from such developments. We need to actively look for the best ways to use them in an academically sound manner. When asked, he says he would like to keep it as part of his course next year. However, he is aware that AI is developing and changing at an extremely fast pace, so he is unsure of how it will look to incorporate it into a future course.Overall, he believes that there is a lot of potential for AI in education, across faculties and disciplines, based on the broad (although sometimes flawed) knowledge it provides, as well as the academic skills that are developed in learning how to use and work with this type of programme. Hes not sure that its great for a deep understanding of a subject matter (which is often needed for philosophy courses) but its great for a general understanding to help students get started.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Are you academic staff, and do you want to learn about ChatGPT and its capabilities and potential applications in higher education? Join us and a group of colleagues for a two-hour workshop, in which you will work directly with ChatGPT and explore its various uses and implications in educational contexts.'],\n",
       " ['By the end of the workshop, you will be better positioned to assess the opportunities and challenges that ChatGPT poses to higher education. You will gain practical experience and leave with a deeper understanding of ChatGPTs potential impact on learning & teaching.The workshop will be facilitated by Jonathan & Milan from ErasmusXOpens external.[This description was written by ChatGPT and edited by the facilitators.]PreparationMake sure you create a ChatGPT account prior to the workshop. You can do this by going to chat.openai.comOpens external and signing up. Would you rather not create an account? Then contact info.erasmusx.nl and they will look for a solution for you. Bring your laptop so that you can experiment with ChatGPT during the workshop.You will be sent a pre-survey a few days before the workshop, and a post-survey after the workshop. The results may be shared with you later!Sign upSigning up is no longer possible.'],\n",
       " ['he workshop will be facilitated by Jonathan & Milan from ErasmusXOpens external.[This description was written by ChatGPT and edited by the facilitators.]PreparationMake sure you create a ChatGPT account prior to the workshop. You can do this by going to chat.openai.comOpens external and signing up. Would you rather not create an account? Then contact info.erasmusx.nl and they will look for a solution for you. Bring your laptop so that you can experiment with ChatGPT during the workshop.You will be sent a pre-survey a few days before the workshop, and a post-survey after the workshop. The results may be shared with you later!Sign upSigning up is no longer possible.'],\n",
       " ['[This description was written by ChatGPT and edited by the facilitators.]PreparationMake sure you create a ChatGPT account prior to the workshop. You can do this by going to chat.openai.comOpens external and signing up. Would you rather not create an account? Then contact info.erasmusx.nl and they will look for a solution for you. Bring your laptop so that you can experiment with ChatGPT during the workshop.You will be sent a pre-survey a few days before the workshop, and a post-survey after the workshop. The results may be shared with you later!Sign upSigning up is no longer possible.'],\n",
       " [],\n",
       " ['o help realize these possibilities, the White House is taking action to elevate the needs, priorities, and experiences of those who will shape and inherit the future of open science: the early career research (ECR) community. The White House Office of Science and Technology Policy (OSTP) will host a series of virtual listening sessions to explore perspectives on the challenges and opportunities for advancing open science in the United States and solutions that might be implemented by the U.S. Government.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['We will show the amazing things ChatGPT is capable of, explain how it was created, but also reflect on its limitations, ethical implications, and impact on education and creativity.'],\n",
       " [],\n",
       " ['his event will be organised by the Computational linguistics group of CLCG in collaboration with the Jantina Tammes School for Digital Society, Technology and AI.'],\n",
       " [],\n",
       " ['As gloomy predictions foretell the end of homework, education institutions are hastily revising their policies and curricula to address the challenges posed by AI chatbots. It is true that the emergence of chatbots does raise ethical and philosophical questions. Yet, through their interactions with AI, people will inevitably enhance skills that are crucial in our day and age: language awareness and critical thinking.'],\n",
       " ['It is not surprising that the success of ChatGPT passing an MBA and producing credible academic papers has sparked worry among educators about how students will learn to form an opinion and articulate it. This is indeed a scary prospect: from the smallest everyday decisions to large-scale, high-stakes societal issues, we form our opinions through gathering information, (preferably) doing some research, thinking critically while we evaluate the evidence and reasoning, and then make our own judgement. Now cue in ChatGPT: it will evaluate the vast dataset it has been trained on, and save you the hard work of researching, thinking and evaluating. The glitch, as the bot itself admits, is that its answers are not based on independent research:I generate text based on patterns I have seen in the data. I present the most likely text based on my training, but I dont have the ability to critically evaluate or form my own opinions.'],\n",
       " ['Dont be fooled by the logic of this answer: the AI application does not explain its actions and their consequences (and as we will see later, there is a big difference between the two). The world ChatGPT presents to us is based on argumentum ad populum it considers to be true what is repeated the most. Of course, its not: if you go down the rabbit hole of reports on AI hallucinations, you are bound to find many stories. Our favourite is how the chatbot dreamed up the most widely cited economics paper. This is why we agree with those who doubt that ChatGPT will take over our content creating, creative, fact-checking jobs any time soon. However convincing they are, AI-generated texts sit in a vacuum: a chatbot does not communicate the way humans do, it does not know the actual purpose of the text, the intended audience or the context in which it will be used unless specifically told so. Learning to better grasp the nuances of language, context and intended purpose could help future generations to combat misinformation. Shutterstock A chance to sharpen our critical skills Users need to be savvy in both prompting and evaluating the output. Prompting is a skill that requires precise vocabulary and an understanding of how language, style or genres work. Evaluation is the ability to assess the output. Let us give an example. Imagine your task is to respond to a corporate crisis. You reach out to ChatGPT to create a corporate apology. You prompt it: Assume some responsibility. Use formal language. Should be short. And this is where the magic happens. You have done your prompting, but now you need to check: does this text look and sound like a corporate apology? How do people normally use language to assume or shift blame? Is the text easy to read or does it hide its true meaning behind complex language? Whose voice are we hearing in the apology? To check if your text is right, you must know what the typical genre or style features are. You must know about crisis management strategies. Readability levels. Or how we encode agency in language (as this study found). In academic scholarship this kind of knowledge is called language awareness. Language awareness has several levels: the first one is simply noticing language(s) and its elements. The second level is when we can identify and label the various elements, and creatively manipulate them. Consider for example the beginning of two versions of corporate apologies ChatGPT created: We would like to deeply apologize for the actions of our company We would like to deeply apologize for the inconvenience our actions caused A cursory read of these two may look as if both messages were apologetic, but the difference is what they apologize for. One apologizes for their actions. The other for the consequences of their actions. This small difference affects legal liability: in the second case, the company does not explicitly accept responsibility. After all, they are only sorry for the inconvenience. Such examples like the one above can make people think about small linguistic differences and their meaning for communication. The beauty of it is that the more often we look closely at language, the more we notice what it does in communication. Once you see how a fauxpology works, you can never unsee it. A potential weapon against misinformation Back to ChatGPT: as we can see, for the best results, users need to prompt it right, and then check the produced text against the prompt criteria. For this they need to understand the nuances of language, context and intended purpose. Why is this knowledge such a big deal? Because of a third level of awareness that we have not mentioned before. This is when people realize how language creates, affects and manipulates their perceptions of reality. This knowledge is invaluable in our age of misinformation and populism when the issues society grapples with are mostly abstract and intangible. The more people know about how language works, the more they start to notice how politicians and the media create versions of the world for them through their communications. Language awareness makes people sensitive to questionable corporate communication practices, from greenwashing to you know, non-apologies. What is more, language awareness may help people better understand why society (doesnt) respond to actions targeting the climate crisis. Dubbed as the largest communication failure in history, almost every aspect of the climate crisis and how people act as a result depends on how we talk about it. It is impossible to predict the extent to which AI applications like ChatGPT will disrupt the world of education and work. For now, society can both prepare for the dangers of AIs and embrace their potential. In the process of learning how to interact with them well, however, people are bound to become prompt savvy, and with that more aware of how language works. With such language awareness comes the power to'],\n",
       " ['his is why we agree with those who doubt that ChatGPT will take over our content creating, creative, fact-checking jobs any time soon. However convincing they are, AI-generated texts sit in a vacuum: a chatbot does not communicate the way humans do, it does not know the actual purpose of the text, the intended audience or the context in which it will be used unless specifically told so.'],\n",
       " [],\n",
       " [],\n",
       " ['It is impossible to predict the extent to which AI applications like ChatGPT will disrupt the world of education and work. For now, society can both prepare for the dangers of AIs and embrace their potential. In the process of learning how to interact with them well, however, people are bound to become prompt savvy, and with that more aware of how language works. With such language awareness comes the power to consume texts with a critical eye. A glimmer of optimism for a sustainable future is that critical reading leaves less room to manipulation and misinformation.'],\n",
       " [],\n",
       " ['How can chat technology be used in different languages and for different purposes, with relatively little training and compute power? Arianna Bisazza, assistant professor specialized in computational linguistics and language processing, is part of a large research consortium that will investigate this.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['he possibilities of AI will become greater as its development continues. Tech giants such as Microsoft have invested billions of dollars in companies that build AI programs such as OpenAI. Furthermore, Microsoft is working on integrating GPT models into Word, PowerPoint, and Outlook, where it can for instance help with email replies and searches. Google has started a slow rollout of their Chat AI, Bard and have announced several other AI projects and integrations in their existing programs that will be rolled out in the coming months. One of these projects is the further enhancement of AI features in Google Workspace. In everyday life, the Internet of Things (IoT) can use AI to learn, identify, and aid in decision making. In higher education, similar benefits can be gained when AI tools are incorporated properly. So what does this entail for the future of higher education? Higher education can play a role in helping students learn to work with these programs, as they will likely use them later on in their work as well. Since the launch of ChatGPT in November this specific program has gained a lot of momentum, yet AI in general has been around for a long time and has already percolated into life and education in various ways. When the Google search engine was first launched to the general public in , or Wikipedia in , these developments led to great concerns in (higher) education about student learning, accuracy, reliability, and plagiarism. The easy availability of AI programs such as ChatGPT leads to similar concerns. As with previous similar situations, ways can and will be found to deal with this. Some AI tools are behind a paywall, while others are free to use. This might, however, change in the future. When choosing to incorporate an AI tool into your teaching or assessment, check to make sure whether the chosen tool is available to your students. If contracts and processing agreements with the owner of a third party tool are not in place, the use of a tool may not be made mandatory for students.Currently, applications such as GPT4All are being developed that allow individuals to run language models locally (i.e., on their own computer). This decentralization of AI tools will increase their availability. This process is being expedited further by efforts to decrease the size of the models behind AI tools, with the result that they can be run on devices with less computing power (e.g., in early the GPT4All model was even successfully implemented on a TI-84 calculator that was released in ). Also, developments in the scope of application of AI models can have implications for higher education. Currently, the development of AI agents has great implications for what AI models can do and be used for. One example of such an AI agent is Auto-GPT , which can be given a goal using natural language and can perform tasks autonomously using the GPT-4 model by breaking the goal into sub-tasks and using the internet and other tools to complete them. Incorporating AI tools in higher education will likely lead to an increase in the use of technology in and outside of the classroom and in formative and summative assessment methods. When used properly AI can also aid personalized learning and lead to time saving, for instance by providing automated feedback to students. On a more abstract level AI can accelerate learning analytics, which can lead to a better course and curriculum design. While these benefits are helpful, teachers should always keep an eye out for ethical and privacy issues when using an AI tool. Even though the output of AI tools will improve as the AI models are trained on bigger databases, the output should always be reviewed critically. Some AI tools are self-learning algorithms, others are language models that use deep learning techniques (and some are a combination), and there are many more options. For each type of AI program it can be argued that they will improve as more data is added to its underlying database.'],\n",
       " ['So what does this entail for the future of higher education? Higher education can play a role in helping students learn to work with these programs, as they will likely use them later on in their work as well. Since the launch of ChatGPT in November this specific program has gained a lot of momentum, yet AI in general has been around for a long time and has already percolated into life and education in various ways. When the Google search engine was first launched to the general public in , or Wikipedia in , these developments led to great concerns in (higher) education about student learning, accuracy, reliability, and plagiarism. The easy availability of AI programs such as ChatGPT leads to similar concerns. As with previous similar situations, ways can and will be found to deal with this. Some AI tools are behind a paywall, while others are free to use. This might, however, change in the future. When choosing to incorporate an AI tool into your teaching or assessment, check to make sure whether the chosen tool is available to your students. If contracts and processing agreements with the owner of a third party tool are not in place, the use of a tool may not be made mandatory for students.Currently, applications such as GPT4All are being developed that allow individuals to run language models locally (i.e., on their own computer). This decentralization of AI tools will increase their availability. This process is being expedited further by efforts to decrease the size of the models behind AI tools, with the result that they can be run on devices with less computing power (e.g., in early the GPT4All model was even successfully implemented on a TI-84 calculator that was released in ). Also, developments in the scope of application of AI models can have implications for higher education. Currently, the development of AI agents has great implications for what AI models can do and be used for. One example of such an AI agent is Auto-GPT , which can be given a goal using natural language and can perform tasks autonomously using the GPT-4 model by breaking the goal into sub-tasks and using the internet and other tools to complete them. Incorporating AI tools in higher education will likely lead to an increase in the use of technology in and outside of the classroom and in formative and summative assessment methods. When used properly AI can also aid personalized learning and lead to time saving, for instance by providing automated feedback to students. On a more abstract level AI can accelerate learning analytics, which can lead to a better course and curriculum design. While these benefits are helpful, teachers should always keep an eye out for ethical and privacy issues when using an AI tool. Even though the output of AI tools will improve as the AI models are trained on bigger databases, the output should always be reviewed critically. Some AI tools are self-learning algorithms, others are language models that use deep learning techniques (and some are a combination), and there are many more options. For each type of AI program it can be argued that they will improve as more data is added to its underlying database.'],\n",
       " ['Currently, applications such as GPT4All are being developed that allow individuals to run language models locally (i.e., on their own computer). This decentralization of AI tools will increase their availability. This process is being expedited further by efforts to decrease the size of the models behind AI tools, with the result that they can be run on devices with less computing power (e.g., in early the GPT4All model was even successfully implemented on a TI-84 calculator that was released in ). Also, developments in the scope of application of AI models can have implications for higher education. Currently, the development of AI agents has great implications for what AI models can do and be used for. One example of such an AI agent is Auto-GPT , which can be given a goal using natural language and can perform tasks autonomously using the GPT-4 model by breaking the goal into sub-tasks and using the internet and other tools to complete them. Incorporating AI tools in higher education will likely lead to an increase in the use of technology in and outside of the classroom and in formative and summative assessment methods. When used properly AI can also aid personalized learning and lead to time saving, for instance by providing automated feedback to students. On a more abstract level AI can accelerate learning analytics, which can lead to a better course and curriculum design. While these benefits are helpful, teachers should always keep an eye out for ethical and privacy issues when using an AI tool. Even though the output of AI tools will improve as the AI models are trained on bigger databases, the output should always be reviewed critically. Some AI tools are self-learning algorithms, others are language models that use deep learning techniques (and some are a combination), and there are many more options. For each type of AI program it can be argued that they will improve as more data is added to its underlying database.'],\n",
       " ['Incorporating AI tools in higher education will likely lead to an increase in the use of technology in and outside of the classroom and in formative and summative assessment methods. When used properly AI can also aid personalized learning and lead to time saving, for instance by providing automated feedback to students. On a more abstract level AI can accelerate learning analytics, which can lead to a better course and curriculum design. While these benefits are helpful, teachers should always keep an eye out for ethical and privacy issues when using an AI tool. Even though the output of AI tools will improve as the AI models are trained on bigger databases, the output should always be reviewed critically. Some AI tools are self-learning algorithms, others are language models that use deep learning techniques (and some are a combination), and there are many more options. For each type of AI program it can be argued that they will improve as more data is added to its underlying database.'],\n",
       " ['Even though the output of AI tools will improve as the AI models are trained on bigger databases, the output should always be reviewed critically. Some AI tools are self-learning algorithms, others are language models that use deep learning techniques (and some are a combination), and there are many more options. For each type of AI program it can be argued that they will improve as more data is added to its underlying database.'],\n",
       " [],\n",
       " [],\n",
       " ['[Dutch only] ChatGPT - What will you do for us in education?'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['AI websites that will change education forever'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['In the last decade, we have witnessed an explosion in the performance and rise to fame of artificial neural networks (ANNs): from the early success of AlexNet in image classification to the very recent and hotly debated large language models like GPT-4 and ChatGPT from OpenAI, and Googles PALM. This performance, though, comes at an enormous cost for training and inference, due to the very high number of parameters of these models (more than trillion in some cases). Model compression (MC) gathers a variety of techniques aimed at reducing the number of parameters of machine learning (ML) models, ANNs included, with the aim of either reducing the computational requirements or aiding generalization. In this seminar, we will be covering the topic of MC for various ML models: starting from easier examples connected to linear regression and decision trees, we will shift towards state-of-the-art MC techniques for ANNs, while keeping the level of the discussed topics accessible to attendees with basic knowledge of ML.'],\n",
       " [],\n",
       " [],\n",
       " ['On May , researchers from different faculties of the University of Groningen will host an interdisciplinary meeting on AI generative language models (such as ChatGPT) and their impact on academic labour. The meeting is part of the Panoptiwork project, funded by the incentive UG fund YAG-SER-2022.'],\n",
       " ['esearchers from seven faculties will explore the topic from their background. The debate will kick off with a question to each of the researchers involved: What is the biggest research topic they see on generative AI language models and academic labour?'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [\"Luuk Terbeek, education specialist at LEARN! Academy, have recently come by frequently when it comes to AI-generated content in higher education. Opportunities and challenges The VU understands that banning the use of ChatGPT is pointless and that such software will continue to improve. The VU policy team therefore advises investigating how the chatbot can be used meaningfully in education. The team is currently in discussions to determine what actions are desirable or necessary in response to students' use of ChatGPT. Recently, Luuk has been organizing knowledge sessions 'Dealing with ChatGPT' within the VU. An important starting point here is to enter into dialogue with each other in order to achieve a balanced approach that is as fully informed as possible. The knowledge sessions also discuss how you can act according to recently formulated policy and how you can link up with the recently developed testing vision of the VU. After all, the emergence of ChatGPT forces us to think about future-proof forms of testing. What agreements do you make with your students about using ChatGPT for writing essays, for example? When is use considered fraud, and what kind of use is allowed, or possibly encouraged? In addition, it is important to be well informed about the ethical aspects of use. For example, can a teacher require a student to consult applications such as ChatGPT, knowing that they must create a personal account for this and that the data will remain on Microsoft servers indefinitely (even if the account is deleted)? Possible ChatGPT applications for education At the same time, it is important not to see AI-generated content purely as a threat. It also offers potential for strengthening education or even reducing work pressure, says Luuk. By discussing this together, new applications can be developed and exchanged. For example, as a teacher you can use ChatGPT to review texts, design a (as yet premature) Rubric or series of lessons, or have a basis for a syllabus written. Or use it to promote critical thinking and reflection among students. For example, let them (jointly) give feedback on answers from the chatbot. Will AI-generated content eventually take over the teacher's work? Luke thinks not. The output is still regularly debatable, so you can mainly use it as a source of inspiration. But even when the accuracy of the output improves further, a chatbot lacks the interpersonal skills, contextual understanding and creativity that are so important for teaching. ChatGPT knowledge sessions for VU employees Whatever the exact implications of AI-generated content may be, as a university we cannot ignore it. So start the conversation and join a LEARN! Academy ChatGPT knowledge session for VU employees. In addition to lecturers, education developers, education advisors, program directors and researchers are of course also very welcome. During this knowledge session (which can also be provided as a lunch session) you will receive an overview of current and relevant information for the VU, and you will discuss the potential, dilemmas and possible applications of ChatGPT for education. Would you like to follow a ChatGPT knowledge session with your team? Then contact LEARN! Academy via learnacademy.nl.\"],\n",
       " ['It is somewhat like the invention of photography, said writer and poet Hannah van Binsbergen on Monday at a meeting of the Royal Netherlands Academy of Arts and Sciences. Artists opposed it or made use of the new photographic perspectives. New skills The new chat program writes essays, literature and scientific papers on command. With its apparent all-rounder, the program raises all kinds of questions. Will the chatbot soon be able to write as well as we do? Can he think for himself and come up with creative solutions? What does this mean for education and science? That amazement and those questions are understandable, responds language technologist and cognitive scientist Jelle Zuidema. The system behind the chatbot is the latest generation of the so-called Large Language Models. Scientists have been working on it for decades, but in the last three years things have moved so fast that the programs have all learned new skills. They do so in dialogue with input from users and programmers. According to Zuidema, such models will change the world. Not because they can think logically themselves, but because they are designed to predict in as many cases as possible what is needed for a possible answer to a question. Generic Still, there are many comments to be made. Author Hannah van Binsbergen pointed to the self-censorship that the programmers have imposed on the chatbot. According to her, creating literary strong texts is therefore impossible for the time being. Answers are mostly very generic. For example, she asked ChatGPT what the chatbot could do for writers. And he replied, among other things, that he can help by \"broadening cultural horizons and expanding what the understanding of literature can be\". That sounds promising, but what it actually means remains unclear. She says there are other problems as well. The program can generate texts well, but it can hardly relate to style and form. For example, she asked ChatGPT to write a poem in the style of Lucebert and a semi-rhyming poem came out, which, according to Van Binsbergen, had nothing to do with the poet. The chatbot is also being trained with the help of underpaid Kenyan test users to provide politically correct answers. to give. In fact, said the Leiden philosopher Victor Gijsbers, the program cannot answer politically sensitive or moral questions at all. And if you ask him why not, he answers that it is important that people form their own opinions. Finding the truth is not important That brought Gijsbers to a sensitive point. According to him, the chatbot is not programmed for truth-finding. While earlier artificial intelligent systems were. OpenAI, the company behind ChatGPT, wouldn\\'t care about that. For example, Gijsbers presented the chatbot with a problem that had already been solved by a program from the s. The chatbot came up with incorrect answers several times. The program also occasionally does strange things. If you ask ChatGPT ten times what the capital of the Netherlands is, it will say Amsterdam nine times and Rotterdam once. Producing coherent pieces of text that are factually correct is often too much to ask, even according to language technologist Zuidema. The chatbot tries to base its answer on existing web texts, but if that doesn\\'t work, it bluffs its way through and fills in nonsense. Sources are not mentioned. A new online program from Microsoft search engine Bing tries to do it the other way around and first look for sources for the answer, says Zuidema. Although the cohesion and separation of the information is not always good, it is at least possible to find out where the information comes from.Pen and paperStudents seem to embrace the new technique en masse and write entire essays with ChatGPT. Are they still encouraged to think critically? Yes, this is no fun for teachers, Gijsbers jokes. That is why we have to test knowledge differently. Just use pen and paper in an exam room again. But there are also advantages for lecturers. It now takes a lot of time and effort to explain to students how to write an essay. Programs will become available in the foreseeable future that will be very helpful in this regard. Just as well? Someone from the audience asked whether ChatGPT could have prepared as good a talk during the symposium as the speakers themselves. They thought not. According to philosopher Gijsbers, a speaker should tell a story that is true and that has value for the audience. I think the relationship between you and me is very different from the relationship between you and the technology.'],\n",
       " ['he new chat program writes essays, literature and scientific papers on command. With its apparent all-rounder, the program raises all kinds of questions. Will the chatbot soon be able to write as well as we do? Can he think for himself and come up with creative solutions? What does this mean for education and science? That amazement and those questions are understandable, responds language technologist and cognitive scientist Jelle Zuidema. The system behind the chatbot is the latest generation of the so-called Large Language Models. Scientists have been working on it for decades, but in the last three years things have moved so fast that the programs have all learned new skills. They do so in dialogue with input from users and programmers. According to Zuidema, such models will change the world. Not because they can think logically themselves, but because they are designed to predict in as many cases as possible what is needed for a possible answer to a question. Generic Still, there are many comments to be made. Author Hannah van Binsbergen pointed to the self-censorship that the programmers have imposed on the chatbot. According to her, creating literary strong texts is therefore impossible for the time being. Answers are mostly very generic. For example, she asked ChatGPT what the chatbot could do for writers. And he replied, among other things, that he can help by \"broadening cultural horizons and expanding what the understanding of literature can be\". That sounds promising, but what it actually means remains unclear. She says there are other problems as well. The program can generate texts well, but it can hardly relate to style and form. For example, she asked ChatGPT to write a poem in the style of Lucebert and a semi-rhyming poem came out, which, according to Van Binsbergen, had nothing to do with the poet. The chatbot is also being trained with the help of underpaid Kenyan test users to provide politically correct answers. to give. In fact, said the Leiden philosopher Victor Gijsbers, the program cannot answer politically sensitive or moral questions at all. And if you ask him why not, he answers that it is important that people form their own opinions. Finding the truth is not important That brought Gijsbers to a sensitive point. According to him, the chatbot is not programmed for truth-finding. While earlier artificial intelligent systems were. OpenAI, the company behind ChatGPT, wouldn\\'t care about that. For example, Gijsbers presented the chatbot with a problem that had already been solved by a program from the s. The chatbot came up with incorrect answers several times. The program also occasionally does strange things. If you ask ChatGPT ten times what the capital of the Netherlands is, it will say Amsterdam nine times and Rotterdam once. Producing coherent pieces of text that are factually correct is often too much to ask, even according to language technologist Zuidema. The chatbot tries to base its answer on existing web texts, but if that doesn\\'t work, it bluffs its way through and fills in nonsense. Sources are not mentioned. A new online program from Microsoft search engine Bing tries to do it the other way around and first look for sources for the answer, says Zuidema. Although the cohesion and separation of the information is not always good, it is at least possible to find out where the information comes from.Pen and paperStudents seem to embrace the new technique en masse and write entire essays with ChatGPT. Are they still encouraged to think critically? Yes, this is no fun for teachers, Gijsbers jokes. That is why we have to test knowledge differently. Just use pen and paper in an exam room again. But there are also advantages for lecturers. It now takes a lot of time and effort to explain to students how to write an essay. Programs will become available in the foreseeable future that will be very helpful in this regard. Just as well? Someone from the audience asked whether ChatGPT could have prepared as good a talk during the symposium as the speakers themselves. They thought not. According to philosopher Gijsbers, a speaker should tell a story that is true and that has value for the audience. I think the relationship between you and me is very different from the relationship between you and the technology.'],\n",
       " ['hat amazement and those questions are understandable, responds language technologist and cognitive scientist Jelle Zuidema. The system behind the chatbot is the latest generation of the so-called Large Language Models. Scientists have been working on it for decades, but in the last three years things have moved so fast that the programs have all learned new skills. They do so in dialogue with input from users and programmers. According to Zuidema, such models will change the world. Not because they can think logically themselves, but because they are designed to predict in as many cases as possible what is needed for a possible answer to a question. Generic Still, there are many comments to be made. Author Hannah van Binsbergen pointed to the self-censorship that the programmers have imposed on the chatbot. According to her, creating literary strong texts is therefore impossible for the time being. Answers are mostly very generic. For example, she asked ChatGPT what the chatbot could do for writers. And he replied, among other things, that he can help by \"broadening cultural horizons and expanding what the understanding of literature can be\". That sounds promising, but what it actually means remains unclear. She says there are other problems as well. The program can generate texts well, but it can hardly relate to style and form. For example, she asked ChatGPT to write a poem in the style of Lucebert and a semi-rhyming poem came out, which, according to Van Binsbergen, had nothing to do with the poet. The chatbot is also being trained with the help of underpaid Kenyan test users to provide politically correct answers. to give. In fact, said the Leiden philosopher Victor Gijsbers, the program cannot answer politically sensitive or moral questions at all. And if you ask him why not, he answers that it is important that people form their own opinions. Finding the truth is not important That brought Gijsbers to a sensitive point. According to him, the chatbot is not programmed for truth-finding. While earlier artificial intelligent systems were. OpenAI, the company behind ChatGPT, wouldn\\'t care about that. For example, Gijsbers presented the chatbot with a problem that had already been solved by a program from the s. The chatbot came up with incorrect answers several times. The program also occasionally does strange things. If you ask ChatGPT ten times what the capital of the Netherlands is, it will say Amsterdam nine times and Rotterdam once. Producing coherent pieces of text that are factually correct is often too much to ask, even according to language technologist Zuidema. The chatbot tries to base its answer on existing web texts, but if that doesn\\'t work, it bluffs its way through and fills in nonsense. Sources are not mentioned. A new online program from Microsoft search engine Bing tries to do it the other way around and first look for sources for the answer, says Zuidema. Although the cohesion and separation of the information is not always good, it is at least possible to find out where the information comes from.Pen and paperStudents seem to embrace the new technique en masse and write entire essays with ChatGPT. Are they still encouraged to think critically? Yes, this is no fun for teachers, Gijsbers jokes. That is why we have to test knowledge differently. Just use pen and paper in an exam room again. But there are also advantages for lecturers. It now takes a lot of time and effort to explain to students how to write an essay. Programs will become available in the foreseeable future that will be very helpful in this regard. Just as well? Someone from the audience asked whether ChatGPT could have prepared as good a talk during the symposium as the speakers themselves. They thought not. According to philosopher Gijsbers, a speaker should tell a story that is true and that has value for the audience. I think the relationship between you and me is very different from the relationship between you and the technology.'],\n",
       " ['According to Zuidema, such models will change the world. Not because they can think logically themselves, but because they are designed to predict in as many cases as possible what is needed for a possible answer to a question. Generic Still, there are many comments to be made. Author Hannah van Binsbergen pointed to the self-censorship that the programmers have imposed on the chatbot. According to her, creating literary strong texts is therefore impossible for the time being. Answers are mostly very generic. For example, she asked ChatGPT what the chatbot could do for writers. And he replied, among other things, that he can help by \"broadening cultural horizons and expanding what the understanding of literature can be\". That sounds promising, but what it actually means remains unclear. She says there are other problems as well. The program can generate texts well, but it can hardly relate to style and form. For example, she asked ChatGPT to write a poem in the style of Lucebert and a semi-rhyming poem came out, which, according to Van Binsbergen, had nothing to do with the poet. The chatbot is also being trained with the help of underpaid Kenyan test users to provide politically correct answers. to give. In fact, said the Leiden philosopher Victor Gijsbers, the program cannot answer politically sensitive or moral questions at all. And if you ask him why not, he answers that it is important that people form their own opinions. Finding the truth is not important That brought Gijsbers to a sensitive point. According to him, the chatbot is not programmed for truth-finding. While earlier artificial intelligent systems were. OpenAI, the company behind ChatGPT, wouldn\\'t care about that. For example, Gijsbers presented the chatbot with a problem that had already been solved by a program from the s. The chatbot came up with incorrect answers several times. The program also occasionally does strange things. If you ask ChatGPT ten times what the capital of the Netherlands is, it will say Amsterdam nine times and Rotterdam once. Producing coherent pieces of text that are factually correct is often too much to ask, even according to language technologist Zuidema. The chatbot tries to base its answer on existing web texts, but if that doesn\\'t work, it bluffs its way through and fills in nonsense. Sources are not mentioned. A new online program from Microsoft search engine Bing tries to do it the other way around and first look for sources for the answer, says Zuidema. Although the cohesion and separation of the information is not always good, it is at least possible to find out where the information comes from.Pen and paperStudents seem to embrace the new technique en masse and write entire essays with ChatGPT. Are they still encouraged to think critically? Yes, this is no fun for teachers, Gijsbers jokes. That is why we have to test knowledge differently. Just use pen and paper in an exam room again. But there are also advantages for lecturers. It now takes a lot of time and effort to explain to students how to write an essay. Programs will become available in the foreseeable future that will be very helpful in this regard. Just as well? Someone from the audience asked whether ChatGPT could have prepared as good a talk during the symposium as the speakers themselves. They thought not. According to philosopher Gijsbers, a speaker should tell a story that is true and that has value for the audience. I think the relationship between you and me is very different from the relationship between you and the technology.'],\n",
       " ['Nevertheless, there are many caveats to be noted. Author Hannah van Binsbergen pointed to the self-censorship that the programmers have imposed on the chatbot. According to her, creating literary strong texts is therefore impossible for the time being. Answers are mostly very generic. For example, she asked ChatGPT what the chatbot could do for writers. And he replied, among other things, that he can help by \"broadening cultural horizons and expanding what the understanding of literature can be\". That sounds promising, but what it actually means remains unclear. She says there are other problems as well. The program can generate texts well, but it can hardly relate to style and form. For example, she asked ChatGPT to write a poem in the style of Lucebert and a semi-rhyming poem came out, which, according to Van Binsbergen, had nothing to do with the poet. The chatbot is also being trained with the help of underpaid Kenyan test users to provide politically correct answers. to give. In fact, said the Leiden philosopher Victor Gijsbers, the program cannot answer politically sensitive or moral questions at all. And if you ask him why not, he answers that it is important that people form their own opinions. Finding the truth is not important That brought Gijsbers to a sensitive point. According to him, the chatbot is not programmed for truth-finding. While earlier artificial intelligent systems were. OpenAI, the company behind ChatGPT, wouldn\\'t care about that. For example, Gijsbers presented the chatbot with a problem that had already been solved by a program from the s. The chatbot came up with incorrect answers several times. The program also occasionally does strange things. If you ask ChatGPT ten times what the capital of the Netherlands is, it will say Amsterdam nine times and Rotterdam once. Producing coherent pieces of text that are factually correct is often too much to ask, even according to language technologist Zuidema. The chatbot tries to base its answer on existing web texts, but if that doesn\\'t work, it bluffs its way through and fills in nonsense. Sources are not mentioned. A new online program from Microsoft search engine Bing tries to do it the other way around and first look for sources for the answer, says Zuidema. Although the cohesion and separation of the information is not always good, it is at least possible to find out where the information comes from.Pen and paperStudents seem to embrace the new technique en masse and write entire essays with ChatGPT. Are they still encouraged to think critically? Yes, this is no fun for teachers, Gijsbers jokes. That is why we have to test knowledge differently. Just use pen and paper in an exam room again. But there are also advantages for lecturers. It now takes a lot of time and effort to explain to students how to write an essay. Programs will become available in the foreseeable future that will be very helpful in this regard. Just as well? Someone from the audience asked whether ChatGPT could have prepared as good a talk during the symposium as the speakers themselves. They thought not. According to philosopher Gijsbers, a speaker should tell a story that is true and that has value for the audience. I think the relationship between you and me is very different from the relationship between you and the technology.'],\n",
       " [\"She says there are other problems as well. The program can generate texts well, but it can hardly relate to style and form. For example, she asked ChatGPT to write a poem in the style of Lucebert and a semi-rhyming poem came out, which, according to Van Binsbergen, had nothing to do with the poet. The chatbot is also being trained with the help of underpaid Kenyan test users to provide politically correct answers. to give. In fact, said the Leiden philosopher Victor Gijsbers, the program cannot answer politically sensitive or moral questions at all. And if you ask him why not, he answers that it is important that people form their own opinions. Finding the truth is not important That brought Gijsbers to a sensitive point. According to him, the chatbot is not programmed for truth-finding. While earlier artificial intelligent systems were. OpenAI, the company behind ChatGPT, wouldn't care about that. For example, Gijsbers presented the chatbot with a problem that had already been solved by a program from the s. The chatbot came up with incorrect answers several times. The program also occasionally does strange things. If you ask ChatGPT ten times what the capital of the Netherlands is, it will say Amsterdam nine times and Rotterdam once. Producing coherent pieces of text that are factually correct is often too much to ask, even according to language technologist Zuidema. The chatbot tries to base its answer on existing web texts, but if that doesn't work, it bluffs its way through and fills in nonsense. Sources are not mentioned. A new online program from Microsoft search engine Bing tries to do it the other way around and first look for sources for the answer, says Zuidema. Although the cohesion and separation of the information is not always good, it is at least possible to find out where the information comes from.Pen and paperStudents seem to embrace the new technique en masse and write entire essays with ChatGPT. Are they still encouraged to think critically? Yes, this is no fun for teachers, Gijsbers jokes. That is why we have to test knowledge differently. Just use pen and paper in an exam room again. But there are also advantages for lecturers. It now takes a lot of time and effort to explain to students how to write an essay. Programs will become available in the foreseeable future that will be very helpful in this regard. Just as well? Someone from the audience asked whether ChatGPT could have prepared as good a talk during the symposium as the speakers themselves. They thought not. According to philosopher Gijsbers, a speaker should tell a story that is true and that has value for the audience. I think the relationship between you and me is very different from the relationship between you and the technology.\"],\n",
       " [\"Furthermore, the chatbot is trained using underpaid Kenyan test users to provide politically correct answers. In fact, said the Leiden philosopher Victor Gijsbers, the program cannot answer politically sensitive or moral questions at all. And if you ask him why not, he answers that it is important that people form their own opinions. Finding the truth is not important That brought Gijsbers to a sensitive point. According to him, the chatbot is not programmed for truth-finding. While earlier artificial intelligent systems were. OpenAI, the company behind ChatGPT, wouldn't care about that. For example, Gijsbers presented the chatbot with a problem that had already been solved by a program from the s. The chatbot came up with incorrect answers several times. The program also occasionally does strange things. If you ask ChatGPT ten times what the capital of the Netherlands is, it will say Amsterdam nine times and Rotterdam once. Producing coherent pieces of text that are factually correct is often too much to ask, even according to language technologist Zuidema. The chatbot tries to base its answer on existing web texts, but if that doesn't work, it bluffs its way through and fills in nonsense. Sources are not mentioned. A new online program from Microsoft search engine Bing tries to do it the other way around and first look for sources for the answer, says Zuidema. Although the cohesion and separation of the information is not always good, it is at least possible to find out where the information comes from.Pen and paperStudents seem to embrace the new technique en masse and write entire essays with ChatGPT. Are they still encouraged to think critically? Yes, this is no fun for teachers, Gijsbers jokes. That is why we have to test knowledge differently. Just use pen and paper in an exam room again. But there are also advantages for lecturers. It now takes a lot of time and effort to explain to students how to write an essay. Programs will become available in the foreseeable future that will be very helpful in this regard. Just as well? Someone from the audience asked whether ChatGPT could have prepared as good a talk during the symposium as the speakers themselves. They thought not. According to philosopher Gijsbers, a speaker should tell a story that is true and that has value for the audience. I think the relationship between you and me is very different from the relationship between you and the technology.\"],\n",
       " [\"hat brought Gijsbers to a sensitive point. According to him, the chatbot is not programmed for truth-finding. While earlier artificial intelligent systems were. OpenAI, the company behind ChatGPT, wouldn't care about that. For example, Gijsbers presented the chatbot with a problem that had already been solved by a program from the s. The chatbot came up with incorrect answers several times. The program also occasionally does strange things. If you ask ChatGPT ten times what the capital of the Netherlands is, it will say Amsterdam nine times and Rotterdam once. Producing coherent pieces of text that are factually correct is often too much to ask, even according to language technologist Zuidema. The chatbot tries to base its answer on existing web texts, but if that doesn't work, it bluffs its way through and fills in nonsense. Sources are not mentioned. A new online program from Microsoft search engine Bing tries to do it the other way around and first look for sources for the answer, says Zuidema. Although the cohesion and separation of the information is not always good, it is at least possible to find out where the information comes from.Pen and paperStudents seem to embrace the new technique en masse and write entire essays with ChatGPT. Are they still encouraged to think critically? Yes, this is no fun for teachers, Gijsbers jokes. That is why we have to test knowledge differently. Just use pen and paper in an exam room again. But there are also advantages for lecturers. It now takes a lot of time and effort to explain to students how to write an essay. Programs will become available in the foreseeable future that will be very helpful in this regard. Just as well? Someone from the audience asked whether ChatGPT could have prepared as good a talk during the symposium as the speakers themselves. They thought not. According to philosopher Gijsbers, a speaker should tell a story that is true and that has value for the audience. I think the relationship between you and me is very different from the relationship between you and the technology.\"],\n",
       " [\"According to language technologist Zuidema, producing coherent pieces of text that are factually correct is often still too much to ask. The chatbot tries to base its answer on existing web texts, but if that doesn't work, it bluffs its way through and fills in nonsense. Sources are not mentioned. A new online program from Microsoft search engine Bing tries to do it the other way around and first look for sources for the answer, says Zuidema. Although the cohesion and separation of the information is not always good, it is at least possible to find out where the information comes from.Pen and paperStudents seem to embrace the new technique en masse and write entire essays with ChatGPT. Are they still encouraged to think critically? Yes, this is no fun for teachers, Gijsbers jokes. That is why we have to test knowledge differently. Just use pen and paper in an exam room again. But there are also advantages for lecturers. It now takes a lot of time and effort to explain to students how to write an essay. Programs will become available in the foreseeable future that will be very helpful in this regard. Just as well? Someone from the audience asked whether ChatGPT could have prepared as good a talk during the symposium as the speakers themselves. They thought not. According to philosopher Gijsbers, a speaker should tell a story that is true and that has value for the audience. I think the relationship between you and me is very different from the relationship between you and the technology.\"],\n",
       " ['In any case, students seem to be embracing the new technique en masse and write entire essays with ChatGPT. Are they still encouraged to think critically? Yes, this is no fun for teachers, Gijsbers jokes. That is why we have to test knowledge differently. Just use pen and paper in an exam room again. But there are also advantages for lecturers. It now takes a lot of time and effort to explain to students how to write an essay. Programs will become available in the foreseeable future that will be very helpful in this regard. Just as well? Someone from the audience asked whether ChatGPT could have prepared as good a talk during the symposium as the speakers themselves. They thought not. According to philosopher Gijsbers, a speaker should tell a story that is true and that has value for the audience. I think the relationship between you and me is very different from the relationship between you and the technology.'],\n",
       " ['Just go back to an exam room with pen and paper. But there are also advantages for lecturers. It now takes a lot of time and effort to explain to students how to write an essay. Programs will become available in the foreseeable future that will be very helpful in this regard. Just as well? Someone from the audience asked whether ChatGPT could have prepared as good a talk during the symposium as the speakers themselves. They thought not. According to philosopher Gijsbers, a speaker should tell a story that is true and that has value for the audience. I think the relationship between you and me is very different from the relationship between you and the technology.'],\n",
       " ['But there are also advantages for teachers. It now takes a lot of time and effort to explain to students how to write an essay. Programs will become available in the foreseeable future that will be very helpful in this regard. Just as well? Someone from the audience asked whether ChatGPT could have prepared as good a talk during the symposium as the speakers themselves. They thought not. According to philosopher Gijsbers, a speaker should tell a story that is true and that has value for the audience. I think the relationship between you and me is very different from the relationship between you and the technology.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Under the supervision of Assistant Professors, Mahmood Shafeie Zargar and Ella Hafermalz, a group of Vrije Universiteit Masters students explored how chatbots can revolutionize qualitative research. After only five months, the chatbots developed were able to successfully and autonomously complete qualitative interviews. The bots successfully captured interview data from different employees about how they had perceived their onboarding process. ChatLab showed that though the bots were not completely independent researchers, they can contribute to qualitative research.ChatLab1.0 and Insights Sharing SessionMore sophisticated chatbots may unleash a whole new range of possibilitiesChatbots have been a hot topic for the last couple of years, and they have been implemented across a range of industries. However, chatbots are rarely used to support qualitative research. One reason is that, in qualitative research, data collection is aimed at gathering rich information. Todays chatbot applications are instead only able to participate in limited, specific conversation topics. These bots are used as funnelling instruments, channelling conversations to a range of pre-specified objectives. A second reason is that qualitative interviewing is regarded as a human job which requires context knowledge and empathy. Chatbots often lack the ability to identify nuanced human emotions and cannot build context knowledge without first gathering a huge amount of specific and costly information. Despite these challenges, the students in ChatLab sank their teeth into developing an interview bot.Chatbots can be designed to autonomously conduct qualitative interviewsChatLab developed two bots that were able to autonomously complete qualitative interviews with employees on their perception of the onboarding process (often defined ast the first -days on a new job). Onboarding proved a great research context for these bots, as it entails both structural, repetitive procedures (e.g. a tour of the building) as well as emotional experiences of employees on their first day (e.g. feeling nervous or lost).The ChatLab studies resulted in two important preliminary findings: The chatbots were quite successful in asking probing questions, which are essential questions in qualitative interviewing. The bots successfully asked follow up questions aimed at evoking more detailed answers, such as what happened next? or how did that make you feel?. Bots tended to reduce social desirability bias compared to face-to-face interviews. Interviewees were less inclined to give socially desirable answers compared to when facing human interviewers. The tendency to make favourable impressions on other humans dropped which resulted in interviewees answering more honestly when being interviewed by a chatbot. On the short term, chatbots will not be able to mimic all human research skillsStill, the infant chatbots built by ChatLab in experienced some growing pains. Compared to human interviewers, the chatbot interviews resulted in less lengthy answers since the bots captured fewer examples and justifications for answers. Whereas interviews conducted by humans often exceed the original timeslot for an interview, the chatbots rarely took longer than expected. Human interviews can surface and dig deeper into new, interesting topics that were not originally anticipated, whereas chatbots are more rigid and stick to their original interview guide. Secondly, the chatbots struggled to adjust the conversation flow and the follow-up questions based on the content of the previous responses. At times, this resulted in awkward conversations as the interviewees got frustrated when the bot asked them redundant questions. To overcome this limitation, the students argue that a lot of data, e.g. in the form of human to human interview transcripts, will be needed to further train and develop the bots.To build more sophisticated bots, a multidisciplinary approach is essentialTo get to these insights, a group of Masters thesis students worked together in ChatLab, creating a complete design approach for the development of the chatbots. Each student covered a different perspective around the development and implementation of the chatbots into their research. They all worked together to gather traditional interview data which helped to feed the bot interview protocols and conversation flows. The bots were then deployed into real organizations and used to answer the students research questions.To capture important interviewing skills and to integrate those into the bots, the students conducted both face-to-face, as well as digital interviews and used their insights to design the chatbots. After numerous iterations, the chatbots started to show sufficient abilities to be able to conduct interviews autonomously. ChatLabs multidisciplinary approach, combing both domain knowledge and technical design features, is quite unique compared to how chatbots are often researched o'],\n",
       " ['ChatLab1.0 and Insights Sharing SessionMore sophisticated chatbots may unleash a whole new range of possibilitiesChatbots have been a hot topic for the last couple of years, and they have been implemented across a range of industries. However, chatbots are rarely used to support qualitative research. One reason is that, in qualitative research, data collection is aimed at gathering rich information. Todays chatbot applications are instead only able to participate in limited, specific conversation topics. These bots are used as funnelling instruments, channelling conversations to a range of pre-specified objectives. A second reason is that qualitative interviewing is regarded as a human job which requires context knowledge and empathy. Chatbots often lack the ability to identify nuanced human emotions and cannot build context knowledge without first gathering a huge amount of specific and costly information. Despite these challenges, the students in ChatLab sank their teeth into developing an interview bot.Chatbots can be designed to autonomously conduct qualitative interviewsChatLab developed two bots that were able to autonomously complete qualitative interviews with employees on their perception of the onboarding process (often defined ast the first -days on a new job). Onboarding proved a great research context for these bots, as it entails both structural, repetitive procedures (e.g. a tour of the building) as well as emotional experiences of employees on their first day (e.g. feeling nervous or lost).The ChatLab studies resulted in two important preliminary findings: The chatbots were quite successful in asking probing questions, which are essential questions in qualitative interviewing. The bots successfully asked follow up questions aimed at evoking more detailed answers, such as what happened next? or how did that make you feel?. Bots tended to reduce social desirability bias compared to face-to-face interviews. Interviewees were less inclined to give socially desirable answers compared to when facing human interviewers. The tendency to make favourable impressions on other humans dropped which resulted in interviewees answering more honestly when being interviewed by a chatbot. On the short term, chatbots will not be able to mimic all human research skillsStill, the infant chatbots built by ChatLab in experienced some growing pains. Compared to human interviewers, the chatbot interviews resulted in less lengthy answers since the bots captured fewer examples and justifications for answers. Whereas interviews conducted by humans often exceed the original timeslot for an interview, the chatbots rarely took longer than expected. Human interviews can surface and dig deeper into new, interesting topics that were not originally anticipated, whereas chatbots are more rigid and stick to their original interview guide. Secondly, the chatbots struggled to adjust the conversation flow and the follow-up questions based on the content of the previous responses. At times, this resulted in awkward conversations as the interviewees got frustrated when the bot asked them redundant questions. To overcome this limitation, the students argue that a lot of data, e.g. in the form of human to human interview transcripts, will be needed to further train and develop the bots.To build more sophisticated bots, a multidisciplinary approach is essentialTo get to these insights, a group of Masters thesis students worked together in ChatLab, creating a complete design approach for the development of the chatbots. Each student covered a different perspective around the development and implementation of the chatbots into their research. They all worked together to gather traditional interview data which helped to feed the bot interview protocols and conversation flows. The bots were then deployed into real organizations and used to answer the students research questions.To capture important interviewing skills and to integrate those into the bots, the students conducted both face-to-face, as well as digital interviews and used their insights to design the chatbots. After numerous iterations, the chatbots started to show sufficient abilities to be able to conduct interviews autonomously. ChatLabs multidisciplinary approach, combing both domain knowledge and technical design features, is quite unique compared to how chatbots are often researched or built. More often than not, a one-dimensional approach is chosen where technical design dominates. While this may work when building simplistic, funnelling bots, to develop more sophisticated chatbots, it is essential to also incorporate high-level domain knowledge. Perspectives included in the ChatLab included technical design, interview design, differences between human vs chatbot interviews, and the human perception of bot interviewers.Next steps: toward human-robot collaboration in qualitative research?In March , a new group of students have started to buil'],\n",
       " ['More sophisticated chatbots may unleash a whole new range of possibilitiesChatbots have been a hot topic for the last couple of years, and they have been implemented across a range of industries. However, chatbots are rarely used to support qualitative research. One reason is that, in qualitative research, data collection is aimed at gathering rich information. Todays chatbot applications are instead only able to participate in limited, specific conversation topics. These bots are used as funnelling instruments, channelling conversations to a range of pre-specified objectives. A second reason is that qualitative interviewing is regarded as a human job which requires context knowledge and empathy. Chatbots often lack the ability to identify nuanced human emotions and cannot build context knowledge without first gathering a huge amount of specific and costly information. Despite these challenges, the students in ChatLab sank their teeth into developing an interview bot.Chatbots can be designed to autonomously conduct qualitative interviewsChatLab developed two bots that were able to autonomously complete qualitative interviews with employees on their perception of the onboarding process (often defined ast the first -days on a new job). Onboarding proved a great research context for these bots, as it entails both structural, repetitive procedures (e.g. a tour of the building) as well as emotional experiences of employees on their first day (e.g. feeling nervous or lost).The ChatLab studies resulted in two important preliminary findings: The chatbots were quite successful in asking probing questions, which are essential questions in qualitative interviewing. The bots successfully asked follow up questions aimed at evoking more detailed answers, such as what happened next? or how did that make you feel?. Bots tended to reduce social desirability bias compared to face-to-face interviews. Interviewees were less inclined to give socially desirable answers compared to when facing human interviewers. The tendency to make favourable impressions on other humans dropped which resulted in interviewees answering more honestly when being interviewed by a chatbot. On the short term, chatbots will not be able to mimic all human research skillsStill, the infant chatbots built by ChatLab in experienced some growing pains. Compared to human interviewers, the chatbot interviews resulted in less lengthy answers since the bots captured fewer examples and justifications for answers. Whereas interviews conducted by humans often exceed the original timeslot for an interview, the chatbots rarely took longer than expected. Human interviews can surface and dig deeper into new, interesting topics that were not originally anticipated, whereas chatbots are more rigid and stick to their original interview guide. Secondly, the chatbots struggled to adjust the conversation flow and the follow-up questions based on the content of the previous responses. At times, this resulted in awkward conversations as the interviewees got frustrated when the bot asked them redundant questions. To overcome this limitation, the students argue that a lot of data, e.g. in the form of human to human interview transcripts, will be needed to further train and develop the bots.To build more sophisticated bots, a multidisciplinary approach is essentialTo get to these insights, a group of Masters thesis students worked together in ChatLab, creating a complete design approach for the development of the chatbots. Each student covered a different perspective around the development and implementation of the chatbots into their research. They all worked together to gather traditional interview data which helped to feed the bot interview protocols and conversation flows. The bots were then deployed into real organizations and used to answer the students research questions.To capture important interviewing skills and to integrate those into the bots, the students conducted both face-to-face, as well as digital interviews and used their insights to design the chatbots. After numerous iterations, the chatbots started to show sufficient abilities to be able to conduct interviews autonomously. ChatLabs multidisciplinary approach, combing both domain knowledge and technical design features, is quite unique compared to how chatbots are often researched or built. More often than not, a one-dimensional approach is chosen where technical design dominates. While this may work when building simplistic, funnelling bots, to develop more sophisticated chatbots, it is essential to also incorporate high-level domain knowledge. Perspectives included in the ChatLab included technical design, interview design, differences between human vs chatbot interviews, and the human perception of bot interviewers.Next steps: toward human-robot collaboration in qualitative research?In March , a new group of students have started to build on the research conducted by ChatLab .'],\n",
       " ['Chatbots have been a hot topic for the last couple of years, and they have been implemented across a range of industries. However, chatbots are rarely used to support qualitative research. One reason is that, in qualitative research, data collection is aimed at gathering rich information. Todays chatbot applications are instead only able to participate in limited, specific conversation topics. These bots are used as funnelling instruments, channelling conversations to a range of pre-specified objectives. A second reason is that qualitative interviewing is regarded as a human job which requires context knowledge and empathy. Chatbots often lack the ability to identify nuanced human emotions and cannot build context knowledge without first gathering a huge amount of specific and costly information. Despite these challenges, the students in ChatLab sank their teeth into developing an interview bot.Chatbots can be designed to autonomously conduct qualitative interviewsChatLab developed two bots that were able to autonomously complete qualitative interviews with employees on their perception of the onboarding process (often defined ast the first -days on a new job). Onboarding proved a great research context for these bots, as it entails both structural, repetitive procedures (e.g. a tour of the building) as well as emotional experiences of employees on their first day (e.g. feeling nervous or lost).The ChatLab studies resulted in two important preliminary findings: The chatbots were quite successful in asking probing questions, which are essential questions in qualitative interviewing. The bots successfully asked follow up questions aimed at evoking more detailed answers, such as what happened next? or how did that make you feel?. Bots tended to reduce social desirability bias compared to face-to-face interviews. Interviewees were less inclined to give socially desirable answers compared to when facing human interviewers. The tendency to make favourable impressions on other humans dropped which resulted in interviewees answering more honestly when being interviewed by a chatbot. On the short term, chatbots will not be able to mimic all human research skillsStill, the infant chatbots built by ChatLab in experienced some growing pains. Compared to human interviewers, the chatbot interviews resulted in less lengthy answers since the bots captured fewer examples and justifications for answers. Whereas interviews conducted by humans often exceed the original timeslot for an interview, the chatbots rarely took longer than expected. Human interviews can surface and dig deeper into new, interesting topics that were not originally anticipated, whereas chatbots are more rigid and stick to their original interview guide. Secondly, the chatbots struggled to adjust the conversation flow and the follow-up questions based on the content of the previous responses. At times, this resulted in awkward conversations as the interviewees got frustrated when the bot asked them redundant questions. To overcome this limitation, the students argue that a lot of data, e.g. in the form of human to human interview transcripts, will be needed to further train and develop the bots.To build more sophisticated bots, a multidisciplinary approach is essentialTo get to these insights, a group of Masters thesis students worked together in ChatLab, creating a complete design approach for the development of the chatbots. Each student covered a different perspective around the development and implementation of the chatbots into their research. They all worked together to gather traditional interview data which helped to feed the bot interview protocols and conversation flows. The bots were then deployed into real organizations and used to answer the students research questions.To capture important interviewing skills and to integrate those into the bots, the students conducted both face-to-face, as well as digital interviews and used their insights to design the chatbots. After numerous iterations, the chatbots started to show sufficient abilities to be able to conduct interviews autonomously. ChatLabs multidisciplinary approach, combing both domain knowledge and technical design features, is quite unique compared to how chatbots are often researched or built. More often than not, a one-dimensional approach is chosen where technical design dominates. While this may work when building simplistic, funnelling bots, to develop more sophisticated chatbots, it is essential to also incorporate high-level domain knowledge. Perspectives included in the ChatLab included technical design, interview design, differences between human vs chatbot interviews, and the human perception of bot interviewers.Next steps: toward human-robot collaboration in qualitative research?In March , a new group of students have started to build on the research conducted by ChatLab . The continuous nature of ChatLab is essential to develop a deep knowledge'],\n",
       " ['Chatbots can be designed to autonomously conduct qualitative interviewsChatLab developed two bots that were able to autonomously complete qualitative interviews with employees on their perception of the onboarding process (often defined ast the first -days on a new job). Onboarding proved a great research context for these bots, as it entails both structural, repetitive procedures (e.g. a tour of the building) as well as emotional experiences of employees on their first day (e.g. feeling nervous or lost).The ChatLab studies resulted in two important preliminary findings: The chatbots were quite successful in asking probing questions, which are essential questions in qualitative interviewing. The bots successfully asked follow up questions aimed at evoking more detailed answers, such as what happened next? or how did that make you feel?. Bots tended to reduce social desirability bias compared to face-to-face interviews. Interviewees were less inclined to give socially desirable answers compared to when facing human interviewers. The tendency to make favourable impressions on other humans dropped which resulted in interviewees answering more honestly when being interviewed by a chatbot. On the short term, chatbots will not be able to mimic all human research skillsStill, the infant chatbots built by ChatLab in experienced some growing pains. Compared to human interviewers, the chatbot interviews resulted in less lengthy answers since the bots captured fewer examples and justifications for answers. Whereas interviews conducted by humans often exceed the original timeslot for an interview, the chatbots rarely took longer than expected. Human interviews can surface and dig deeper into new, interesting topics that were not originally anticipated, whereas chatbots are more rigid and stick to their original interview guide. Secondly, the chatbots struggled to adjust the conversation flow and the follow-up questions based on the content of the previous responses. At times, this resulted in awkward conversations as the interviewees got frustrated when the bot asked them redundant questions. To overcome this limitation, the students argue that a lot of data, e.g. in the form of human to human interview transcripts, will be needed to further train and develop the bots.To build more sophisticated bots, a multidisciplinary approach is essentialTo get to these insights, a group of Masters thesis students worked together in ChatLab, creating a complete design approach for the development of the chatbots. Each student covered a different perspective around the development and implementation of the chatbots into their research. They all worked together to gather traditional interview data which helped to feed the bot interview protocols and conversation flows. The bots were then deployed into real organizations and used to answer the students research questions.To capture important interviewing skills and to integrate those into the bots, the students conducted both face-to-face, as well as digital interviews and used their insights to design the chatbots. After numerous iterations, the chatbots started to show sufficient abilities to be able to conduct interviews autonomously. ChatLabs multidisciplinary approach, combing both domain knowledge and technical design features, is quite unique compared to how chatbots are often researched or built. More often than not, a one-dimensional approach is chosen where technical design dominates. While this may work when building simplistic, funnelling bots, to develop more sophisticated chatbots, it is essential to also incorporate high-level domain knowledge. Perspectives included in the ChatLab included technical design, interview design, differences between human vs chatbot interviews, and the human perception of bot interviewers.Next steps: toward human-robot collaboration in qualitative research?In March , a new group of students have started to build on the research conducted by ChatLab . The continuous nature of ChatLab is essential to develop a deep knowledge base across multiple cohorts. This way, the combination of theses and cohorts will help to build even more sophisticated bots able to generate and capture rich responses from interviewees.Whether such chatbots may replace human interviewers some day is hard to answer. Traditional human abilities to capture emotions and interpret intonations or body language will remain difficult to mimic in a bot. However, while, on short term, bots may not yet reach the same level of skills as humans in semi-structured interviews, they might prove valuable at certain stages of the research process.As is seen in other industries as well, robots and humans can very well complement each other. For example, one could think of chatbots conducting the introductory parts of interviews or doing interview sweeps, finding the most interesting interviewees for human colleagues to follow-up with. This way, chatbots could s'],\n",
       " ['ChatLab developed two bots that were able to autonomously complete qualitative interviews with employees on their perception of the onboarding process (often defined ast the first -days on a new job). Onboarding proved a great research context for these bots, as it entails both structural, repetitive procedures (e.g. a tour of the building) as well as emotional experiences of employees on their first day (e.g. feeling nervous or lost).The ChatLab studies resulted in two important preliminary findings: The chatbots were quite successful in asking probing questions, which are essential questions in qualitative interviewing. The bots successfully asked follow up questions aimed at evoking more detailed answers, such as what happened next? or how did that make you feel?. Bots tended to reduce social desirability bias compared to face-to-face interviews. Interviewees were less inclined to give socially desirable answers compared to when facing human interviewers. The tendency to make favourable impressions on other humans dropped which resulted in interviewees answering more honestly when being interviewed by a chatbot. On the short term, chatbots will not be able to mimic all human research skillsStill, the infant chatbots built by ChatLab in experienced some growing pains. Compared to human interviewers, the chatbot interviews resulted in less lengthy answers since the bots captured fewer examples and justifications for answers. Whereas interviews conducted by humans often exceed the original timeslot for an interview, the chatbots rarely took longer than expected. Human interviews can surface and dig deeper into new, interesting topics that were not originally anticipated, whereas chatbots are more rigid and stick to their original interview guide. Secondly, the chatbots struggled to adjust the conversation flow and the follow-up questions based on the content of the previous responses. At times, this resulted in awkward conversations as the interviewees got frustrated when the bot asked them redundant questions. To overcome this limitation, the students argue that a lot of data, e.g. in the form of human to human interview transcripts, will be needed to further train and develop the bots.To build more sophisticated bots, a multidisciplinary approach is essentialTo get to these insights, a group of Masters thesis students worked together in ChatLab, creating a complete design approach for the development of the chatbots. Each student covered a different perspective around the development and implementation of the chatbots into their research. They all worked together to gather traditional interview data which helped to feed the bot interview protocols and conversation flows. The bots were then deployed into real organizations and used to answer the students research questions.To capture important interviewing skills and to integrate those into the bots, the students conducted both face-to-face, as well as digital interviews and used their insights to design the chatbots. After numerous iterations, the chatbots started to show sufficient abilities to be able to conduct interviews autonomously. ChatLabs multidisciplinary approach, combing both domain knowledge and technical design features, is quite unique compared to how chatbots are often researched or built. More often than not, a one-dimensional approach is chosen where technical design dominates. While this may work when building simplistic, funnelling bots, to develop more sophisticated chatbots, it is essential to also incorporate high-level domain knowledge. Perspectives included in the ChatLab included technical design, interview design, differences between human vs chatbot interviews, and the human perception of bot interviewers.Next steps: toward human-robot collaboration in qualitative research?In March , a new group of students have started to build on the research conducted by ChatLab . The continuous nature of ChatLab is essential to develop a deep knowledge base across multiple cohorts. This way, the combination of theses and cohorts will help to build even more sophisticated bots able to generate and capture rich responses from interviewees.Whether such chatbots may replace human interviewers some day is hard to answer. Traditional human abilities to capture emotions and interpret intonations or body language will remain difficult to mimic in a bot. However, while, on short term, bots may not yet reach the same level of skills as humans in semi-structured interviews, they might prove valuable at certain stages of the research process.As is seen in other industries as well, robots and humans can very well complement each other. For example, one could think of chatbots conducting the introductory parts of interviews or doing interview sweeps, finding the most interesting interviewees for human colleagues to follow-up with. This way, chatbots could save precious time by processing more potential candidates and allowing'],\n",
       " ['he ChatLab studies resulted in two important preliminary findings: The chatbots were quite successful in asking probing questions, which are essential questions in qualitative interviewing. The bots successfully asked follow up questions aimed at evoking more detailed answers, such as what happened next? or how did that make you feel?. Bots tended to reduce social desirability bias compared to face-to-face interviews. Interviewees were less inclined to give socially desirable answers compared to when facing human interviewers. The tendency to make favourable impressions on other humans dropped which resulted in interviewees answering more honestly when being interviewed by a chatbot. On the short term, chatbots will not be able to mimic all human research skillsStill, the infant chatbots built by ChatLab in experienced some growing pains. Compared to human interviewers, the chatbot interviews resulted in less lengthy answers since the bots captured fewer examples and justifications for answers. Whereas interviews conducted by humans often exceed the original timeslot for an interview, the chatbots rarely took longer than expected. Human interviews can surface and dig deeper into new, interesting topics that were not originally anticipated, whereas chatbots are more rigid and stick to their original interview guide. Secondly, the chatbots struggled to adjust the conversation flow and the follow-up questions based on the content of the previous responses. At times, this resulted in awkward conversations as the interviewees got frustrated when the bot asked them redundant questions. To overcome this limitation, the students argue that a lot of data, e.g. in the form of human to human interview transcripts, will be needed to further train and develop the bots.To build more sophisticated bots, a multidisciplinary approach is essentialTo get to these insights, a group of Masters thesis students worked together in ChatLab, creating a complete design approach for the development of the chatbots. Each student covered a different perspective around the development and implementation of the chatbots into their research. They all worked together to gather traditional interview data which helped to feed the bot interview protocols and conversation flows. The bots were then deployed into real organizations and used to answer the students research questions.To capture important interviewing skills and to integrate those into the bots, the students conducted both face-to-face, as well as digital interviews and used their insights to design the chatbots. After numerous iterations, the chatbots started to show sufficient abilities to be able to conduct interviews autonomously. ChatLabs multidisciplinary approach, combing both domain knowledge and technical design features, is quite unique compared to how chatbots are often researched or built. More often than not, a one-dimensional approach is chosen where technical design dominates. While this may work when building simplistic, funnelling bots, to develop more sophisticated chatbots, it is essential to also incorporate high-level domain knowledge. Perspectives included in the ChatLab included technical design, interview design, differences between human vs chatbot interviews, and the human perception of bot interviewers.Next steps: toward human-robot collaboration in qualitative research?In March , a new group of students have started to build on the research conducted by ChatLab . The continuous nature of ChatLab is essential to develop a deep knowledge base across multiple cohorts. This way, the combination of theses and cohorts will help to build even more sophisticated bots able to generate and capture rich responses from interviewees.Whether such chatbots may replace human interviewers some day is hard to answer. Traditional human abilities to capture emotions and interpret intonations or body language will remain difficult to mimic in a bot. However, while, on short term, bots may not yet reach the same level of skills as humans in semi-structured interviews, they might prove valuable at certain stages of the research process.As is seen in other industries as well, robots and humans can very well complement each other. For example, one could think of chatbots conducting the introductory parts of interviews or doing interview sweeps, finding the most interesting interviewees for human colleagues to follow-up with. This way, chatbots could save precious time by processing more potential candidates and allowing their human counterparts to focus on the cognitively challenging parts. In this way, artificial intelligence can augment rather than automate human tasks and skills.In March , a new group of Masters students have picked up where the cohort left off. They will further develop the chatbot and focus on the design of the bot, the interview design, chatbots performance vs human interviewers, and human perception.Deep dive into th'],\n",
       " ['On the short term, chatbots will not be able to mimic all human research skillsStill, the infant chatbots built by ChatLab in experienced some growing pains. Compared to human interviewers, the chatbot interviews resulted in less lengthy answers since the bots captured fewer examples and justifications for answers. Whereas interviews conducted by humans often exceed the original timeslot for an interview, the chatbots rarely took longer than expected. Human interviews can surface and dig deeper into new, interesting topics that were not originally anticipated, whereas chatbots are more rigid and stick to their original interview guide. Secondly, the chatbots struggled to adjust the conversation flow and the follow-up questions based on the content of the previous responses. At times, this resulted in awkward conversations as the interviewees got frustrated when the bot asked them redundant questions. To overcome this limitation, the students argue that a lot of data, e.g. in the form of human to human interview transcripts, will be needed to further train and develop the bots.To build more sophisticated bots, a multidisciplinary approach is essentialTo get to these insights, a group of Masters thesis students worked together in ChatLab, creating a complete design approach for the development of the chatbots. Each student covered a different perspective around the development and implementation of the chatbots into their research. They all worked together to gather traditional interview data which helped to feed the bot interview protocols and conversation flows. The bots were then deployed into real organizations and used to answer the students research questions.To capture important interviewing skills and to integrate those into the bots, the students conducted both face-to-face, as well as digital interviews and used their insights to design the chatbots. After numerous iterations, the chatbots started to show sufficient abilities to be able to conduct interviews autonomously. ChatLabs multidisciplinary approach, combing both domain knowledge and technical design features, is quite unique compared to how chatbots are often researched or built. More often than not, a one-dimensional approach is chosen where technical design dominates. While this may work when building simplistic, funnelling bots, to develop more sophisticated chatbots, it is essential to also incorporate high-level domain knowledge. Perspectives included in the ChatLab included technical design, interview design, differences between human vs chatbot interviews, and the human perception of bot interviewers.Next steps: toward human-robot collaboration in qualitative research?In March , a new group of students have started to build on the research conducted by ChatLab . The continuous nature of ChatLab is essential to develop a deep knowledge base across multiple cohorts. This way, the combination of theses and cohorts will help to build even more sophisticated bots able to generate and capture rich responses from interviewees.Whether such chatbots may replace human interviewers some day is hard to answer. Traditional human abilities to capture emotions and interpret intonations or body language will remain difficult to mimic in a bot. However, while, on short term, bots may not yet reach the same level of skills as humans in semi-structured interviews, they might prove valuable at certain stages of the research process.As is seen in other industries as well, robots and humans can very well complement each other. For example, one could think of chatbots conducting the introductory parts of interviews or doing interview sweeps, finding the most interesting interviewees for human colleagues to follow-up with. This way, chatbots could save precious time by processing more potential candidates and allowing their human counterparts to focus on the cognitively challenging parts. In this way, artificial intelligence can augment rather than automate human tasks and skills.In March , a new group of Masters students have picked up where the cohort left off. They will further develop the chatbot and focus on the design of the bot, the interview design, chatbots performance vs human interviewers, and human perception.Deep dive into the contentAre you interested to learn more about this research? Please contact KIN.SBE.NL for more information. We work with organizations to connect and translate these insights into your contexts.Browse the cohort theses here: Tugce Bilge Can chatbots make you talk? Carla Manquillo Huete Application of the chatbot technology on interviewing as qualitative research tool Alexander Berkhout Do we care what we say to a chatbot? Eleni Diasiti Face-to-face versus Chatbot Interviews: The Implementation of Probes on the Quality of Answers Bas Wolff Designing a chatbot interview Are you interested in doing a PhD on AI and its use in organizations? Apply to work and study with us'],\n",
       " ['Still, the infant chatbots built by ChatLab in experienced some growing pains. Compared to human interviewers, the chatbot interviews resulted in less lengthy answers since the bots captured fewer examples and justifications for answers. Whereas interviews conducted by humans often exceed the original timeslot for an interview, the chatbots rarely took longer than expected. Human interviews can surface and dig deeper into new, interesting topics that were not originally anticipated, whereas chatbots are more rigid and stick to their original interview guide. Secondly, the chatbots struggled to adjust the conversation flow and the follow-up questions based on the content of the previous responses. At times, this resulted in awkward conversations as the interviewees got frustrated when the bot asked them redundant questions. To overcome this limitation, the students argue that a lot of data, e.g. in the form of human to human interview transcripts, will be needed to further train and develop the bots.To build more sophisticated bots, a multidisciplinary approach is essentialTo get to these insights, a group of Masters thesis students worked together in ChatLab, creating a complete design approach for the development of the chatbots. Each student covered a different perspective around the development and implementation of the chatbots into their research. They all worked together to gather traditional interview data which helped to feed the bot interview protocols and conversation flows. The bots were then deployed into real organizations and used to answer the students research questions.To capture important interviewing skills and to integrate those into the bots, the students conducted both face-to-face, as well as digital interviews and used their insights to design the chatbots. After numerous iterations, the chatbots started to show sufficient abilities to be able to conduct interviews autonomously. ChatLabs multidisciplinary approach, combing both domain knowledge and technical design features, is quite unique compared to how chatbots are often researched or built. More often than not, a one-dimensional approach is chosen where technical design dominates. While this may work when building simplistic, funnelling bots, to develop more sophisticated chatbots, it is essential to also incorporate high-level domain knowledge. Perspectives included in the ChatLab included technical design, interview design, differences between human vs chatbot interviews, and the human perception of bot interviewers.Next steps: toward human-robot collaboration in qualitative research?In March , a new group of students have started to build on the research conducted by ChatLab . The continuous nature of ChatLab is essential to develop a deep knowledge base across multiple cohorts. This way, the combination of theses and cohorts will help to build even more sophisticated bots able to generate and capture rich responses from interviewees.Whether such chatbots may replace human interviewers some day is hard to answer. Traditional human abilities to capture emotions and interpret intonations or body language will remain difficult to mimic in a bot. However, while, on short term, bots may not yet reach the same level of skills as humans in semi-structured interviews, they might prove valuable at certain stages of the research process.As is seen in other industries as well, robots and humans can very well complement each other. For example, one could think of chatbots conducting the introductory parts of interviews or doing interview sweeps, finding the most interesting interviewees for human colleagues to follow-up with. This way, chatbots could save precious time by processing more potential candidates and allowing their human counterparts to focus on the cognitively challenging parts. In this way, artificial intelligence can augment rather than automate human tasks and skills.In March , a new group of Masters students have picked up where the cohort left off. They will further develop the chatbot and focus on the design of the bot, the interview design, chatbots performance vs human interviewers, and human perception.Deep dive into the contentAre you interested to learn more about this research? Please contact KIN.SBE.NL for more information. We work with organizations to connect and translate these insights into your contexts.Browse the cohort theses here: Tugce Bilge Can chatbots make you talk? Carla Manquillo Huete Application of the chatbot technology on interviewing as qualitative research tool Alexander Berkhout Do we care what we say to a chatbot? Eleni Diasiti Face-to-face versus Chatbot Interviews: The Implementation of Probes on the Quality of Answers Bas Wolff Designing a chatbot interview Are you interested in doing a PhD on AI and its use in organizations? Apply to work and study with us before May th! Read more here. Author: Juul Cappon'],\n",
       " ['o build more sophisticated bots, a multidisciplinary approach is essentialTo get to these insights, a group of Masters thesis students worked together in ChatLab, creating a complete design approach for the development of the chatbots. Each student covered a different perspective around the development and implementation of the chatbots into their research. They all worked together to gather traditional interview data which helped to feed the bot interview protocols and conversation flows. The bots were then deployed into real organizations and used to answer the students research questions.To capture important interviewing skills and to integrate those into the bots, the students conducted both face-to-face, as well as digital interviews and used their insights to design the chatbots. After numerous iterations, the chatbots started to show sufficient abilities to be able to conduct interviews autonomously. ChatLabs multidisciplinary approach, combing both domain knowledge and technical design features, is quite unique compared to how chatbots are often researched or built. More often than not, a one-dimensional approach is chosen where technical design dominates. While this may work when building simplistic, funnelling bots, to develop more sophisticated chatbots, it is essential to also incorporate high-level domain knowledge. Perspectives included in the ChatLab included technical design, interview design, differences between human vs chatbot interviews, and the human perception of bot interviewers.Next steps: toward human-robot collaboration in qualitative research?In March , a new group of students have started to build on the research conducted by ChatLab . The continuous nature of ChatLab is essential to develop a deep knowledge base across multiple cohorts. This way, the combination of theses and cohorts will help to build even more sophisticated bots able to generate and capture rich responses from interviewees.Whether such chatbots may replace human interviewers some day is hard to answer. Traditional human abilities to capture emotions and interpret intonations or body language will remain difficult to mimic in a bot. However, while, on short term, bots may not yet reach the same level of skills as humans in semi-structured interviews, they might prove valuable at certain stages of the research process.As is seen in other industries as well, robots and humans can very well complement each other. For example, one could think of chatbots conducting the introductory parts of interviews or doing interview sweeps, finding the most interesting interviewees for human colleagues to follow-up with. This way, chatbots could save precious time by processing more potential candidates and allowing their human counterparts to focus on the cognitively challenging parts. In this way, artificial intelligence can augment rather than automate human tasks and skills.In March , a new group of Masters students have picked up where the cohort left off. They will further develop the chatbot and focus on the design of the bot, the interview design, chatbots performance vs human interviewers, and human perception.Deep dive into the contentAre you interested to learn more about this research? Please contact KIN.SBE.NL for more information. We work with organizations to connect and translate these insights into your contexts.Browse the cohort theses here: Tugce Bilge Can chatbots make you talk? Carla Manquillo Huete Application of the chatbot technology on interviewing as qualitative research tool Alexander Berkhout Do we care what we say to a chatbot? Eleni Diasiti Face-to-face versus Chatbot Interviews: The Implementation of Probes on the Quality of Answers Bas Wolff Designing a chatbot interview Are you interested in doing a PhD on AI and its use in organizations? Apply to work and study with us before May th! Read more here. Author: Juul Cappon'],\n",
       " ['o get to these insights, a group of Masters thesis students worked together in ChatLab, creating a complete design approach for the development of the chatbots. Each student covered a different perspective around the development and implementation of the chatbots into their research. They all worked together to gather traditional interview data which helped to feed the bot interview protocols and conversation flows. The bots were then deployed into real organizations and used to answer the students research questions.To capture important interviewing skills and to integrate those into the bots, the students conducted both face-to-face, as well as digital interviews and used their insights to design the chatbots. After numerous iterations, the chatbots started to show sufficient abilities to be able to conduct interviews autonomously. ChatLabs multidisciplinary approach, combing both domain knowledge and technical design features, is quite unique compared to how chatbots are often researched or built. More often than not, a one-dimensional approach is chosen where technical design dominates. While this may work when building simplistic, funnelling bots, to develop more sophisticated chatbots, it is essential to also incorporate high-level domain knowledge. Perspectives included in the ChatLab included technical design, interview design, differences between human vs chatbot interviews, and the human perception of bot interviewers.Next steps: toward human-robot collaboration in qualitative research?In March , a new group of students have started to build on the research conducted by ChatLab . The continuous nature of ChatLab is essential to develop a deep knowledge base across multiple cohorts. This way, the combination of theses and cohorts will help to build even more sophisticated bots able to generate and capture rich responses from interviewees.Whether such chatbots may replace human interviewers some day is hard to answer. Traditional human abilities to capture emotions and interpret intonations or body language will remain difficult to mimic in a bot. However, while, on short term, bots may not yet reach the same level of skills as humans in semi-structured interviews, they might prove valuable at certain stages of the research process.As is seen in other industries as well, robots and humans can very well complement each other. For example, one could think of chatbots conducting the introductory parts of interviews or doing interview sweeps, finding the most interesting interviewees for human colleagues to follow-up with. This way, chatbots could save precious time by processing more potential candidates and allowing their human counterparts to focus on the cognitively challenging parts. In this way, artificial intelligence can augment rather than automate human tasks and skills.In March , a new group of Masters students have picked up where the cohort left off. They will further develop the chatbot and focus on the design of the bot, the interview design, chatbots performance vs human interviewers, and human perception.Deep dive into the contentAre you interested to learn more about this research? Please contact KIN.SBE.NL for more information. We work with organizations to connect and translate these insights into your contexts.Browse the cohort theses here: Tugce Bilge Can chatbots make you talk? Carla Manquillo Huete Application of the chatbot technology on interviewing as qualitative research tool Alexander Berkhout Do we care what we say to a chatbot? Eleni Diasiti Face-to-face versus Chatbot Interviews: The Implementation of Probes on the Quality of Answers Bas Wolff Designing a chatbot interview Are you interested in doing a PhD on AI and its use in organizations? Apply to work and study with us before May th! Read more here. Author: Juul Cappon'],\n",
       " ['o capture important interviewing skills and to integrate those into the bots, the students conducted both face-to-face, as well as digital interviews and used their insights to design the chatbots. After numerous iterations, the chatbots started to show sufficient abilities to be able to conduct interviews autonomously. ChatLabs multidisciplinary approach, combing both domain knowledge and technical design features, is quite unique compared to how chatbots are often researched or built. More often than not, a one-dimensional approach is chosen where technical design dominates. While this may work when building simplistic, funnelling bots, to develop more sophisticated chatbots, it is essential to also incorporate high-level domain knowledge. Perspectives included in the ChatLab included technical design, interview design, differences between human vs chatbot interviews, and the human perception of bot interviewers.Next steps: toward human-robot collaboration in qualitative research?In March , a new group of students have started to build on the research conducted by ChatLab . The continuous nature of ChatLab is essential to develop a deep knowledge base across multiple cohorts. This way, the combination of theses and cohorts will help to build even more sophisticated bots able to generate and capture rich responses from interviewees.Whether such chatbots may replace human interviewers some day is hard to answer. Traditional human abilities to capture emotions and interpret intonations or body language will remain difficult to mimic in a bot. However, while, on short term, bots may not yet reach the same level of skills as humans in semi-structured interviews, they might prove valuable at certain stages of the research process.As is seen in other industries as well, robots and humans can very well complement each other. For example, one could think of chatbots conducting the introductory parts of interviews or doing interview sweeps, finding the most interesting interviewees for human colleagues to follow-up with. This way, chatbots could save precious time by processing more potential candidates and allowing their human counterparts to focus on the cognitively challenging parts. In this way, artificial intelligence can augment rather than automate human tasks and skills.In March , a new group of Masters students have picked up where the cohort left off. They will further develop the chatbot and focus on the design of the bot, the interview design, chatbots performance vs human interviewers, and human perception.Deep dive into the contentAre you interested to learn more about this research? Please contact KIN.SBE.NL for more information. We work with organizations to connect and translate these insights into your contexts.Browse the cohort theses here: Tugce Bilge Can chatbots make you talk? Carla Manquillo Huete Application of the chatbot technology on interviewing as qualitative research tool Alexander Berkhout Do we care what we say to a chatbot? Eleni Diasiti Face-to-face versus Chatbot Interviews: The Implementation of Probes on the Quality of Answers Bas Wolff Designing a chatbot interview Are you interested in doing a PhD on AI and its use in organizations? Apply to work and study with us before May th! Read more here. Author: Juul Cappon'],\n",
       " ['Next steps: toward human-robot collaboration in qualitative research?In March , a new group of students have started to build on the research conducted by ChatLab . The continuous nature of ChatLab is essential to develop a deep knowledge base across multiple cohorts. This way, the combination of theses and cohorts will help to build even more sophisticated bots able to generate and capture rich responses from interviewees.Whether such chatbots may replace human interviewers some day is hard to answer. Traditional human abilities to capture emotions and interpret intonations or body language will remain difficult to mimic in a bot. However, while, on short term, bots may not yet reach the same level of skills as humans in semi-structured interviews, they might prove valuable at certain stages of the research process.As is seen in other industries as well, robots and humans can very well complement each other. For example, one could think of chatbots conducting the introductory parts of interviews or doing interview sweeps, finding the most interesting interviewees for human colleagues to follow-up with. This way, chatbots could save precious time by processing more potential candidates and allowing their human counterparts to focus on the cognitively challenging parts. In this way, artificial intelligence can augment rather than automate human tasks and skills.In March , a new group of Masters students have picked up where the cohort left off. They will further develop the chatbot and focus on the design of the bot, the interview design, chatbots performance vs human interviewers, and human perception.Deep dive into the contentAre you interested to learn more about this research? Please contact KIN.SBE.NL for more information. We work with organizations to connect and translate these insights into your contexts.Browse the cohort theses here: Tugce Bilge Can chatbots make you talk? Carla Manquillo Huete Application of the chatbot technology on interviewing as qualitative research tool Alexander Berkhout Do we care what we say to a chatbot? Eleni Diasiti Face-to-face versus Chatbot Interviews: The Implementation of Probes on the Quality of Answers Bas Wolff Designing a chatbot interview Are you interested in doing a PhD on AI and its use in organizations? Apply to work and study with us before May th! Read more here. Author: Juul Cappon'],\n",
       " ['In March , a new group of students have started to build on the research conducted by ChatLab . The continuous nature of ChatLab is essential to develop a deep knowledge base across multiple cohorts. This way, the combination of theses and cohorts will help to build even more sophisticated bots able to generate and capture rich responses from interviewees.Whether such chatbots may replace human interviewers some day is hard to answer. Traditional human abilities to capture emotions and interpret intonations or body language will remain difficult to mimic in a bot. However, while, on short term, bots may not yet reach the same level of skills as humans in semi-structured interviews, they might prove valuable at certain stages of the research process.As is seen in other industries as well, robots and humans can very well complement each other. For example, one could think of chatbots conducting the introductory parts of interviews or doing interview sweeps, finding the most interesting interviewees for human colleagues to follow-up with. This way, chatbots could save precious time by processing more potential candidates and allowing their human counterparts to focus on the cognitively challenging parts. In this way, artificial intelligence can augment rather than automate human tasks and skills.In March , a new group of Masters students have picked up where the cohort left off. They will further develop the chatbot and focus on the design of the bot, the interview design, chatbots performance vs human interviewers, and human perception.Deep dive into the contentAre you interested to learn more about this research? Please contact KIN.SBE.NL for more information. We work with organizations to connect and translate these insights into your contexts.Browse the cohort theses here: Tugce Bilge Can chatbots make you talk? Carla Manquillo Huete Application of the chatbot technology on interviewing as qualitative research tool Alexander Berkhout Do we care what we say to a chatbot? Eleni Diasiti Face-to-face versus Chatbot Interviews: The Implementation of Probes on the Quality of Answers Bas Wolff Designing a chatbot interview Are you interested in doing a PhD on AI and its use in organizations? Apply to work and study with us before May th! Read more here. Author: Juul Cappon'],\n",
       " ['Whether such chatbots may replace human interviewers some day is hard to answer. Traditional human abilities to capture emotions and interpret intonations or body language will remain difficult to mimic in a bot. However, while, on short term, bots may not yet reach the same level of skills as humans in semi-structured interviews, they might prove valuable at certain stages of the research process.As is seen in other industries as well, robots and humans can very well complement each other. For example, one could think of chatbots conducting the introductory parts of interviews or doing interview sweeps, finding the most interesting interviewees for human colleagues to follow-up with. This way, chatbots could save precious time by processing more potential candidates and allowing their human counterparts to focus on the cognitively challenging parts. In this way, artificial intelligence can augment rather than automate human tasks and skills.In March , a new group of Masters students have picked up where the cohort left off. They will further develop the chatbot and focus on the design of the bot, the interview design, chatbots performance vs human interviewers, and human perception.Deep dive into the contentAre you interested to learn more about this research? Please contact KIN.SBE.NL for more information. We work with organizations to connect and translate these insights into your contexts.Browse the cohort theses here: Tugce Bilge Can chatbots make you talk? Carla Manquillo Huete Application of the chatbot technology on interviewing as qualitative research tool Alexander Berkhout Do we care what we say to a chatbot? Eleni Diasiti Face-to-face versus Chatbot Interviews: The Implementation of Probes on the Quality of Answers Bas Wolff Designing a chatbot interview Are you interested in doing a PhD on AI and its use in organizations? Apply to work and study with us before May th! Read more here. Author: Juul Cappon'],\n",
       " ['As is seen in other industries as well, robots and humans can very well complement each other. For example, one could think of chatbots conducting the introductory parts of interviews or doing interview sweeps, finding the most interesting interviewees for human colleagues to follow-up with. This way, chatbots could save precious time by processing more potential candidates and allowing their human counterparts to focus on the cognitively challenging parts. In this way, artificial intelligence can augment rather than automate human tasks and skills.In March , a new group of Masters students have picked up where the cohort left off. They will further develop the chatbot and focus on the design of the bot, the interview design, chatbots performance vs human interviewers, and human perception.Deep dive into the contentAre you interested to learn more about this research? Please contact KIN.SBE.NL for more information. We work with organizations to connect and translate these insights into your contexts.Browse the cohort theses here: Tugce Bilge Can chatbots make you talk? Carla Manquillo Huete Application of the chatbot technology on interviewing as qualitative research tool Alexander Berkhout Do we care what we say to a chatbot? Eleni Diasiti Face-to-face versus Chatbot Interviews: The Implementation of Probes on the Quality of Answers Bas Wolff Designing a chatbot interview Are you interested in doing a PhD on AI and its use in organizations? Apply to work and study with us before May th! Read more here. Author: Juul Cappon'],\n",
       " ['In March , a new group of Masters students have picked up where the cohort left off. They will further develop the chatbot and focus on the design of the bot, the interview design, chatbots performance vs human interviewers, and human perception.Deep dive into the contentAre you interested to learn more about this research? Please contact KIN.SBE.NL for more information. We work with organizations to connect and translate these insights into your contexts.Browse the cohort theses here: Tugce Bilge Can chatbots make you talk? Carla Manquillo Huete Application of the chatbot technology on interviewing as qualitative research tool Alexander Berkhout Do we care what we say to a chatbot? Eleni Diasiti Face-to-face versus Chatbot Interviews: The Implementation of Probes on the Quality of Answers Bas Wolff Designing a chatbot interview Are you interested in doing a PhD on AI and its use in organizations? Apply to work and study with us before May th! Read more here. Author: Juul Cappon'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['he Hybrid Intelligence CentreThe Hybrid Intelligence Centre is a large year nationwide research programme funded by the Dutch Government. Hybrid Intelligence (HI) is the combination of human and machine intelligence, expanding human intellect instead of replacing it. Our goal is to design Hybrid Intelligent systems, an approach to Artificial Intelligence that puts humans at the centre, changing the course of the ongoing AI revolution. You will be part of the Hybrid Intelligence Centre that offers training and opportunities for joint research and technical support. More information about our research programme can be found at intelligence-centre.nlThe Computational Linguistics and Text Mining LabThe Computational Linguistics and Text Mining Lab (CLTL) at the Faculty of Humanities of the Vrije Universiteit Amsterdam is one of the leading groups in the area of multilingual language understanding, language modelling and resources and human-robot communication. About PhDs are doing research on various topics related to Natural Language Processing and several projects related to our robot platform Leolani: and check out our website at: for more details about our research and teaching. Application Are you interested in this position? Please apply via the application button and upload your curriculum vitae and cover letter until /06/2023. The job interviews are planned for July , when possible please take this into account when applying for the position.Submitting a diploma and a reference check are part of the application process.Applications received by e-mail will not be processed.Vacancy questionsIf you have any questions regarding this vacancy, you may contact:Name: Piek VossenPosition: Professor Computational LexicologyE-mail: piek.vossen.nlTelephone:No agencies'],\n",
       " ['he Hybrid Intelligence Centre is a large year nationwide research programme funded by the Dutch Government. Hybrid Intelligence (HI) is the combination of human and machine intelligence, expanding human intellect instead of replacing it. Our goal is to design Hybrid Intelligent systems, an approach to Artificial Intelligence that puts humans at the centre, changing the course of the ongoing AI revolution. You will be part of the Hybrid Intelligence Centre that offers training and opportunities for joint research and technical support. More information about our research programme can be found at intelligence-centre.nlThe Computational Linguistics and Text Mining LabThe Computational Linguistics and Text Mining Lab (CLTL) at the Faculty of Humanities of the Vrije Universiteit Amsterdam is one of the leading groups in the area of multilingual language understanding, language modelling and resources and human-robot communication. About PhDs are doing research on various topics related to Natural Language Processing and several projects related to our robot platform Leolani: and check out our website at: for more details about our research and teaching. Application Are you interested in this position? Please apply via the application button and upload your curriculum vitae and cover letter until /06/2023. The job interviews are planned for July , when possible please take this into account when applying for the position.Submitting a diploma and a reference check are part of the application process.Applications received by e-mail will not be processed.Vacancy questionsIf you have any questions regarding this vacancy, you may contact:Name: Piek VossenPosition: Professor Computational LexicologyE-mail: piek.vossen.nlTelephone:No agencies'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['hese presentations will be delivered by esteemed national and international scholars, renowned for their contributions to these disciplines. Additionally, the event will include artistic talks featuring preeminent artists who specialized in debinarizing AI arts. We believe that this symposium offers a unique opportunity for participants to engage with their peers, learn about the latest developments in their fields, and build lasting relationships. Whether you are a seasoned expert or a young scholar, this symposium is a place for you to connect, collaborate, and grow.On this website, you will find all the information you need to plan your participation in the symposium. You can browse the program, learn about our speakers, and register for the event. We are excited to welcome you to this symposium! To check out the website and to register, click here.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Exactly. The West was the first to develop modern technology and science, giving it an enormous position of power over the rest of the world. That technological edge was accompanied by stereotypes, reducing China to a country that could only copy Western ideas or a dictatorial regime that worked everyone to the bone. Anyone taking a broader perspective would immediately find fault with such views. China is home to an ancient civilisation that was by no means inferior to ours for thousands of years. In fact, it was considerably more developed than other parts of the world. To take this new, truer perspective, however, we will have to do away with our antiquated views first.\"'],\n",
       " [],\n",
       " ['he Hybrid Intelligence project is a collaboration of top AI researchers from the VU Amsterdam, the University of Amsterdam, the TU Delft, and the Universities of Groningen, Leiden, and Utrecht, in areas such as machine learning, knowledge representation, natural language understanding & generation, information retrieval, multi-agent systems, psychology, multimodal interaction, social robotics, AI & law and ethics of technology. The HI poroject will create a national and international focus point for research on all aspects of Hybrid Intelligent systems.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['About the department, institute, projectThe VU Department of Computer Science has approximately staff members, including approximately PhD students. Lecturers form a critical and essential basis for the functioning of the department, providing foundational education that helps determine the future of our students.Our research and our students are diverse, covering disciplines such as Social sciences, Humanities, Economics, and Bioinformatics. Currently, we offer programs in Computer Science, Artificial Intelligence and Information Sciences (BSc and MSc), and Bioinformatics and Systems Biology (MSc), with a total of around new students each year.Specifically you will be part of the Social AI research group. The vision of the Social AI group is to research and develop Smarter Digital Companions. Our mission is to advance AI to improve the way humans and machines understand and interact with each other. You will have access to the social AI lab, including its many social robots. This PhD position is part of the Hybrid Intelligence (HI) Centre. It is a collaboration of top AI researchers from the VU Amsterdam, the University of Amsterdam, the TU Delft, the University of Twente (UT) and the Universities of Groningen, Leiden, and Utrecht. Hybrid Intelligence (HI) is the combination of human and machine intelligence, expanding human intellect instead of replacing it. HI takes human expertise and intentionality into account when making meaningful decisions and perform appropriate actions, together with ethical, legal and societal values. Our goal is to design Hybrid Intelligent systems, an approach to Artificial Intelligence that puts humans at the center, changing the course of the ongoing AI revolution.Note that this job opening is one of several job openings on the HI page with job openings. You can apply to more than just this one. If you do so, please inform the Hybrid Intelligence Centres Project Manager via email of the projects you are applying to.We aim to create hybrid intelligence for everyone, see also our Diversity Statement. To do this, we need an inclusive and diverse team of researchers. We especially encourage people from underrepresented groups to apply for this job.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [\"What would you consider an interesting question about this? An interesting question that could be asked about this is: What are the most important skills that students need to develop in order to work successfully with AI? This question is interesting because the answer will vary depending on the specific course of study for which the students are preparing. Some skills, such as data analysis and programming techniques, will be important for almost all students working with AI. Other skills, such as understanding specific AI algorithms or applying AI to a particular field, will depend on the student's specific goals. The answer to this question can help students to better align their study choice and career planning with the requirements of working with AI.\"],\n",
       " ['Which fields of study will AI have the greatest impact on? AI is likely to have the greatest impact on fields of study related to data analytics, machine learning, and natural language processing. These are fields in which AI has already made a lot of progress and for which more and more applications are being developed. Moreover, AI will also impact other fields, such as medicine, finance and marketing, for example, as these fields increasingly use data analytics and machine learning. In short, AI is likely to impact a wide range of fields of study, and it is important that students are aware of the opportunities and challenges that AI presents.'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['May I also make one last point of criticism? It takes a lot of computing power to make a program like this. You never hear about what that means for the environment. ChatGPT is also based on data from a certain time frame. In five years the language will have changed, we will have changed and this system will be outdated. I think it\\'s stupid to build such an unsustainable model. It\\'s all nice, but there are I don\\'t know how many computers stamping and producing heat. And if you look at what a six-year-old child has read compared to the staggering amount of texts this system knows, that six-year-old child is still smarter than ChatGPT.\"'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['But what about having ChatGPT write your partner a love letter? The result will most likely be fantastic, and AI could possibly produce a much more eloquent and heartfelt letter than you ever would have. But would it be authentic? Can we outsource moral tasks, or do they derive their very meaning from the fact that we have to do them ourselves and that they are difficult? That seems to be the current norm. The first meal your child cooks for you is unlikely to be Michelin-worthy, but it will have meaning because they tried their hand at something new and challenging. Interpersonal relationships are not about the perfect gift or perfect letter, but about the effort that was put into writing or finding it. We would have to stretch our concept of authenticity to accommodate for AI.\"'],\n",
       " ['It\\'s a trade-off. It can be exhausting if friends or family are never available, but we need a certain degree of uncontrollability to stay interested. Models that cannot balance the two will quickly lose their lustre: not everything has to be predictable. ChatGPT never gives the same answer twice, which keeps things interesting.\"'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['I truly believe that language software like ChatGPT is the greatest technological innovation of the last years. It will significantly change many aspects of our lives and open technological doors for interpersonal relationships. More and more people will fall in love with AI. Plenty of people have already fallen in love online, so we know that you can fall in love without ever seeing or touching the other person. The more these programs start to look like people - which they already do - I wouldn\\'t be able to tell you why falling in love with AI would be any different. People will always have feelings and will talk to more and more chatbots. It is becoming easier and easier to forget that you are not actually talking to a real person. It is likely that society will initially look down on people who start a relationship with a chatbot.\"'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['And may I make one other final point of criticism? It takes a lot of computing power to create a program like this. You dont hear anyone talk about what that means for the environment. ChatGPT is also based on data from a particular time frame. Five years from now, language will have changed, well have changed and this system will be obsolete. I think its stupid to build such an unsustainable model. It\\'s great fun and all that, but who knows how many computers it has steaming away, generating heat. And even though this system knows an unimaginable number of texts compared with what a six-year-old child has read, that six-year-old child is still smarter than ChatGPT.\"'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [\"le do not tend to remember information if they believe it will be available to look up later. Further, if people have future access to information, they are much more likely to remember where the information is located than recalling the information itself (Sparrow et al., ). Another study by Dong & Potenza (2015) found that information learned through internet search is recalled less accurately and with less confidence as compared with traditional book searching.The proliferation of information through the internet has seemingly caused a decline in our ability to memorize and recall information effectively, however generative AI applications like ChatGPT might go even further and compromise other cognitive capabilities associated with System thinking, like logical and analytical thinking, as well. Whether it is writing code or solving complex math problems, for which humans require logical thinking and problem-solving skills, or composing neatly written text related to a particular topic or artistic poems, which requires us to be creative and stresses our writing skills. With generative AI, our cognitive capabilities will be further shifted from independent, creative thinking to mainly requesting knowledge. By inserting a prompt, we get everything served on a silver platter, so the only cognitive effort lies within creating the prompt.For the further course of this article, we have outlined three potential consequences that the utilization of generative AI applications, particularly chatbots, may have on human cognitive processes. We will elaborate each of these consequences, providing additional details and illustration through examples.Consequences of Generative AI on Human Cognition1) Short-cutting to final outcome without engaging in the process of developing itIt is commonly counter argued that external memory sources, such as the internet, enable individuals to perform at higher cognitive levels by allowing them to efficiently access and process information without spending cognitive resources on recall. However, there lies a big difference between incumbent external memory sources and advanced chatbots: While traditional external sources like the internet provide specific information in response to a query, the human user still must engage in the cognitively demanding process of reasoning and drawing conclusions based on that information. In contrast, advanced chatbots like ChatGPT can perform this entire process of reasoning and decision-making on behalf of the user, effectively substituting almost the full human thinking and decision-making process. For example, imagine a financial analyst who needs to decide about a potential investment. In the past, the analyst would have to spend significant time researching the company, analyzing financial statements, and considering market trends. With the use of an advanced chatbot, the analyst can simply input a prompt asking for the chatbot's recommendation on the investment and receive a detailed and well-reasoned response that includes financial analysis, market trends, and a prediction of the company's future performance. The chatbot's sophisticated features effectively take over the cognitively demanding process of researching and analyzing, thus reducing human error and providing a more efficient way of decision making, while the analyst can rely on the chatbot's output and make the final decision. Another example can be drawn from the field of software engineering: Traditionally, software developers would need to spend a significant amount of time and cognitive effort researching and understanding a problem or task at hand, as well as troubleshooting and debugging the code they write. However, with the use of chatbots, a developer could simply provide the chatbot with a prompt outlining the problem or task, and the chatbot would be able to generate the necessary code, troubleshoot and debug it, and even provide explanations for its decisions. This greatly reduces the amount of time and cognitive effort required from the developer.2) Defaulting the uncritical and cognitively appealing (mindless) consumption of synthetic content in generalPicking up the examples from above, the shift in thinking patterns may not be limited to just the work environment. The transition from critical System thinking to superficial System thinking can become the default way of approaching thought processes in other areas of life, too. For instance, white-collar workers may use ChatGPT to manage their email traffic at work in a more efficient manner by letting chatbots do the demanding task of formulating emails, while the worker only provides the content in condensed bullet points. This bears the risk that those employees may gradually lean into this mode of short-cutting to handle personal emails or personal communication in the same manner. But also, for more trivial cognitive tasks outside of work, like meal planning, organizing of daily activities or\"],\n",
       " [\"decision-making in the shopping process, humans may start to outsource cognitive effort to generative AI solutions like chatbots since the efficiency boost and cognitive relief is tempting for humans in their role as cognitive misers.If humans stop learning or stop engaging in cognitive effortful tasks, the brain may be less able to adapt and change, potentially leading to a decline in cognitive abilities and overall intellectual capacity. This is because the brain can be metaphorically seen as a muscle, in the sense that if it's not used, established neuronal connections and thus learned knowledge and cognitive abilities regress (Shors et al., ). Generative AI applications may cause individuals to gradually avoid engaging in System thinking in general, as the brain is no longer accustomed to this mode of operation.3) Superficially accepting the knowledge without/before critically examining itIf this pattern of superficial requesting of knowledge continues and bears the risk to become the default mode of working, humans may gradually also lose their cognitive abilities to engage in critical examination of the results generated by generative technologies, too. Since a critical examination and evaluation of the outputs of a chatbot can also be cognitively demanding, and users may not be experts in the field for which they are retrieving knowledge, the danger of pure acceptance of the chatbot's output is tempting. This creates a double risk: not only may humans lose certain essential cognitive capabilities regarding their deep thinking, but they may also be unable to correct problematic or incorrect results generated by these technologies, which is especially dangerous in critical fields such as healthcare.While it can be argued that advanced chatbots like ChatGPT can perform complex tasks on a level that can surpass human abilities, this doesn't mean that they are resistant to errors or biases. Chatbots, and generative AI in general, is only as good as the data it is trained on. If the underlying data contains biases or inaccuracies, the AIs outputs will also be biased or inaccurate. Moreover, there are certain situations where a human touch is still required, for example in ethical or moral decision-making. A chatbot may be able to provide recommendations based on the data it has been trained on, but it lacks the ability to understand the nuances of a situation and make a decision that considers the broader context and implications. Therefore, even if chatbots become more advanced in the future and will eventually surpass human-level capabilities in problem-solving tasks, there will still be cases where human intervention and critical or analytical thinking are necessary to resolve issues and overcome challenges. For this reason, it is important to maintain our ability to critically examine information and engage in independent thinking, so that we can step in when required and make informed decisions based on our unique understanding of the situation.What to be mindful about and whats next?As advanced chatbots may continue to substitute more and more the independent human thought process, there is a risk that individuals will increasingly rely on superficial, heuristic thinking (System thinking), rather than the more analytical and conscious thinking (System thinking). This shift towards superficial thinking can have far-reaching consequences as it may reduce the ability of individuals to critically evaluate and understand complex information. Moreover, it may also lead to a decline in the human capability to think creatively and to come up with innovative solutions to problems on their own. Furthermore, heuristic thinking is a way of approximating information, which can lead to errors and biases that can be problematic in certain situations and decision making without automation assistance. In that sense, when people rely on heuristics too much, they might miss important information and make poor decisions, which can be particularly dangerous in fields that involve high stakes, like healthcare or law enforcement. Therefore, it is important to be aware of the potential risks associated with relying on heuristic evaluation on the output of generative AI and to actively cultivate and maintain our ability for analytical System thinking.ChatGPT has reached million users just two months after launching (Hu, ), so the widespread future use of advanced chatbots is almost certain since economic, external incentives, as well as internal, psychological incentives favor automation over human cognitive thinking: In the business world, competition favors every little possibility to gain market advantage over competitors, whereby the most efficient methods are always chosen to conduct work, thus automation becomes more pervasive and continues to replace inefficient human thinking in the work environment. From a psychological perspective, humans themselves can be seen as cognitive misers, wher\"],\n",
       " [\"as a result, we welcome any form of automation that relieves us of cognitive effort in our private life.ChatGPT, with its superb capabilities to solve information processing tasks, is set to become more advanced with each iteration. Microsoft already launched a new version of its Bing search engine that incorporates ChatGPT to make it easier for users to create content and find answers on the web (Mehdi. ). Google has followed suit and introduced its own chatbot, Bard, which will also be integrated into the company's search engine (Pichai, ). Due to market pressure, every player in the market will aim to beat the competitors' chatbot in terms of their capabilities and try to incorporate the technology in their services as much as possible. Therefore, the previously addressed weaknesses are likely to be overcome sooner than later. Chatbots will likely become increasingly prevalent in the business world and may take part in our daily lives, making our interactions with technology more seamless and efficient. As the technology continues to improve, it is likely that advanced chatbots will play a significant role in shaping the future of how we access and process information.However, the question remains how independent human thinking will be shaped: Will we continue to be able to draw logical conclusions ourselves through deep, but tedious thinking? Or will we lose cognitive capabilities and become like shallow waters, lacking the depth and flow of ideas and imagination by only perceiving and interpreting information superficially?Rather than making predictions about the future of the interplay between humans and chatbots, this article should serve more as a theoretical foundation on how humans are exposed to automated information processing from a cognitive-psychological perspective. The article should stress and call for further research in the area of cognitive biases that may arise from the use and adoption of advanced chatbots in order to better understand potential consequences. Lets think deeply together!About the authorsMarcel Peter is an alumnus of the Digital Business & Innovation Programme at VU Amsterdam, where he obtained his Master's degree in . As a part of his Master's thesis, he researched the effect of explainable AI in the domain of radiology, specifically how explainable AI methods influence radiologists in their decision-making process while reading mammograms. Marcel was supervised by Prof. Dr. Mohammad Rezazade Mehrizi and worked closely together with him over the course of the thesis trajectory. After graduating, Marcel continued to stay in contact with Mohammad, and together they have further extended their research in the field of AI in radiology. After testing ChatGPT, Marcel found that much of the literature from his Master's thesis on Cognitive Psychology and Hybrid Intelligence was highly applicable to the way humans interact with chatbots, what led him to write this article.Mohammad H. Rezazade Mehrizi is an Associate Professor of work and organizational learning, at KIN center for digital innovation, Vrije Universiteit Amsterdam. His is passionate about understanding and helping practitioners and organizations to learn and unlearn beyond their current limitations. His current research he examines the dynamics of expertise and learning among knowledge works and professionals in relation to emerging algorithmic technologies.ReferencesDong, G., & Potenza, M. N. (2015). Behavioural and brain responses related to Internet search and memory. European Journal of Neuroscience, (8), . S. T., & Taylor, S. E. (1991). Social Cognition. McGraw-Hill Education.Gigerenzer, G., & Gaissmaier, W. (2011). Heuristic Decision Making. Annual Review of Psychology, (1), . T., & Savitsky, K. (1996). Like goes with like: The role of representativeness in erroneous and pseudoscientific beliefs. Skeptical Inquirer: The Magazine for Science and Reason, , -40.Hu, K. (2023, February ). ChatGPT sets record for fastest-growing user base - analyst D. (2003). A perspective on judgment and choice: Mapping bounded rationality. American Psychologist, (9), . D. (2011). Thinking, Fast and Slow (1st ed.). Farrar, Straus and GirouxMehdi, Y. (2023, February ). Reinventing search with a new AI-powered Microsoft Bing and Edge, your copilot for the web - The Official Microsoft Blog. The Official Microsoft S. (2023, February ). An important next step on our AI journey. Google. T. J., Anderson, M. L., Curlik, D. M., & Nokia, M. S. (2012). Use it or lose it: How neurogenesis keeps the brain fit for learning. Behavioural Brain Research, (2), . K. (2009). SIX.\"],\n",
       " ['Since all the technical capabilities that ChatGPT offers are already being vividly discussed as well as their potential disruptive consequences for incumbent technologies, like Google search for example, one question still seems mostly unaddressed: How do generative AI applications affect essential human thinking capabilities such as critical, reflective, deep thinking? While the internet as a sheer infinitely large external- and always available information medium already made it difficult for us to memorize information, do advanced chatbots go even further and affect other human cognitive abilities such as logical reasoning and analytical thinking? By writing this article, we aim to reflect on what we can learn from the previous technology adaptation to the internet and hypothesize the (unintended) consequences of the use of generative AI applications on human cognitive capabilities. We primarily draw on the theoretical lens of cognitive psychology to assess the impact of technology on human thinking.To do so, we first examine some core human cognition theories and then apply them to the use of advanced chatbots. This way, we identify three (unintended) cognitive consequences for the rise of generative AI.A glimpse into the cognitive psychology perspectiveIn the field of cognitive psychology, the human mind is often referred to as a \"cognitive miser\" because people, regardless of their intelligence, tend to choose simpler and easier thinking methods instead of more complex and cognitively demanding ones (Stanovich, ). The underlying assumption of the concept is that humans are limited in their capacity to process information, so they take shortcuts whenever they can (Fiske & Taylor, ; Kahneman, ). The cognitive miser theory, first introduced by Fiske & Taylor (1991), suggests that people engage in economically cost-effective thought processes instead of rationally weighting costs against benefits and updating expectations based upon the results of their everyday actions (Fiske & Taylor, ).Much of the cognitive miser theory is built upon research done on heuristics in human judgment and decision-making. For instance, dual-process theories explain how human thought processes are mainly distinguished: System , being intuitive, automatic and unconscious processing of information, whereas System , being analytical, controlled and conscious thinking (Stanovich & West, ; Kahneman, ; Kahneman, ). System is therefore often also referred to as fast thinking, following mental shortcuts and heuristics, whereas System is referred to as slow thinking, relying on conscious and careful reasoning of information and arguments (Kahneman, ; Kahneman, ). Because System is slower and more cognitively demanding than System , humans often switch to System thinking, thus using heuristic thinking for a faster, more efficient computation of information, but with the risk to arrive at a suboptimal decision.Heuristics can be defined as the \"judgmental shortcuts that generally get us where we need to goand quicklybut at the cost of occasionally sending us off course\" (Gilovich & Savitsky, , p.36). To reduce their cognitive load, humans tend to ignore part of the information associated with certain tasks and rather rely on mental shortcuts to solve the underlying task, because information search and processing costs time and cognitive resources (Gigerenzer & Gaissmaier, ).In today\\'s world, the search for suitable information is easier than ever thanks to the internet as an external memorization medium. Since the information required no longer must be retrieved by people themselves from their memory, but is almost always at hand via intelligent devices, the associated cognitive efforts for gathering and storing information are reduced. However, this comfortable method of information retrieval has also compromised the ability of humans to recall information, also known as the Google Effect. A study by Sparrow et al. (2011) investigated the cognitive consequences of having information at our fingertips due to the advent of the internet and found that people do not tend to remember information if they believe it will be available to look up later. Further, if people have future access to information, they are much more likely to remember where the information is located than recalling the information itself (Sparrow et al., ). Another study by Dong & Potenza (2015) found that information learned through internet search is recalled less accurately and with less confidence as compared with traditional book searching.The proliferation of information through the internet has seemingly caused a decline in our ability to memorize and recall information effectively, however generative AI applications like ChatGPT might go even further and compromise other cognitive capabilities associated with System thinking, like logical and analytical thinking, as well. Whether it is writing c'],\n",
       " [\"de or solving complex math problems, for which humans require logical thinking and problem-solving skills, or composing neatly written text related to a particular topic or artistic poems, which requires us to be creative and stresses our writing skills. With generative AI, our cognitive capabilities will be further shifted from independent, creative thinking to mainly requesting knowledge. By inserting a prompt, we get everything served on a silver platter, so the only cognitive effort lies within creating the prompt.For the further course of this article, we have outlined three potential consequences that the utilization of generative AI applications, particularly chatbots, may have on human cognitive processes. We will elaborate each of these consequences, providing additional details and illustration through examples.Consequences of Generative AI on Human Cognition1) Short-cutting to final outcome without engaging in the process of developing itIt is commonly counter argued that external memory sources, such as the internet, enable individuals to perform at higher cognitive levels by allowing them to efficiently access and process information without spending cognitive resources on recall. However, there lies a big difference between incumbent external memory sources and advanced chatbots: While traditional external sources like the internet provide specific information in response to a query, the human user still must engage in the cognitively demanding process of reasoning and drawing conclusions based on that information. In contrast, advanced chatbots like ChatGPT can perform this entire process of reasoning and decision-making on behalf of the user, effectively substituting almost the full human thinking and decision-making process. For example, imagine a financial analyst who needs to decide about a potential investment. In the past, the analyst would have to spend significant time researching the company, analyzing financial statements, and considering market trends. With the use of an advanced chatbot, the analyst can simply input a prompt asking for the chatbot's recommendation on the investment and receive a detailed and well-reasoned response that includes financial analysis, market trends, and a prediction of the company's future performance. The chatbot's sophisticated features effectively take over the cognitively demanding process of researching and analyzing, thus reducing human error and providing a more efficient way of decision making, while the analyst can rely on the chatbot's output and make the final decision. Another example can be drawn from the field of software engineering: Traditionally, software developers would need to spend a significant amount of time and cognitive effort researching and understanding a problem or task at hand, as well as troubleshooting and debugging the code they write. However, with the use of chatbots, a developer could simply provide the chatbot with a prompt outlining the problem or task, and the chatbot would be able to generate the necessary code, troubleshoot and debug it, and even provide explanations for its decisions. This greatly reduces the amount of time and cognitive effort required from the developer.2) Defaulting the uncritical and cognitively appealing (mindless) consumption of synthetic content in generalPicking up the examples from above, the shift in thinking patterns may not be limited to just the work environment. The transition from critical System thinking to superficial System thinking can become the default way of approaching thought processes in other areas of life, too. For instance, white-collar workers may use ChatGPT to manage their email traffic at work in a more efficient manner by letting chatbots do the demanding task of formulating emails, while the worker only provides the content in condensed bullet points. This bears the risk that those employees may gradually lean into this mode of short-cutting to handle personal emails or personal communication in the same manner. But also, for more trivial cognitive tasks outside of work, like meal planning, organizing of daily activities or decision-making in the shopping process, humans may start to outsource cognitive effort to generative AI solutions like chatbots since the efficiency boost and cognitive relief is tempting for humans in their role as cognitive misers.If humans stop learning or stop engaging in cognitive effortful tasks, the brain may be less able to adapt and change, potentially leading to a decline in cognitive abilities and overall intellectual capacity. This is because the brain can be metaphorically seen as a muscle, in the sense that if it's not used, established neuronal connections and thus learned knowledge and cognitive abilities regress (Shors et al., ). Generative AI applications may cause individuals to gradually avoid engaging in System thinking in general, as the brain is no longer accustomed to this mode of operation.3)\"],\n",
       " [\"Superficially accepting the knowledge without/before critically examining itIf this pattern of superficial requesting of knowledge continues and bears the risk to become the default mode of working, humans may gradually also lose their cognitive abilities to engage in critical examination of the results generated by generative technologies, too. Since a critical examination and evaluation of the outputs of a chatbot can also be cognitively demanding, and users may not be experts in the field for which they are retrieving knowledge, the danger of pure acceptance of the chatbot's output is tempting. This creates a double risk: not only may humans lose certain essential cognitive capabilities regarding their deep thinking, but they may also be unable to correct problematic or incorrect results generated by these technologies, which is especially dangerous in critical fields such as healthcare.While it can be argued that advanced chatbots like ChatGPT can perform complex tasks on a level that can surpass human abilities, this doesn't mean that they are resistant to errors or biases. Chatbots, and generative AI in general, is only as good as the data it is trained on. If the underlying data contains biases or inaccuracies, the AIs outputs will also be biased or inaccurate. Moreover, there are certain situations where a human touch is still required, for example in ethical or moral decision-making. A chatbot may be able to provide recommendations based on the data it has been trained on, but it lacks the ability to understand the nuances of a situation and make a decision that considers the broader context and implications. Therefore, even if chatbots become more advanced in the future and will eventually surpass human-level capabilities in problem-solving tasks, there will still be cases where human intervention and critical or analytical thinking are necessary to resolve issues and overcome challenges. For this reason, it is important to maintain our ability to critically examine information and engage in independent thinking, so that we can step in when required and make informed decisions based on our unique understanding of the situation.What to be mindful about and whats next?As advanced chatbots may continue to substitute more and more the independent human thought process, there is a risk that individuals will increasingly rely on superficial, heuristic thinking (System thinking), rather than the more analytical and conscious thinking (System thinking). This shift towards superficial thinking can have far-reaching consequences as it may reduce the ability of individuals to critically evaluate and understand complex information. Moreover, it may also lead to a decline in the human capability to think creatively and to come up with innovative solutions to problems on their own. Furthermore, heuristic thinking is a way of approximating information, which can lead to errors and biases that can be problematic in certain situations and decision making without automation assistance. In that sense, when people rely on heuristics too much, they might miss important information and make poor decisions, which can be particularly dangerous in fields that involve high stakes, like healthcare or law enforcement. Therefore, it is important to be aware of the potential risks associated with relying on heuristic evaluation on the output of generative AI and to actively cultivate and maintain our ability for analytical System thinking.ChatGPT has reached million users just two months after launching (Hu, ), so the widespread future use of advanced chatbots is almost certain since economic, external incentives, as well as internal, psychological incentives favor automation over human cognitive thinking: In the business world, competition favors every little possibility to gain market advantage over competitors, whereby the most efficient methods are always chosen to conduct work, thus automation becomes more pervasive and continues to replace inefficient human thinking in the work environment. From a psychological perspective, humans themselves can be seen as cognitive misers, where as a result, we welcome any form of automation that relieves us of cognitive effort in our private life.ChatGPT, with its superb capabilities to solve information processing tasks, is set to become more advanced with each iteration. Microsoft already launched a new version of its Bing search engine that incorporates ChatGPT to make it easier for users to create content and find answers on the web (Mehdi. ). Google has followed suit and introduced its own chatbot, Bard, which will also be integrated into the company's search engine (Pichai, ). Due to market pressure, every player in the market will aim to beat the competitors' chatbot in terms of their capabilities and try to incorporate the technology in their services as much as possible. Therefore, the previously addressed weaknesses are likely to be overcome sooner\"],\n",
       " ['o do so, we first examine some core human cognition theories and then apply them to the use of advanced chatbots. This way, we identify three (unintended) cognitive consequences for the rise of generative AI.A glimpse into the cognitive psychology perspectiveIn the field of cognitive psychology, the human mind is often referred to as a \"cognitive miser\" because people, regardless of their intelligence, tend to choose simpler and easier thinking methods instead of more complex and cognitively demanding ones (Stanovich, ). The underlying assumption of the concept is that humans are limited in their capacity to process information, so they take shortcuts whenever they can (Fiske & Taylor, ; Kahneman, ). The cognitive miser theory, first introduced by Fiske & Taylor (1991), suggests that people engage in economically cost-effective thought processes instead of rationally weighting costs against benefits and updating expectations based upon the results of their everyday actions (Fiske & Taylor, ).Much of the cognitive miser theory is built upon research done on heuristics in human judgment and decision-making. For instance, dual-process theories explain how human thought processes are mainly distinguished: System , being intuitive, automatic and unconscious processing of information, whereas System , being analytical, controlled and conscious thinking (Stanovich & West, ; Kahneman, ; Kahneman, ). System is therefore often also referred to as fast thinking, following mental shortcuts and heuristics, whereas System is referred to as slow thinking, relying on conscious and careful reasoning of information and arguments (Kahneman, ; Kahneman, ). Because System is slower and more cognitively demanding than System , humans often switch to System thinking, thus using heuristic thinking for a faster, more efficient computation of information, but with the risk to arrive at a suboptimal decision.Heuristics can be defined as the \"judgmental shortcuts that generally get us where we need to goand quicklybut at the cost of occasionally sending us off course\" (Gilovich & Savitsky, , p.36). To reduce their cognitive load, humans tend to ignore part of the information associated with certain tasks and rather rely on mental shortcuts to solve the underlying task, because information search and processing costs time and cognitive resources (Gigerenzer & Gaissmaier, ).In today\\'s world, the search for suitable information is easier than ever thanks to the internet as an external memorization medium. Since the information required no longer must be retrieved by people themselves from their memory, but is almost always at hand via intelligent devices, the associated cognitive efforts for gathering and storing information are reduced. However, this comfortable method of information retrieval has also compromised the ability of humans to recall information, also known as the Google Effect. A study by Sparrow et al. (2011) investigated the cognitive consequences of having information at our fingertips due to the advent of the internet and found that people do not tend to remember information if they believe it will be available to look up later. Further, if people have future access to information, they are much more likely to remember where the information is located than recalling the information itself (Sparrow et al., ). Another study by Dong & Potenza (2015) found that information learned through internet search is recalled less accurately and with less confidence as compared with traditional book searching.The proliferation of information through the internet has seemingly caused a decline in our ability to memorize and recall information effectively, however generative AI applications like ChatGPT might go even further and compromise other cognitive capabilities associated with System thinking, like logical and analytical thinking, as well. Whether it is writing code or solving complex math problems, for which humans require logical thinking and problem-solving skills, or composing neatly written text related to a particular topic or artistic poems, which requires us to be creative and stresses our writing skills. With generative AI, our cognitive capabilities will be further shifted from independent, creative thinking to mainly requesting knowledge. By inserting a prompt, we get everything served on a silver platter, so the only cognitive effort lies within creating the prompt.For the further course of this article, we have outlined three potential consequences that the utilization of generative AI applications, particularly chatbots, may have on human cognitive processes. We will elaborate each of these consequences, providing additional details and illustration through examples.Consequences of Generative AI on Human Cognition1) Short-cutting to final outcome without engaging in the process of developing itIt is commonly counter argued that external memo'],\n",
       " [],\n",
       " [\"man abilities, this doesn't mean that they are resistant to errors or biases. Chatbots, and generative AI in general, is only as good as the data it is trained on. If the underlying data contains biases or inaccuracies, the AIs outputs will also be biased or inaccurate. Moreover, there are certain situations where a human touch is still required, for example in ethical or moral decision-making. A chatbot may be able to provide recommendations based on the data it has been trained on, but it lacks the ability to understand the nuances of a situation and make a decision that considers the broader context and implications. Therefore, even if chatbots become more advanced in the future and will eventually surpass human-level capabilities in problem-solving tasks, there will still be cases where human intervention and critical or analytical thinking are necessary to resolve issues and overcome challenges. For this reason, it is important to maintain our ability to critically examine information and engage in independent thinking, so that we can step in when required and make informed decisions based on our unique understanding of the situation.What to be mindful about and whats next?As advanced chatbots may continue to substitute more and more the independent human thought process, there is a risk that individuals will increasingly rely on superficial, heuristic thinking (System thinking), rather than the more analytical and conscious thinking (System thinking). This shift towards superficial thinking can have far-reaching consequences as it may reduce the ability of individuals to critically evaluate and understand complex information. Moreover, it may also lead to a decline in the human capability to think creatively and to come up with innovative solutions to problems on their own. Furthermore, heuristic thinking is a way of approximating information, which can lead to errors and biases that can be problematic in certain situations and decision making without automation assistance. In that sense, when people rely on heuristics too much, they might miss important information and make poor decisions, which can be particularly dangerous in fields that involve high stakes, like healthcare or law enforcement. Therefore, it is important to be aware of the potential risks associated with relying on heuristic evaluation on the output of generative AI and to actively cultivate and maintain our ability for analytical System thinking.ChatGPT has reached million users just two months after launching (Hu, ), so the widespread future use of advanced chatbots is almost certain since economic, external incentives, as well as internal, psychological incentives favor automation over human cognitive thinking: In the business world, competition favors every little possibility to gain market advantage over competitors, whereby the most efficient methods are always chosen to conduct work, thus automation becomes more pervasive and continues to replace inefficient human thinking in the work environment. From a psychological perspective, humans themselves can be seen as cognitive misers, where as a result, we welcome any form of automation that relieves us of cognitive effort in our private life.ChatGPT, with its superb capabilities to solve information processing tasks, is set to become more advanced with each iteration. Microsoft already launched a new version of its Bing search engine that incorporates ChatGPT to make it easier for users to create content and find answers on the web (Mehdi. ). Google has followed suit and introduced its own chatbot, Bard, which will also be integrated into the company's search engine (Pichai, ). Due to market pressure, every player in the market will aim to beat the competitors' chatbot in terms of their capabilities and try to incorporate the technology in their services as much as possible. Therefore, the previously addressed weaknesses are likely to be overcome sooner than later. Chatbots will likely become increasingly prevalent in the business world and may take part in our daily lives, making our interactions with technology more seamless and efficient. As the technology continues to improve, it is likely that advanced chatbots will play a significant role in shaping the future of how we access and process information.However, the question remains how independent human thinking will be shaped: Will we continue to be able to draw logical conclusions ourselves through deep, but tedious thinking? Or will we lose cognitive capabilities and become like shallow waters, lacking the depth and flow of ideas and imagination by only perceiving and interpreting information superficially?Rather than making predictions about the future of the interplay between humans and chatbots, this article should serve more as a theoretical foundation on how humans are exposed to automated information processing from a cognitive-psychological perspective. The article should stress and cal\"],\n",
       " ['In the field of cognitive psychology, the human mind is often referred to as a \"cognitive miser\" because people, regardless of their intelligence, tend to choose simpler and easier thinking methods instead of more complex and cognitively demanding ones (Stanovich, ). The underlying assumption of the concept is that humans are limited in their capacity to process information, so they take shortcuts whenever they can (Fiske & Taylor, ; Kahneman, ). The cognitive miser theory, first introduced by Fiske & Taylor (1991), suggests that people engage in economically cost-effective thought processes instead of rationally weighting costs against benefits and updating expectations based upon the results of their everyday actions (Fiske & Taylor, ).Much of the cognitive miser theory is built upon research done on heuristics in human judgment and decision-making. For instance, dual-process theories explain how human thought processes are mainly distinguished: System , being intuitive, automatic and unconscious processing of information, whereas System , being analytical, controlled and conscious thinking (Stanovich & West, ; Kahneman, ; Kahneman, ). System is therefore often also referred to as fast thinking, following mental shortcuts and heuristics, whereas System is referred to as slow thinking, relying on conscious and careful reasoning of information and arguments (Kahneman, ; Kahneman, ). Because System is slower and more cognitively demanding than System , humans often switch to System thinking, thus using heuristic thinking for a faster, more efficient computation of information, but with the risk to arrive at a suboptimal decision.Heuristics can be defined as the \"judgmental shortcuts that generally get us where we need to goand quicklybut at the cost of occasionally sending us off course\" (Gilovich & Savitsky, , p.36). To reduce their cognitive load, humans tend to ignore part of the information associated with certain tasks and rather rely on mental shortcuts to solve the underlying task, because information search and processing costs time and cognitive resources (Gigerenzer & Gaissmaier, ).In today\\'s world, the search for suitable information is easier than ever thanks to the internet as an external memorization medium. Since the information required no longer must be retrieved by people themselves from their memory, but is almost always at hand via intelligent devices, the associated cognitive efforts for gathering and storing information are reduced. However, this comfortable method of information retrieval has also compromised the ability of humans to recall information, also known as the Google Effect. A study by Sparrow et al. (2011) investigated the cognitive consequences of having information at our fingertips due to the advent of the internet and found that people do not tend to remember information if they believe it will be available to look up later. Further, if people have future access to information, they are much more likely to remember where the information is located than recalling the information itself (Sparrow et al., ). Another study by Dong & Potenza (2015) found that information learned through internet search is recalled less accurately and with less confidence as compared with traditional book searching.The proliferation of information through the internet has seemingly caused a decline in our ability to memorize and recall information effectively, however generative AI applications like ChatGPT might go even further and compromise other cognitive capabilities associated with System thinking, like logical and analytical thinking, as well. Whether it is writing code or solving complex math problems, for which humans require logical thinking and problem-solving skills, or composing neatly written text related to a particular topic or artistic poems, which requires us to be creative and stresses our writing skills. With generative AI, our cognitive capabilities will be further shifted from independent, creative thinking to mainly requesting knowledge. By inserting a prompt, we get everything served on a silver platter, so the only cognitive effort lies within creating the prompt.For the further course of this article, we have outlined three potential consequences that the utilization of generative AI applications, particularly chatbots, may have on human cognitive processes. We will elaborate each of these consequences, providing additional details and illustration through examples.Consequences of Generative AI on Human Cognition1) Short-cutting to final outcome without engaging in the process of developing itIt is commonly counter argued that external memory sources, such as the internet, enable individuals to perform at higher cognitive levels by allowing them to efficiently access and process information without spending cognitive resources on recall. However, there lies a big difference between incumbent ext'],\n",
       " [\"rnal memory sources and advanced chatbots: While traditional external sources like the internet provide specific information in response to a query, the human user still must engage in the cognitively demanding process of reasoning and drawing conclusions based on that information. In contrast, advanced chatbots like ChatGPT can perform this entire process of reasoning and decision-making on behalf of the user, effectively substituting almost the full human thinking and decision-making process. For example, imagine a financial analyst who needs to decide about a potential investment. In the past, the analyst would have to spend significant time researching the company, analyzing financial statements, and considering market trends. With the use of an advanced chatbot, the analyst can simply input a prompt asking for the chatbot's recommendation on the investment and receive a detailed and well-reasoned response that includes financial analysis, market trends, and a prediction of the company's future performance. The chatbot's sophisticated features effectively take over the cognitively demanding process of researching and analyzing, thus reducing human error and providing a more efficient way of decision making, while the analyst can rely on the chatbot's output and make the final decision. Another example can be drawn from the field of software engineering: Traditionally, software developers would need to spend a significant amount of time and cognitive effort researching and understanding a problem or task at hand, as well as troubleshooting and debugging the code they write. However, with the use of chatbots, a developer could simply provide the chatbot with a prompt outlining the problem or task, and the chatbot would be able to generate the necessary code, troubleshoot and debug it, and even provide explanations for its decisions. This greatly reduces the amount of time and cognitive effort required from the developer.2) Defaulting the uncritical and cognitively appealing (mindless) consumption of synthetic content in generalPicking up the examples from above, the shift in thinking patterns may not be limited to just the work environment. The transition from critical System thinking to superficial System thinking can become the default way of approaching thought processes in other areas of life, too. For instance, white-collar workers may use ChatGPT to manage their email traffic at work in a more efficient manner by letting chatbots do the demanding task of formulating emails, while the worker only provides the content in condensed bullet points. This bears the risk that those employees may gradually lean into this mode of short-cutting to handle personal emails or personal communication in the same manner. But also, for more trivial cognitive tasks outside of work, like meal planning, organizing of daily activities or decision-making in the shopping process, humans may start to outsource cognitive effort to generative AI solutions like chatbots since the efficiency boost and cognitive relief is tempting for humans in their role as cognitive misers.If humans stop learning or stop engaging in cognitive effortful tasks, the brain may be less able to adapt and change, potentially leading to a decline in cognitive abilities and overall intellectual capacity. This is because the brain can be metaphorically seen as a muscle, in the sense that if it's not used, established neuronal connections and thus learned knowledge and cognitive abilities regress (Shors et al., ). Generative AI applications may cause individuals to gradually avoid engaging in System thinking in general, as the brain is no longer accustomed to this mode of operation.3) Superficially accepting the knowledge without/before critically examining itIf this pattern of superficial requesting of knowledge continues and bears the risk to become the default mode of working, humans may gradually also lose their cognitive abilities to engage in critical examination of the results generated by generative technologies, too. Since a critical examination and evaluation of the outputs of a chatbot can also be cognitively demanding, and users may not be experts in the field for which they are retrieving knowledge, the danger of pure acceptance of the chatbot's output is tempting. This creates a double risk: not only may humans lose certain essential cognitive capabilities regarding their deep thinking, but they may also be unable to correct problematic or incorrect results generated by these technologies, which is especially dangerous in critical fields such as healthcare.While it can be argued that advanced chatbots like ChatGPT can perform complex tasks on a level that can surpass human abilities, this doesn't mean that they are resistant to errors or biases. Chatbots, and generative AI in general, is only as good as the data it is trained on. If the underlying data contains biases or inaccuracies, the AIs outputs will also be biased or\"],\n",
       " [\"inaccurate. Moreover, there are certain situations where a human touch is still required, for example in ethical or moral decision-making. A chatbot may be able to provide recommendations based on the data it has been trained on, but it lacks the ability to understand the nuances of a situation and make a decision that considers the broader context and implications. Therefore, even if chatbots become more advanced in the future and will eventually surpass human-level capabilities in problem-solving tasks, there will still be cases where human intervention and critical or analytical thinking are necessary to resolve issues and overcome challenges. For this reason, it is important to maintain our ability to critically examine information and engage in independent thinking, so that we can step in when required and make informed decisions based on our unique understanding of the situation.What to be mindful about and whats next?As advanced chatbots may continue to substitute more and more the independent human thought process, there is a risk that individuals will increasingly rely on superficial, heuristic thinking (System thinking), rather than the more analytical and conscious thinking (System thinking). This shift towards superficial thinking can have far-reaching consequences as it may reduce the ability of individuals to critically evaluate and understand complex information. Moreover, it may also lead to a decline in the human capability to think creatively and to come up with innovative solutions to problems on their own. Furthermore, heuristic thinking is a way of approximating information, which can lead to errors and biases that can be problematic in certain situations and decision making without automation assistance. In that sense, when people rely on heuristics too much, they might miss important information and make poor decisions, which can be particularly dangerous in fields that involve high stakes, like healthcare or law enforcement. Therefore, it is important to be aware of the potential risks associated with relying on heuristic evaluation on the output of generative AI and to actively cultivate and maintain our ability for analytical System thinking.ChatGPT has reached million users just two months after launching (Hu, ), so the widespread future use of advanced chatbots is almost certain since economic, external incentives, as well as internal, psychological incentives favor automation over human cognitive thinking: In the business world, competition favors every little possibility to gain market advantage over competitors, whereby the most efficient methods are always chosen to conduct work, thus automation becomes more pervasive and continues to replace inefficient human thinking in the work environment. From a psychological perspective, humans themselves can be seen as cognitive misers, where as a result, we welcome any form of automation that relieves us of cognitive effort in our private life.ChatGPT, with its superb capabilities to solve information processing tasks, is set to become more advanced with each iteration. Microsoft already launched a new version of its Bing search engine that incorporates ChatGPT to make it easier for users to create content and find answers on the web (Mehdi. ). Google has followed suit and introduced its own chatbot, Bard, which will also be integrated into the company's search engine (Pichai, ). Due to market pressure, every player in the market will aim to beat the competitors' chatbot in terms of their capabilities and try to incorporate the technology in their services as much as possible. Therefore, the previously addressed weaknesses are likely to be overcome sooner than later. Chatbots will likely become increasingly prevalent in the business world and may take part in our daily lives, making our interactions with technology more seamless and efficient. As the technology continues to improve, it is likely that advanced chatbots will play a significant role in shaping the future of how we access and process information.However, the question remains how independent human thinking will be shaped: Will we continue to be able to draw logical conclusions ourselves through deep, but tedious thinking? Or will we lose cognitive capabilities and become like shallow waters, lacking the depth and flow of ideas and imagination by only perceiving and interpreting information superficially?Rather than making predictions about the future of the interplay between humans and chatbots, this article should serve more as a theoretical foundation on how humans are exposed to automated information processing from a cognitive-psychological perspective. The article should stress and call for further research in the area of cognitive biases that may arise from the use and adoption of advanced chatbots in order to better understand potential consequences. Lets think deeply together!About the authorsMarcel Peter is an alumnus of the Digital Bu\"],\n",
       " ['Much of the cognitive miser theory is built upon research done on heuristics in human judgment and decision-making. For instance, dual-process theories explain how human thought processes are mainly distinguished: System , being intuitive, automatic and unconscious processing of information, whereas System , being analytical, controlled and conscious thinking (Stanovich & West, ; Kahneman, ; Kahneman, ). System is therefore often also referred to as fast thinking, following mental shortcuts and heuristics, whereas System is referred to as slow thinking, relying on conscious and careful reasoning of information and arguments (Kahneman, ; Kahneman, ). Because System is slower and more cognitively demanding than System , humans often switch to System thinking, thus using heuristic thinking for a faster, more efficient computation of information, but with the risk to arrive at a suboptimal decision.Heuristics can be defined as the \"judgmental shortcuts that generally get us where we need to goand quicklybut at the cost of occasionally sending us off course\" (Gilovich & Savitsky, , p.36). To reduce their cognitive load, humans tend to ignore part of the information associated with certain tasks and rather rely on mental shortcuts to solve the underlying task, because information search and processing costs time and cognitive resources (Gigerenzer & Gaissmaier, ).In today\\'s world, the search for suitable information is easier than ever thanks to the internet as an external memorization medium. Since the information required no longer must be retrieved by people themselves from their memory, but is almost always at hand via intelligent devices, the associated cognitive efforts for gathering and storing information are reduced. However, this comfortable method of information retrieval has also compromised the ability of humans to recall information, also known as the Google Effect. A study by Sparrow et al. (2011) investigated the cognitive consequences of having information at our fingertips due to the advent of the internet and found that people do not tend to remember information if they believe it will be available to look up later. Further, if people have future access to information, they are much more likely to remember where the information is located than recalling the information itself (Sparrow et al., ). Another study by Dong & Potenza (2015) found that information learned through internet search is recalled less accurately and with less confidence as compared with traditional book searching.The proliferation of information through the internet has seemingly caused a decline in our ability to memorize and recall information effectively, however generative AI applications like ChatGPT might go even further and compromise other cognitive capabilities associated with System thinking, like logical and analytical thinking, as well. Whether it is writing code or solving complex math problems, for which humans require logical thinking and problem-solving skills, or composing neatly written text related to a particular topic or artistic poems, which requires us to be creative and stresses our writing skills. With generative AI, our cognitive capabilities will be further shifted from independent, creative thinking to mainly requesting knowledge. By inserting a prompt, we get everything served on a silver platter, so the only cognitive effort lies within creating the prompt.For the further course of this article, we have outlined three potential consequences that the utilization of generative AI applications, particularly chatbots, may have on human cognitive processes. We will elaborate each of these consequences, providing additional details and illustration through examples.Consequences of Generative AI on Human Cognition1) Short-cutting to final outcome without engaging in the process of developing itIt is commonly counter argued that external memory sources, such as the internet, enable individuals to perform at higher cognitive levels by allowing them to efficiently access and process information without spending cognitive resources on recall. However, there lies a big difference between incumbent external memory sources and advanced chatbots: While traditional external sources like the internet provide specific information in response to a query, the human user still must engage in the cognitively demanding process of reasoning and drawing conclusions based on that information. In contrast, advanced chatbots like ChatGPT can perform this entire process of reasoning and decision-making on behalf of the user, effectively substituting almost the full human thinking and decision-making process. For example, imagine a financial analyst who needs to decide about a potential investment. In the past, the analyst would have to spend significant time researching the company, analyzing financial statements, and considering market trends. With the use of an adv'],\n",
       " [\"nced chatbot, the analyst can simply input a prompt asking for the chatbot's recommendation on the investment and receive a detailed and well-reasoned response that includes financial analysis, market trends, and a prediction of the company's future performance. The chatbot's sophisticated features effectively take over the cognitively demanding process of researching and analyzing, thus reducing human error and providing a more efficient way of decision making, while the analyst can rely on the chatbot's output and make the final decision. Another example can be drawn from the field of software engineering: Traditionally, software developers would need to spend a significant amount of time and cognitive effort researching and understanding a problem or task at hand, as well as troubleshooting and debugging the code they write. However, with the use of chatbots, a developer could simply provide the chatbot with a prompt outlining the problem or task, and the chatbot would be able to generate the necessary code, troubleshoot and debug it, and even provide explanations for its decisions. This greatly reduces the amount of time and cognitive effort required from the developer.2) Defaulting the uncritical and cognitively appealing (mindless) consumption of synthetic content in generalPicking up the examples from above, the shift in thinking patterns may not be limited to just the work environment. The transition from critical System thinking to superficial System thinking can become the default way of approaching thought processes in other areas of life, too. For instance, white-collar workers may use ChatGPT to manage their email traffic at work in a more efficient manner by letting chatbots do the demanding task of formulating emails, while the worker only provides the content in condensed bullet points. This bears the risk that those employees may gradually lean into this mode of short-cutting to handle personal emails or personal communication in the same manner. But also, for more trivial cognitive tasks outside of work, like meal planning, organizing of daily activities or decision-making in the shopping process, humans may start to outsource cognitive effort to generative AI solutions like chatbots since the efficiency boost and cognitive relief is tempting for humans in their role as cognitive misers.If humans stop learning or stop engaging in cognitive effortful tasks, the brain may be less able to adapt and change, potentially leading to a decline in cognitive abilities and overall intellectual capacity. This is because the brain can be metaphorically seen as a muscle, in the sense that if it's not used, established neuronal connections and thus learned knowledge and cognitive abilities regress (Shors et al., ). Generative AI applications may cause individuals to gradually avoid engaging in System thinking in general, as the brain is no longer accustomed to this mode of operation.3) Superficially accepting the knowledge without/before critically examining itIf this pattern of superficial requesting of knowledge continues and bears the risk to become the default mode of working, humans may gradually also lose their cognitive abilities to engage in critical examination of the results generated by generative technologies, too. Since a critical examination and evaluation of the outputs of a chatbot can also be cognitively demanding, and users may not be experts in the field for which they are retrieving knowledge, the danger of pure acceptance of the chatbot's output is tempting. This creates a double risk: not only may humans lose certain essential cognitive capabilities regarding their deep thinking, but they may also be unable to correct problematic or incorrect results generated by these technologies, which is especially dangerous in critical fields such as healthcare.While it can be argued that advanced chatbots like ChatGPT can perform complex tasks on a level that can surpass human abilities, this doesn't mean that they are resistant to errors or biases. Chatbots, and generative AI in general, is only as good as the data it is trained on. If the underlying data contains biases or inaccuracies, the AIs outputs will also be biased or inaccurate. Moreover, there are certain situations where a human touch is still required, for example in ethical or moral decision-making. A chatbot may be able to provide recommendations based on the data it has been trained on, but it lacks the ability to understand the nuances of a situation and make a decision that considers the broader context and implications. Therefore, even if chatbots become more advanced in the future and will eventually surpass human-level capabilities in problem-solving tasks, there will still be cases where human intervention and critical or analytical thinking are necessary to resolve issues and overcome challenges. For this reason, it is important to maintain our ability to critically examine information and engage in ind\"],\n",
       " [\"pendent thinking, so that we can step in when required and make informed decisions based on our unique understanding of the situation.What to be mindful about and whats next?As advanced chatbots may continue to substitute more and more the independent human thought process, there is a risk that individuals will increasingly rely on superficial, heuristic thinking (System thinking), rather than the more analytical and conscious thinking (System thinking). This shift towards superficial thinking can have far-reaching consequences as it may reduce the ability of individuals to critically evaluate and understand complex information. Moreover, it may also lead to a decline in the human capability to think creatively and to come up with innovative solutions to problems on their own. Furthermore, heuristic thinking is a way of approximating information, which can lead to errors and biases that can be problematic in certain situations and decision making without automation assistance. In that sense, when people rely on heuristics too much, they might miss important information and make poor decisions, which can be particularly dangerous in fields that involve high stakes, like healthcare or law enforcement. Therefore, it is important to be aware of the potential risks associated with relying on heuristic evaluation on the output of generative AI and to actively cultivate and maintain our ability for analytical System thinking.ChatGPT has reached million users just two months after launching (Hu, ), so the widespread future use of advanced chatbots is almost certain since economic, external incentives, as well as internal, psychological incentives favor automation over human cognitive thinking: In the business world, competition favors every little possibility to gain market advantage over competitors, whereby the most efficient methods are always chosen to conduct work, thus automation becomes more pervasive and continues to replace inefficient human thinking in the work environment. From a psychological perspective, humans themselves can be seen as cognitive misers, where as a result, we welcome any form of automation that relieves us of cognitive effort in our private life.ChatGPT, with its superb capabilities to solve information processing tasks, is set to become more advanced with each iteration. Microsoft already launched a new version of its Bing search engine that incorporates ChatGPT to make it easier for users to create content and find answers on the web (Mehdi. ). Google has followed suit and introduced its own chatbot, Bard, which will also be integrated into the company's search engine (Pichai, ). Due to market pressure, every player in the market will aim to beat the competitors' chatbot in terms of their capabilities and try to incorporate the technology in their services as much as possible. Therefore, the previously addressed weaknesses are likely to be overcome sooner than later. Chatbots will likely become increasingly prevalent in the business world and may take part in our daily lives, making our interactions with technology more seamless and efficient. As the technology continues to improve, it is likely that advanced chatbots will play a significant role in shaping the future of how we access and process information.However, the question remains how independent human thinking will be shaped: Will we continue to be able to draw logical conclusions ourselves through deep, but tedious thinking? Or will we lose cognitive capabilities and become like shallow waters, lacking the depth and flow of ideas and imagination by only perceiving and interpreting information superficially?Rather than making predictions about the future of the interplay between humans and chatbots, this article should serve more as a theoretical foundation on how humans are exposed to automated information processing from a cognitive-psychological perspective. The article should stress and call for further research in the area of cognitive biases that may arise from the use and adoption of advanced chatbots in order to better understand potential consequences. Lets think deeply together!About the authorsMarcel Peter is an alumnus of the Digital Business & Innovation Programme at VU Amsterdam, where he obtained his Master's degree in . As a part of his Master's thesis, he researched the effect of explainable AI in the domain of radiology, specifically how explainable AI methods influence radiologists in their decision-making process while reading mammograms. Marcel was supervised by Prof. Dr. Mohammad Rezazade Mehrizi and worked closely together with him over the course of the thesis trajectory. After graduating, Marcel continued to stay in contact with Mohammad, and together they have further extended their research in the field of AI in radiology. After testing ChatGPT, Marcel found that much of the literature from his Master's thesis on Cognitive Psychology and Hybrid Intelligence was highl\"],\n",
       " ['Heuristics can be defined as the \"judgmental shortcuts that generally get us where we need to goand quicklybut at the cost of occasionally sending us off course\" (Gilovich & Savitsky, , p.36). To reduce their cognitive load, humans tend to ignore part of the information associated with certain tasks and rather rely on mental shortcuts to solve the underlying task, because information search and processing costs time and cognitive resources (Gigerenzer & Gaissmaier, ).In today\\'s world, the search for suitable information is easier than ever thanks to the internet as an external memorization medium. Since the information required no longer must be retrieved by people themselves from their memory, but is almost always at hand via intelligent devices, the associated cognitive efforts for gathering and storing information are reduced. However, this comfortable method of information retrieval has also compromised the ability of humans to recall information, also known as the Google Effect. A study by Sparrow et al. (2011) investigated the cognitive consequences of having information at our fingertips due to the advent of the internet and found that people do not tend to remember information if they believe it will be available to look up later. Further, if people have future access to information, they are much more likely to remember where the information is located than recalling the information itself (Sparrow et al., ). Another study by Dong & Potenza (2015) found that information learned through internet search is recalled less accurately and with less confidence as compared with traditional book searching.The proliferation of information through the internet has seemingly caused a decline in our ability to memorize and recall information effectively, however generative AI applications like ChatGPT might go even further and compromise other cognitive capabilities associated with System thinking, like logical and analytical thinking, as well. Whether it is writing code or solving complex math problems, for which humans require logical thinking and problem-solving skills, or composing neatly written text related to a particular topic or artistic poems, which requires us to be creative and stresses our writing skills. With generative AI, our cognitive capabilities will be further shifted from independent, creative thinking to mainly requesting knowledge. By inserting a prompt, we get everything served on a silver platter, so the only cognitive effort lies within creating the prompt.For the further course of this article, we have outlined three potential consequences that the utilization of generative AI applications, particularly chatbots, may have on human cognitive processes. We will elaborate each of these consequences, providing additional details and illustration through examples.Consequences of Generative AI on Human Cognition1) Short-cutting to final outcome without engaging in the process of developing itIt is commonly counter argued that external memory sources, such as the internet, enable individuals to perform at higher cognitive levels by allowing them to efficiently access and process information without spending cognitive resources on recall. However, there lies a big difference between incumbent external memory sources and advanced chatbots: While traditional external sources like the internet provide specific information in response to a query, the human user still must engage in the cognitively demanding process of reasoning and drawing conclusions based on that information. In contrast, advanced chatbots like ChatGPT can perform this entire process of reasoning and decision-making on behalf of the user, effectively substituting almost the full human thinking and decision-making process. For example, imagine a financial analyst who needs to decide about a potential investment. In the past, the analyst would have to spend significant time researching the company, analyzing financial statements, and considering market trends. With the use of an advanced chatbot, the analyst can simply input a prompt asking for the chatbot\\'s recommendation on the investment and receive a detailed and well-reasoned response that includes financial analysis, market trends, and a prediction of the company\\'s future performance. The chatbot\\'s sophisticated features effectively take over the cognitively demanding process of researching and analyzing, thus reducing human error and providing a more efficient way of decision making, while the analyst can rely on the chatbot\\'s output and make the final decision. Another example can be drawn from the field of software engineering: Traditionally, software developers would need to spend a significant amount of time and cognitive effort researching and understanding a problem or task at hand, as well as troubleshooting and debugging the code they write. However, with the use of chatbots, a developer could simply provide the chatbot with a prompt outl'],\n",
       " [\"ning the problem or task, and the chatbot would be able to generate the necessary code, troubleshoot and debug it, and even provide explanations for its decisions. This greatly reduces the amount of time and cognitive effort required from the developer.2) Defaulting the uncritical and cognitively appealing (mindless) consumption of synthetic content in generalPicking up the examples from above, the shift in thinking patterns may not be limited to just the work environment. The transition from critical System thinking to superficial System thinking can become the default way of approaching thought processes in other areas of life, too. For instance, white-collar workers may use ChatGPT to manage their email traffic at work in a more efficient manner by letting chatbots do the demanding task of formulating emails, while the worker only provides the content in condensed bullet points. This bears the risk that those employees may gradually lean into this mode of short-cutting to handle personal emails or personal communication in the same manner. But also, for more trivial cognitive tasks outside of work, like meal planning, organizing of daily activities or decision-making in the shopping process, humans may start to outsource cognitive effort to generative AI solutions like chatbots since the efficiency boost and cognitive relief is tempting for humans in their role as cognitive misers.If humans stop learning or stop engaging in cognitive effortful tasks, the brain may be less able to adapt and change, potentially leading to a decline in cognitive abilities and overall intellectual capacity. This is because the brain can be metaphorically seen as a muscle, in the sense that if it's not used, established neuronal connections and thus learned knowledge and cognitive abilities regress (Shors et al., ). Generative AI applications may cause individuals to gradually avoid engaging in System thinking in general, as the brain is no longer accustomed to this mode of operation.3) Superficially accepting the knowledge without/before critically examining itIf this pattern of superficial requesting of knowledge continues and bears the risk to become the default mode of working, humans may gradually also lose their cognitive abilities to engage in critical examination of the results generated by generative technologies, too. Since a critical examination and evaluation of the outputs of a chatbot can also be cognitively demanding, and users may not be experts in the field for which they are retrieving knowledge, the danger of pure acceptance of the chatbot's output is tempting. This creates a double risk: not only may humans lose certain essential cognitive capabilities regarding their deep thinking, but they may also be unable to correct problematic or incorrect results generated by these technologies, which is especially dangerous in critical fields such as healthcare.While it can be argued that advanced chatbots like ChatGPT can perform complex tasks on a level that can surpass human abilities, this doesn't mean that they are resistant to errors or biases. Chatbots, and generative AI in general, is only as good as the data it is trained on. If the underlying data contains biases or inaccuracies, the AIs outputs will also be biased or inaccurate. Moreover, there are certain situations where a human touch is still required, for example in ethical or moral decision-making. A chatbot may be able to provide recommendations based on the data it has been trained on, but it lacks the ability to understand the nuances of a situation and make a decision that considers the broader context and implications. Therefore, even if chatbots become more advanced in the future and will eventually surpass human-level capabilities in problem-solving tasks, there will still be cases where human intervention and critical or analytical thinking are necessary to resolve issues and overcome challenges. For this reason, it is important to maintain our ability to critically examine information and engage in independent thinking, so that we can step in when required and make informed decisions based on our unique understanding of the situation.What to be mindful about and whats next?As advanced chatbots may continue to substitute more and more the independent human thought process, there is a risk that individuals will increasingly rely on superficial, heuristic thinking (System thinking), rather than the more analytical and conscious thinking (System thinking). This shift towards superficial thinking can have far-reaching consequences as it may reduce the ability of individuals to critically evaluate and understand complex information. Moreover, it may also lead to a decline in the human capability to think creatively and to come up with innovative solutions to problems on their own. Furthermore, heuristic thinking is a way of approximating information, which can lead to errors and biases that can be problematic in certain sit\"],\n",
       " [\"ations and decision making without automation assistance. In that sense, when people rely on heuristics too much, they might miss important information and make poor decisions, which can be particularly dangerous in fields that involve high stakes, like healthcare or law enforcement. Therefore, it is important to be aware of the potential risks associated with relying on heuristic evaluation on the output of generative AI and to actively cultivate and maintain our ability for analytical System thinking.ChatGPT has reached million users just two months after launching (Hu, ), so the widespread future use of advanced chatbots is almost certain since economic, external incentives, as well as internal, psychological incentives favor automation over human cognitive thinking: In the business world, competition favors every little possibility to gain market advantage over competitors, whereby the most efficient methods are always chosen to conduct work, thus automation becomes more pervasive and continues to replace inefficient human thinking in the work environment. From a psychological perspective, humans themselves can be seen as cognitive misers, where as a result, we welcome any form of automation that relieves us of cognitive effort in our private life.ChatGPT, with its superb capabilities to solve information processing tasks, is set to become more advanced with each iteration. Microsoft already launched a new version of its Bing search engine that incorporates ChatGPT to make it easier for users to create content and find answers on the web (Mehdi. ). Google has followed suit and introduced its own chatbot, Bard, which will also be integrated into the company's search engine (Pichai, ). Due to market pressure, every player in the market will aim to beat the competitors' chatbot in terms of their capabilities and try to incorporate the technology in their services as much as possible. Therefore, the previously addressed weaknesses are likely to be overcome sooner than later. Chatbots will likely become increasingly prevalent in the business world and may take part in our daily lives, making our interactions with technology more seamless and efficient. As the technology continues to improve, it is likely that advanced chatbots will play a significant role in shaping the future of how we access and process information.However, the question remains how independent human thinking will be shaped: Will we continue to be able to draw logical conclusions ourselves through deep, but tedious thinking? Or will we lose cognitive capabilities and become like shallow waters, lacking the depth and flow of ideas and imagination by only perceiving and interpreting information superficially?Rather than making predictions about the future of the interplay between humans and chatbots, this article should serve more as a theoretical foundation on how humans are exposed to automated information processing from a cognitive-psychological perspective. The article should stress and call for further research in the area of cognitive biases that may arise from the use and adoption of advanced chatbots in order to better understand potential consequences. Lets think deeply together!About the authorsMarcel Peter is an alumnus of the Digital Business & Innovation Programme at VU Amsterdam, where he obtained his Master's degree in . As a part of his Master's thesis, he researched the effect of explainable AI in the domain of radiology, specifically how explainable AI methods influence radiologists in their decision-making process while reading mammograms. Marcel was supervised by Prof. Dr. Mohammad Rezazade Mehrizi and worked closely together with him over the course of the thesis trajectory. After graduating, Marcel continued to stay in contact with Mohammad, and together they have further extended their research in the field of AI in radiology. After testing ChatGPT, Marcel found that much of the literature from his Master's thesis on Cognitive Psychology and Hybrid Intelligence was highly applicable to the way humans interact with chatbots, what led him to write this article.Mohammad H. Rezazade Mehrizi is an Associate Professor of work and organizational learning, at KIN center for digital innovation, Vrije Universiteit Amsterdam. His is passionate about understanding and helping practitioners and organizations to learn and unlearn beyond their current limitations. His current research he examines the dynamics of expertise and learning among knowledge works and professionals in relation to emerging algorithmic technologies.ReferencesDong, G., & Potenza, M. N. (2015). Behavioural and brain responses related to Internet search and memory. European Journal of Neuroscience, (8), . S. T., & Taylor, S. E. (1991). Social Cognition. McGraw-Hill Education.Gigerenzer, G., & Gaissmaier, W. (2011). Heuristic Decision Making. Annual Review of Psychology, (1), .\"],\n",
       " [\"In today's world, the search for suitable information is easier than ever thanks to the internet as an external memorization medium. Since the information required no longer must be retrieved by people themselves from their memory, but is almost always at hand via intelligent devices, the associated cognitive efforts for gathering and storing information are reduced. However, this comfortable method of information retrieval has also compromised the ability of humans to recall information, also known as the Google Effect. A study by Sparrow et al. (2011) investigated the cognitive consequences of having information at our fingertips due to the advent of the internet and found that people do not tend to remember information if they believe it will be available to look up later. Further, if people have future access to information, they are much more likely to remember where the information is located than recalling the information itself (Sparrow et al., ). Another study by Dong & Potenza (2015) found that information learned through internet search is recalled less accurately and with less confidence as compared with traditional book searching.The proliferation of information through the internet has seemingly caused a decline in our ability to memorize and recall information effectively, however generative AI applications like ChatGPT might go even further and compromise other cognitive capabilities associated with System thinking, like logical and analytical thinking, as well. Whether it is writing code or solving complex math problems, for which humans require logical thinking and problem-solving skills, or composing neatly written text related to a particular topic or artistic poems, which requires us to be creative and stresses our writing skills. With generative AI, our cognitive capabilities will be further shifted from independent, creative thinking to mainly requesting knowledge. By inserting a prompt, we get everything served on a silver platter, so the only cognitive effort lies within creating the prompt.For the further course of this article, we have outlined three potential consequences that the utilization of generative AI applications, particularly chatbots, may have on human cognitive processes. We will elaborate each of these consequences, providing additional details and illustration through examples.Consequences of Generative AI on Human Cognition1) Short-cutting to final outcome without engaging in the process of developing itIt is commonly counter argued that external memory sources, such as the internet, enable individuals to perform at higher cognitive levels by allowing them to efficiently access and process information without spending cognitive resources on recall. However, there lies a big difference between incumbent external memory sources and advanced chatbots: While traditional external sources like the internet provide specific information in response to a query, the human user still must engage in the cognitively demanding process of reasoning and drawing conclusions based on that information. In contrast, advanced chatbots like ChatGPT can perform this entire process of reasoning and decision-making on behalf of the user, effectively substituting almost the full human thinking and decision-making process. For example, imagine a financial analyst who needs to decide about a potential investment. In the past, the analyst would have to spend significant time researching the company, analyzing financial statements, and considering market trends. With the use of an advanced chatbot, the analyst can simply input a prompt asking for the chatbot's recommendation on the investment and receive a detailed and well-reasoned response that includes financial analysis, market trends, and a prediction of the company's future performance. The chatbot's sophisticated features effectively take over the cognitively demanding process of researching and analyzing, thus reducing human error and providing a more efficient way of decision making, while the analyst can rely on the chatbot's output and make the final decision. Another example can be drawn from the field of software engineering: Traditionally, software developers would need to spend a significant amount of time and cognitive effort researching and understanding a problem or task at hand, as well as troubleshooting and debugging the code they write. However, with the use of chatbots, a developer could simply provide the chatbot with a prompt outlining the problem or task, and the chatbot would be able to generate the necessary code, troubleshoot and debug it, and even provide explanations for its decisions. This greatly reduces the amount of time and cognitive effort required from the developer.2) Defaulting the uncritical and cognitively appealing (mindless) consumption of synthetic content in generalPicking up the examples from above, the shift in thinking patterns may not be limited to just the work environment. The\"],\n",
       " [\"transition from critical System thinking to superficial System thinking can become the default way of approaching thought processes in other areas of life, too. For instance, white-collar workers may use ChatGPT to manage their email traffic at work in a more efficient manner by letting chatbots do the demanding task of formulating emails, while the worker only provides the content in condensed bullet points. This bears the risk that those employees may gradually lean into this mode of short-cutting to handle personal emails or personal communication in the same manner. But also, for more trivial cognitive tasks outside of work, like meal planning, organizing of daily activities or decision-making in the shopping process, humans may start to outsource cognitive effort to generative AI solutions like chatbots since the efficiency boost and cognitive relief is tempting for humans in their role as cognitive misers.If humans stop learning or stop engaging in cognitive effortful tasks, the brain may be less able to adapt and change, potentially leading to a decline in cognitive abilities and overall intellectual capacity. This is because the brain can be metaphorically seen as a muscle, in the sense that if it's not used, established neuronal connections and thus learned knowledge and cognitive abilities regress (Shors et al., ). Generative AI applications may cause individuals to gradually avoid engaging in System thinking in general, as the brain is no longer accustomed to this mode of operation.3) Superficially accepting the knowledge without/before critically examining itIf this pattern of superficial requesting of knowledge continues and bears the risk to become the default mode of working, humans may gradually also lose their cognitive abilities to engage in critical examination of the results generated by generative technologies, too. Since a critical examination and evaluation of the outputs of a chatbot can also be cognitively demanding, and users may not be experts in the field for which they are retrieving knowledge, the danger of pure acceptance of the chatbot's output is tempting. This creates a double risk: not only may humans lose certain essential cognitive capabilities regarding their deep thinking, but they may also be unable to correct problematic or incorrect results generated by these technologies, which is especially dangerous in critical fields such as healthcare.While it can be argued that advanced chatbots like ChatGPT can perform complex tasks on a level that can surpass human abilities, this doesn't mean that they are resistant to errors or biases. Chatbots, and generative AI in general, is only as good as the data it is trained on. If the underlying data contains biases or inaccuracies, the AIs outputs will also be biased or inaccurate. Moreover, there are certain situations where a human touch is still required, for example in ethical or moral decision-making. A chatbot may be able to provide recommendations based on the data it has been trained on, but it lacks the ability to understand the nuances of a situation and make a decision that considers the broader context and implications. Therefore, even if chatbots become more advanced in the future and will eventually surpass human-level capabilities in problem-solving tasks, there will still be cases where human intervention and critical or analytical thinking are necessary to resolve issues and overcome challenges. For this reason, it is important to maintain our ability to critically examine information and engage in independent thinking, so that we can step in when required and make informed decisions based on our unique understanding of the situation.What to be mindful about and whats next?As advanced chatbots may continue to substitute more and more the independent human thought process, there is a risk that individuals will increasingly rely on superficial, heuristic thinking (System thinking), rather than the more analytical and conscious thinking (System thinking). This shift towards superficial thinking can have far-reaching consequences as it may reduce the ability of individuals to critically evaluate and understand complex information. Moreover, it may also lead to a decline in the human capability to think creatively and to come up with innovative solutions to problems on their own. Furthermore, heuristic thinking is a way of approximating information, which can lead to errors and biases that can be problematic in certain situations and decision making without automation assistance. In that sense, when people rely on heuristics too much, they might miss important information and make poor decisions, which can be particularly dangerous in fields that involve high stakes, like healthcare or law enforcement. Therefore, it is important to be aware of the potential risks associated with relying on heuristic evaluation on the output of generative AI and to actively cultivate and maintain our ability for\"],\n",
       " [\"nalytical System thinking.ChatGPT has reached million users just two months after launching (Hu, ), so the widespread future use of advanced chatbots is almost certain since economic, external incentives, as well as internal, psychological incentives favor automation over human cognitive thinking: In the business world, competition favors every little possibility to gain market advantage over competitors, whereby the most efficient methods are always chosen to conduct work, thus automation becomes more pervasive and continues to replace inefficient human thinking in the work environment. From a psychological perspective, humans themselves can be seen as cognitive misers, where as a result, we welcome any form of automation that relieves us of cognitive effort in our private life.ChatGPT, with its superb capabilities to solve information processing tasks, is set to become more advanced with each iteration. Microsoft already launched a new version of its Bing search engine that incorporates ChatGPT to make it easier for users to create content and find answers on the web (Mehdi. ). Google has followed suit and introduced its own chatbot, Bard, which will also be integrated into the company's search engine (Pichai, ). Due to market pressure, every player in the market will aim to beat the competitors' chatbot in terms of their capabilities and try to incorporate the technology in their services as much as possible. Therefore, the previously addressed weaknesses are likely to be overcome sooner than later. Chatbots will likely become increasingly prevalent in the business world and may take part in our daily lives, making our interactions with technology more seamless and efficient. As the technology continues to improve, it is likely that advanced chatbots will play a significant role in shaping the future of how we access and process information.However, the question remains how independent human thinking will be shaped: Will we continue to be able to draw logical conclusions ourselves through deep, but tedious thinking? Or will we lose cognitive capabilities and become like shallow waters, lacking the depth and flow of ideas and imagination by only perceiving and interpreting information superficially?Rather than making predictions about the future of the interplay between humans and chatbots, this article should serve more as a theoretical foundation on how humans are exposed to automated information processing from a cognitive-psychological perspective. The article should stress and call for further research in the area of cognitive biases that may arise from the use and adoption of advanced chatbots in order to better understand potential consequences. Lets think deeply together!About the authorsMarcel Peter is an alumnus of the Digital Business & Innovation Programme at VU Amsterdam, where he obtained his Master's degree in . As a part of his Master's thesis, he researched the effect of explainable AI in the domain of radiology, specifically how explainable AI methods influence radiologists in their decision-making process while reading mammograms. Marcel was supervised by Prof. Dr. Mohammad Rezazade Mehrizi and worked closely together with him over the course of the thesis trajectory. After graduating, Marcel continued to stay in contact with Mohammad, and together they have further extended their research in the field of AI in radiology. After testing ChatGPT, Marcel found that much of the literature from his Master's thesis on Cognitive Psychology and Hybrid Intelligence was highly applicable to the way humans interact with chatbots, what led him to write this article.Mohammad H. Rezazade Mehrizi is an Associate Professor of work and organizational learning, at KIN center for digital innovation, Vrije Universiteit Amsterdam. His is passionate about understanding and helping practitioners and organizations to learn and unlearn beyond their current limitations. His current research he examines the dynamics of expertise and learning among knowledge works and professionals in relation to emerging algorithmic technologies.ReferencesDong, G., & Potenza, M. N. (2015). Behavioural and brain responses related to Internet search and memory. European Journal of Neuroscience, (8), . S. T., & Taylor, S. E. (1991). Social Cognition. McGraw-Hill Education.Gigerenzer, G., & Gaissmaier, W. (2011). Heuristic Decision Making. Annual Review of Psychology, (1), . T., & Savitsky, K. (1996). Like goes with like: The role of representativeness in erroneous and pseudoscientific beliefs. Skeptical Inquirer: The Magazine for Science and Reason, , -40.Hu, K. (2023, February ). ChatGPT sets record for fastest-growing user base - analyst D. (2003). A perspective on judgment and choice: Mapping bounded rationality. American Psychologist, (9), .\"],\n",
       " [\"he proliferation of information through the internet has seemingly caused a decline in our ability to memorize and recall information effectively, however generative AI applications like ChatGPT might go even further and compromise other cognitive capabilities associated with System thinking, like logical and analytical thinking, as well. Whether it is writing code or solving complex math problems, for which humans require logical thinking and problem-solving skills, or composing neatly written text related to a particular topic or artistic poems, which requires us to be creative and stresses our writing skills. With generative AI, our cognitive capabilities will be further shifted from independent, creative thinking to mainly requesting knowledge. By inserting a prompt, we get everything served on a silver platter, so the only cognitive effort lies within creating the prompt.For the further course of this article, we have outlined three potential consequences that the utilization of generative AI applications, particularly chatbots, may have on human cognitive processes. We will elaborate each of these consequences, providing additional details and illustration through examples.Consequences of Generative AI on Human Cognition1) Short-cutting to final outcome without engaging in the process of developing itIt is commonly counter argued that external memory sources, such as the internet, enable individuals to perform at higher cognitive levels by allowing them to efficiently access and process information without spending cognitive resources on recall. However, there lies a big difference between incumbent external memory sources and advanced chatbots: While traditional external sources like the internet provide specific information in response to a query, the human user still must engage in the cognitively demanding process of reasoning and drawing conclusions based on that information. In contrast, advanced chatbots like ChatGPT can perform this entire process of reasoning and decision-making on behalf of the user, effectively substituting almost the full human thinking and decision-making process. For example, imagine a financial analyst who needs to decide about a potential investment. In the past, the analyst would have to spend significant time researching the company, analyzing financial statements, and considering market trends. With the use of an advanced chatbot, the analyst can simply input a prompt asking for the chatbot's recommendation on the investment and receive a detailed and well-reasoned response that includes financial analysis, market trends, and a prediction of the company's future performance. The chatbot's sophisticated features effectively take over the cognitively demanding process of researching and analyzing, thus reducing human error and providing a more efficient way of decision making, while the analyst can rely on the chatbot's output and make the final decision. Another example can be drawn from the field of software engineering: Traditionally, software developers would need to spend a significant amount of time and cognitive effort researching and understanding a problem or task at hand, as well as troubleshooting and debugging the code they write. However, with the use of chatbots, a developer could simply provide the chatbot with a prompt outlining the problem or task, and the chatbot would be able to generate the necessary code, troubleshoot and debug it, and even provide explanations for its decisions. This greatly reduces the amount of time and cognitive effort required from the developer.2) Defaulting the uncritical and cognitively appealing (mindless) consumption of synthetic content in generalPicking up the examples from above, the shift in thinking patterns may not be limited to just the work environment. The transition from critical System thinking to superficial System thinking can become the default way of approaching thought processes in other areas of life, too. For instance, white-collar workers may use ChatGPT to manage their email traffic at work in a more efficient manner by letting chatbots do the demanding task of formulating emails, while the worker only provides the content in condensed bullet points. This bears the risk that those employees may gradually lean into this mode of short-cutting to handle personal emails or personal communication in the same manner. But also, for more trivial cognitive tasks outside of work, like meal planning, organizing of daily activities or decision-making in the shopping process, humans may start to outsource cognitive effort to generative AI solutions like chatbots since the efficiency boost and cognitive relief is tempting for humans in their role as cognitive misers.If humans stop learning or stop engaging in cognitive effortful tasks, the brain may be less able to adapt and change, potentially leading to a decline in cognitive abilities and overall intellectual capacity. This is because the brain\"],\n",
       " [\"can be metaphorically seen as a muscle, in the sense that if it's not used, established neuronal connections and thus learned knowledge and cognitive abilities regress (Shors et al., ). Generative AI applications may cause individuals to gradually avoid engaging in System thinking in general, as the brain is no longer accustomed to this mode of operation.3) Superficially accepting the knowledge without/before critically examining itIf this pattern of superficial requesting of knowledge continues and bears the risk to become the default mode of working, humans may gradually also lose their cognitive abilities to engage in critical examination of the results generated by generative technologies, too. Since a critical examination and evaluation of the outputs of a chatbot can also be cognitively demanding, and users may not be experts in the field for which they are retrieving knowledge, the danger of pure acceptance of the chatbot's output is tempting. This creates a double risk: not only may humans lose certain essential cognitive capabilities regarding their deep thinking, but they may also be unable to correct problematic or incorrect results generated by these technologies, which is especially dangerous in critical fields such as healthcare.While it can be argued that advanced chatbots like ChatGPT can perform complex tasks on a level that can surpass human abilities, this doesn't mean that they are resistant to errors or biases. Chatbots, and generative AI in general, is only as good as the data it is trained on. If the underlying data contains biases or inaccuracies, the AIs outputs will also be biased or inaccurate. Moreover, there are certain situations where a human touch is still required, for example in ethical or moral decision-making. A chatbot may be able to provide recommendations based on the data it has been trained on, but it lacks the ability to understand the nuances of a situation and make a decision that considers the broader context and implications. Therefore, even if chatbots become more advanced in the future and will eventually surpass human-level capabilities in problem-solving tasks, there will still be cases where human intervention and critical or analytical thinking are necessary to resolve issues and overcome challenges. For this reason, it is important to maintain our ability to critically examine information and engage in independent thinking, so that we can step in when required and make informed decisions based on our unique understanding of the situation.What to be mindful about and whats next?As advanced chatbots may continue to substitute more and more the independent human thought process, there is a risk that individuals will increasingly rely on superficial, heuristic thinking (System thinking), rather than the more analytical and conscious thinking (System thinking). This shift towards superficial thinking can have far-reaching consequences as it may reduce the ability of individuals to critically evaluate and understand complex information. Moreover, it may also lead to a decline in the human capability to think creatively and to come up with innovative solutions to problems on their own. Furthermore, heuristic thinking is a way of approximating information, which can lead to errors and biases that can be problematic in certain situations and decision making without automation assistance. In that sense, when people rely on heuristics too much, they might miss important information and make poor decisions, which can be particularly dangerous in fields that involve high stakes, like healthcare or law enforcement. Therefore, it is important to be aware of the potential risks associated with relying on heuristic evaluation on the output of generative AI and to actively cultivate and maintain our ability for analytical System thinking.ChatGPT has reached million users just two months after launching (Hu, ), so the widespread future use of advanced chatbots is almost certain since economic, external incentives, as well as internal, psychological incentives favor automation over human cognitive thinking: In the business world, competition favors every little possibility to gain market advantage over competitors, whereby the most efficient methods are always chosen to conduct work, thus automation becomes more pervasive and continues to replace inefficient human thinking in the work environment. From a psychological perspective, humans themselves can be seen as cognitive misers, where as a result, we welcome any form of automation that relieves us of cognitive effort in our private life.ChatGPT, with its superb capabilities to solve information processing tasks, is set to become more advanced with each iteration. Microsoft already launched a new version of its Bing search engine that incorporates ChatGPT to make it easier for users to create content and find answers on the web (Mehdi. ). Google has followed suit and introduced its own chatbot\"],\n",
       " [\"Bard, which will also be integrated into the company's search engine (Pichai, ). Due to market pressure, every player in the market will aim to beat the competitors' chatbot in terms of their capabilities and try to incorporate the technology in their services as much as possible. Therefore, the previously addressed weaknesses are likely to be overcome sooner than later. Chatbots will likely become increasingly prevalent in the business world and may take part in our daily lives, making our interactions with technology more seamless and efficient. As the technology continues to improve, it is likely that advanced chatbots will play a significant role in shaping the future of how we access and process information.However, the question remains how independent human thinking will be shaped: Will we continue to be able to draw logical conclusions ourselves through deep, but tedious thinking? Or will we lose cognitive capabilities and become like shallow waters, lacking the depth and flow of ideas and imagination by only perceiving and interpreting information superficially?Rather than making predictions about the future of the interplay between humans and chatbots, this article should serve more as a theoretical foundation on how humans are exposed to automated information processing from a cognitive-psychological perspective. The article should stress and call for further research in the area of cognitive biases that may arise from the use and adoption of advanced chatbots in order to better understand potential consequences. Lets think deeply together!About the authorsMarcel Peter is an alumnus of the Digital Business & Innovation Programme at VU Amsterdam, where he obtained his Master's degree in . As a part of his Master's thesis, he researched the effect of explainable AI in the domain of radiology, specifically how explainable AI methods influence radiologists in their decision-making process while reading mammograms. Marcel was supervised by Prof. Dr. Mohammad Rezazade Mehrizi and worked closely together with him over the course of the thesis trajectory. After graduating, Marcel continued to stay in contact with Mohammad, and together they have further extended their research in the field of AI in radiology. After testing ChatGPT, Marcel found that much of the literature from his Master's thesis on Cognitive Psychology and Hybrid Intelligence was highly applicable to the way humans interact with chatbots, what led him to write this article.Mohammad H. Rezazade Mehrizi is an Associate Professor of work and organizational learning, at KIN center for digital innovation, Vrije Universiteit Amsterdam. His is passionate about understanding and helping practitioners and organizations to learn and unlearn beyond their current limitations. His current research he examines the dynamics of expertise and learning among knowledge works and professionals in relation to emerging algorithmic technologies.ReferencesDong, G., & Potenza, M. N. (2015). Behavioural and brain responses related to Internet search and memory. European Journal of Neuroscience, (8), . S. T., & Taylor, S. E. (1991). Social Cognition. McGraw-Hill Education.Gigerenzer, G., & Gaissmaier, W. (2011). Heuristic Decision Making. Annual Review of Psychology, (1), . T., & Savitsky, K. (1996). Like goes with like: The role of representativeness in erroneous and pseudoscientific beliefs. Skeptical Inquirer: The Magazine for Science and Reason, , -40.Hu, K. (2023, February ). ChatGPT sets record for fastest-growing user base - analyst D. (2003). A perspective on judgment and choice: Mapping bounded rationality. American Psychologist, (9), . D. (2011). Thinking, Fast and Slow (1st ed.). Farrar, Straus and GirouxMehdi, Y. (2023, February ). Reinventing search with a new AI-powered Microsoft Bing and Edge, your copilot for the web - The Official Microsoft Blog. The Official Microsoft S. (2023, February ). An important next step on our AI journey. Google. T. J., Anderson, M. L., Curlik, D. M., & Nokia, M. S. (2012). Use it or lose it: How neurogenesis keeps the brain fit for learning. Behavioural Brain Research, (2), . K. (2009). SIX. The Cognitive Miser: Ways to Avoid Thinking. In What Intelligence Tests Miss: The Psychology of Rational Thought (pp. -85). New Haven: Yale University Press. K. E., & West, R. F. (2000). Individual differences in reasoning: Implications for the rationality debate? Behavioral and Brain Sciences, (5), . B., Liu, J., & Wegner, D. M. (2011). Google Effects on\"],\n",
       " [\"For the further course of this article, we have outlined three potential consequences that the utilization of generative AI applications, particularly chatbots, may have on human cognitive processes. We will elaborate each of these consequences, providing additional details and illustration through examples.Consequences of Generative AI on Human Cognition1) Short-cutting to final outcome without engaging in the process of developing itIt is commonly counter argued that external memory sources, such as the internet, enable individuals to perform at higher cognitive levels by allowing them to efficiently access and process information without spending cognitive resources on recall. However, there lies a big difference between incumbent external memory sources and advanced chatbots: While traditional external sources like the internet provide specific information in response to a query, the human user still must engage in the cognitively demanding process of reasoning and drawing conclusions based on that information. In contrast, advanced chatbots like ChatGPT can perform this entire process of reasoning and decision-making on behalf of the user, effectively substituting almost the full human thinking and decision-making process. For example, imagine a financial analyst who needs to decide about a potential investment. In the past, the analyst would have to spend significant time researching the company, analyzing financial statements, and considering market trends. With the use of an advanced chatbot, the analyst can simply input a prompt asking for the chatbot's recommendation on the investment and receive a detailed and well-reasoned response that includes financial analysis, market trends, and a prediction of the company's future performance. The chatbot's sophisticated features effectively take over the cognitively demanding process of researching and analyzing, thus reducing human error and providing a more efficient way of decision making, while the analyst can rely on the chatbot's output and make the final decision. Another example can be drawn from the field of software engineering: Traditionally, software developers would need to spend a significant amount of time and cognitive effort researching and understanding a problem or task at hand, as well as troubleshooting and debugging the code they write. However, with the use of chatbots, a developer could simply provide the chatbot with a prompt outlining the problem or task, and the chatbot would be able to generate the necessary code, troubleshoot and debug it, and even provide explanations for its decisions. This greatly reduces the amount of time and cognitive effort required from the developer.2) Defaulting the uncritical and cognitively appealing (mindless) consumption of synthetic content in generalPicking up the examples from above, the shift in thinking patterns may not be limited to just the work environment. The transition from critical System thinking to superficial System thinking can become the default way of approaching thought processes in other areas of life, too. For instance, white-collar workers may use ChatGPT to manage their email traffic at work in a more efficient manner by letting chatbots do the demanding task of formulating emails, while the worker only provides the content in condensed bullet points. This bears the risk that those employees may gradually lean into this mode of short-cutting to handle personal emails or personal communication in the same manner. But also, for more trivial cognitive tasks outside of work, like meal planning, organizing of daily activities or decision-making in the shopping process, humans may start to outsource cognitive effort to generative AI solutions like chatbots since the efficiency boost and cognitive relief is tempting for humans in their role as cognitive misers.If humans stop learning or stop engaging in cognitive effortful tasks, the brain may be less able to adapt and change, potentially leading to a decline in cognitive abilities and overall intellectual capacity. This is because the brain can be metaphorically seen as a muscle, in the sense that if it's not used, established neuronal connections and thus learned knowledge and cognitive abilities regress (Shors et al., ). Generative AI applications may cause individuals to gradually avoid engaging in System thinking in general, as the brain is no longer accustomed to this mode of operation.3) Superficially accepting the knowledge without/before critically examining itIf this pattern of superficial requesting of knowledge continues and bears the risk to become the default mode of working, humans may gradually also lose their cognitive abilities to engage in critical examination of the results generated by generative technologies, too. Since a critical examination and evaluation of the outputs of a chatbot can also be cognitively demanding, and users may not be experts in the field for which they are retrieving\"],\n",
       " [\"nowledge, the danger of pure acceptance of the chatbot's output is tempting. This creates a double risk: not only may humans lose certain essential cognitive capabilities regarding their deep thinking, but they may also be unable to correct problematic or incorrect results generated by these technologies, which is especially dangerous in critical fields such as healthcare.While it can be argued that advanced chatbots like ChatGPT can perform complex tasks on a level that can surpass human abilities, this doesn't mean that they are resistant to errors or biases. Chatbots, and generative AI in general, is only as good as the data it is trained on. If the underlying data contains biases or inaccuracies, the AIs outputs will also be biased or inaccurate. Moreover, there are certain situations where a human touch is still required, for example in ethical or moral decision-making. A chatbot may be able to provide recommendations based on the data it has been trained on, but it lacks the ability to understand the nuances of a situation and make a decision that considers the broader context and implications. Therefore, even if chatbots become more advanced in the future and will eventually surpass human-level capabilities in problem-solving tasks, there will still be cases where human intervention and critical or analytical thinking are necessary to resolve issues and overcome challenges. For this reason, it is important to maintain our ability to critically examine information and engage in independent thinking, so that we can step in when required and make informed decisions based on our unique understanding of the situation.What to be mindful about and whats next?As advanced chatbots may continue to substitute more and more the independent human thought process, there is a risk that individuals will increasingly rely on superficial, heuristic thinking (System thinking), rather than the more analytical and conscious thinking (System thinking). This shift towards superficial thinking can have far-reaching consequences as it may reduce the ability of individuals to critically evaluate and understand complex information. Moreover, it may also lead to a decline in the human capability to think creatively and to come up with innovative solutions to problems on their own. Furthermore, heuristic thinking is a way of approximating information, which can lead to errors and biases that can be problematic in certain situations and decision making without automation assistance. In that sense, when people rely on heuristics too much, they might miss important information and make poor decisions, which can be particularly dangerous in fields that involve high stakes, like healthcare or law enforcement. Therefore, it is important to be aware of the potential risks associated with relying on heuristic evaluation on the output of generative AI and to actively cultivate and maintain our ability for analytical System thinking.ChatGPT has reached million users just two months after launching (Hu, ), so the widespread future use of advanced chatbots is almost certain since economic, external incentives, as well as internal, psychological incentives favor automation over human cognitive thinking: In the business world, competition favors every little possibility to gain market advantage over competitors, whereby the most efficient methods are always chosen to conduct work, thus automation becomes more pervasive and continues to replace inefficient human thinking in the work environment. From a psychological perspective, humans themselves can be seen as cognitive misers, where as a result, we welcome any form of automation that relieves us of cognitive effort in our private life.ChatGPT, with its superb capabilities to solve information processing tasks, is set to become more advanced with each iteration. Microsoft already launched a new version of its Bing search engine that incorporates ChatGPT to make it easier for users to create content and find answers on the web (Mehdi. ). Google has followed suit and introduced its own chatbot, Bard, which will also be integrated into the company's search engine (Pichai, ). Due to market pressure, every player in the market will aim to beat the competitors' chatbot in terms of their capabilities and try to incorporate the technology in their services as much as possible. Therefore, the previously addressed weaknesses are likely to be overcome sooner than later. Chatbots will likely become increasingly prevalent in the business world and may take part in our daily lives, making our interactions with technology more seamless and efficient. As the technology continues to improve, it is likely that advanced chatbots will play a significant role in shaping the future of how we access and process information.However, the question remains how independent human thinking will be shaped: Will we continue to be able to draw logical conclusions ourselves through deep, but tedious\"],\n",
       " [],\n",
       " [\"uch as healthcare.While it can be argued that advanced chatbots like ChatGPT can perform complex tasks on a level that can surpass human abilities, this doesn't mean that they are resistant to errors or biases. Chatbots, and generative AI in general, is only as good as the data it is trained on. If the underlying data contains biases or inaccuracies, the AIs outputs will also be biased or inaccurate. Moreover, there are certain situations where a human touch is still required, for example in ethical or moral decision-making. A chatbot may be able to provide recommendations based on the data it has been trained on, but it lacks the ability to understand the nuances of a situation and make a decision that considers the broader context and implications. Therefore, even if chatbots become more advanced in the future and will eventually surpass human-level capabilities in problem-solving tasks, there will still be cases where human intervention and critical or analytical thinking are necessary to resolve issues and overcome challenges. For this reason, it is important to maintain our ability to critically examine information and engage in independent thinking, so that we can step in when required and make informed decisions based on our unique understanding of the situation.What to be mindful about and whats next?As advanced chatbots may continue to substitute more and more the independent human thought process, there is a risk that individuals will increasingly rely on superficial, heuristic thinking (System thinking), rather than the more analytical and conscious thinking (System thinking). This shift towards superficial thinking can have far-reaching consequences as it may reduce the ability of individuals to critically evaluate and understand complex information. Moreover, it may also lead to a decline in the human capability to think creatively and to come up with innovative solutions to problems on their own. Furthermore, heuristic thinking is a way of approximating information, which can lead to errors and biases that can be problematic in certain situations and decision making without automation assistance. In that sense, when people rely on heuristics too much, they might miss important information and make poor decisions, which can be particularly dangerous in fields that involve high stakes, like healthcare or law enforcement. Therefore, it is important to be aware of the potential risks associated with relying on heuristic evaluation on the output of generative AI and to actively cultivate and maintain our ability for analytical System thinking.ChatGPT has reached million users just two months after launching (Hu, ), so the widespread future use of advanced chatbots is almost certain since economic, external incentives, as well as internal, psychological incentives favor automation over human cognitive thinking: In the business world, competition favors every little possibility to gain market advantage over competitors, whereby the most efficient methods are always chosen to conduct work, thus automation becomes more pervasive and continues to replace inefficient human thinking in the work environment. From a psychological perspective, humans themselves can be seen as cognitive misers, where as a result, we welcome any form of automation that relieves us of cognitive effort in our private life.ChatGPT, with its superb capabilities to solve information processing tasks, is set to become more advanced with each iteration. Microsoft already launched a new version of its Bing search engine that incorporates ChatGPT to make it easier for users to create content and find answers on the web (Mehdi. ). Google has followed suit and introduced its own chatbot, Bard, which will also be integrated into the company's search engine (Pichai, ). Due to market pressure, every player in the market will aim to beat the competitors' chatbot in terms of their capabilities and try to incorporate the technology in their services as much as possible. Therefore, the previously addressed weaknesses are likely to be overcome sooner than later. Chatbots will likely become increasingly prevalent in the business world and may take part in our daily lives, making our interactions with technology more seamless and efficient. As the technology continues to improve, it is likely that advanced chatbots will play a significant role in shaping the future of how we access and process information.However, the question remains how independent human thinking will be shaped: Will we continue to be able to draw logical conclusions ourselves through deep, but tedious thinking? Or will we lose cognitive capabilities and become like shallow waters, lacking the depth and flow of ideas and imagination by only perceiving and interpreting information superficially?Rather than making predictions about the future of the interplay between humans and chatbots, this article should serve more as a theoretical foundation on how\"],\n",
       " [],\n",
       " [\"form complex tasks on a level that can surpass human abilities, this doesn't mean that they are resistant to errors or biases. Chatbots, and generative AI in general, is only as good as the data it is trained on. If the underlying data contains biases or inaccuracies, the AIs outputs will also be biased or inaccurate. Moreover, there are certain situations where a human touch is still required, for example in ethical or moral decision-making. A chatbot may be able to provide recommendations based on the data it has been trained on, but it lacks the ability to understand the nuances of a situation and make a decision that considers the broader context and implications. Therefore, even if chatbots become more advanced in the future and will eventually surpass human-level capabilities in problem-solving tasks, there will still be cases where human intervention and critical or analytical thinking are necessary to resolve issues and overcome challenges. For this reason, it is important to maintain our ability to critically examine information and engage in independent thinking, so that we can step in when required and make informed decisions based on our unique understanding of the situation.What to be mindful about and whats next?As advanced chatbots may continue to substitute more and more the independent human thought process, there is a risk that individuals will increasingly rely on superficial, heuristic thinking (System thinking), rather than the more analytical and conscious thinking (System thinking). This shift towards superficial thinking can have far-reaching consequences as it may reduce the ability of individuals to critically evaluate and understand complex information. Moreover, it may also lead to a decline in the human capability to think creatively and to come up with innovative solutions to problems on their own. Furthermore, heuristic thinking is a way of approximating information, which can lead to errors and biases that can be problematic in certain situations and decision making without automation assistance. In that sense, when people rely on heuristics too much, they might miss important information and make poor decisions, which can be particularly dangerous in fields that involve high stakes, like healthcare or law enforcement. Therefore, it is important to be aware of the potential risks associated with relying on heuristic evaluation on the output of generative AI and to actively cultivate and maintain our ability for analytical System thinking.ChatGPT has reached million users just two months after launching (Hu, ), so the widespread future use of advanced chatbots is almost certain since economic, external incentives, as well as internal, psychological incentives favor automation over human cognitive thinking: In the business world, competition favors every little possibility to gain market advantage over competitors, whereby the most efficient methods are always chosen to conduct work, thus automation becomes more pervasive and continues to replace inefficient human thinking in the work environment. From a psychological perspective, humans themselves can be seen as cognitive misers, where as a result, we welcome any form of automation that relieves us of cognitive effort in our private life.ChatGPT, with its superb capabilities to solve information processing tasks, is set to become more advanced with each iteration. Microsoft already launched a new version of its Bing search engine that incorporates ChatGPT to make it easier for users to create content and find answers on the web (Mehdi. ). Google has followed suit and introduced its own chatbot, Bard, which will also be integrated into the company's search engine (Pichai, ). Due to market pressure, every player in the market will aim to beat the competitors' chatbot in terms of their capabilities and try to incorporate the technology in their services as much as possible. Therefore, the previously addressed weaknesses are likely to be overcome sooner than later. Chatbots will likely become increasingly prevalent in the business world and may take part in our daily lives, making our interactions with technology more seamless and efficient. As the technology continues to improve, it is likely that advanced chatbots will play a significant role in shaping the future of how we access and process information.However, the question remains how independent human thinking will be shaped: Will we continue to be able to draw logical conclusions ourselves through deep, but tedious thinking? Or will we lose cognitive capabilities and become like shallow waters, lacking the depth and flow of ideas and imagination by only perceiving and interpreting information superficially?Rather than making predictions about the future of the interplay between humans and chatbots, this article should serve more as a theoretical foundation on how humans are exposed to automated information processing from a cognitive-psychologic\"],\n",
       " [\") Defaulting the uncritical and cognitively appealing (mindless) consumption of synthetic content in generalPicking up the examples from above, the shift in thinking patterns may not be limited to just the work environment. The transition from critical System thinking to superficial System thinking can become the default way of approaching thought processes in other areas of life, too. For instance, white-collar workers may use ChatGPT to manage their email traffic at work in a more efficient manner by letting chatbots do the demanding task of formulating emails, while the worker only provides the content in condensed bullet points. This bears the risk that those employees may gradually lean into this mode of short-cutting to handle personal emails or personal communication in the same manner. But also, for more trivial cognitive tasks outside of work, like meal planning, organizing of daily activities or decision-making in the shopping process, humans may start to outsource cognitive effort to generative AI solutions like chatbots since the efficiency boost and cognitive relief is tempting for humans in their role as cognitive misers.If humans stop learning or stop engaging in cognitive effortful tasks, the brain may be less able to adapt and change, potentially leading to a decline in cognitive abilities and overall intellectual capacity. This is because the brain can be metaphorically seen as a muscle, in the sense that if it's not used, established neuronal connections and thus learned knowledge and cognitive abilities regress (Shors et al., ). Generative AI applications may cause individuals to gradually avoid engaging in System thinking in general, as the brain is no longer accustomed to this mode of operation.3) Superficially accepting the knowledge without/before critically examining itIf this pattern of superficial requesting of knowledge continues and bears the risk to become the default mode of working, humans may gradually also lose their cognitive abilities to engage in critical examination of the results generated by generative technologies, too. Since a critical examination and evaluation of the outputs of a chatbot can also be cognitively demanding, and users may not be experts in the field for which they are retrieving knowledge, the danger of pure acceptance of the chatbot's output is tempting. This creates a double risk: not only may humans lose certain essential cognitive capabilities regarding their deep thinking, but they may also be unable to correct problematic or incorrect results generated by these technologies, which is especially dangerous in critical fields such as healthcare.While it can be argued that advanced chatbots like ChatGPT can perform complex tasks on a level that can surpass human abilities, this doesn't mean that they are resistant to errors or biases. Chatbots, and generative AI in general, is only as good as the data it is trained on. If the underlying data contains biases or inaccuracies, the AIs outputs will also be biased or inaccurate. Moreover, there are certain situations where a human touch is still required, for example in ethical or moral decision-making. A chatbot may be able to provide recommendations based on the data it has been trained on, but it lacks the ability to understand the nuances of a situation and make a decision that considers the broader context and implications. Therefore, even if chatbots become more advanced in the future and will eventually surpass human-level capabilities in problem-solving tasks, there will still be cases where human intervention and critical or analytical thinking are necessary to resolve issues and overcome challenges. For this reason, it is important to maintain our ability to critically examine information and engage in independent thinking, so that we can step in when required and make informed decisions based on our unique understanding of the situation.What to be mindful about and whats next?As advanced chatbots may continue to substitute more and more the independent human thought process, there is a risk that individuals will increasingly rely on superficial, heuristic thinking (System thinking), rather than the more analytical and conscious thinking (System thinking). This shift towards superficial thinking can have far-reaching consequences as it may reduce the ability of individuals to critically evaluate and understand complex information. Moreover, it may also lead to a decline in the human capability to think creatively and to come up with innovative solutions to problems on their own. Furthermore, heuristic thinking is a way of approximating information, which can lead to errors and biases that can be problematic in certain situations and decision making without automation assistance. In that sense, when people rely on heuristics too much, they might miss important information and make poor decisions, which can be particularly dangerous in fields that involve high stakes, lik\"],\n",
       " [\"healthcare or law enforcement. Therefore, it is important to be aware of the potential risks associated with relying on heuristic evaluation on the output of generative AI and to actively cultivate and maintain our ability for analytical System thinking.ChatGPT has reached million users just two months after launching (Hu, ), so the widespread future use of advanced chatbots is almost certain since economic, external incentives, as well as internal, psychological incentives favor automation over human cognitive thinking: In the business world, competition favors every little possibility to gain market advantage over competitors, whereby the most efficient methods are always chosen to conduct work, thus automation becomes more pervasive and continues to replace inefficient human thinking in the work environment. From a psychological perspective, humans themselves can be seen as cognitive misers, where as a result, we welcome any form of automation that relieves us of cognitive effort in our private life.ChatGPT, with its superb capabilities to solve information processing tasks, is set to become more advanced with each iteration. Microsoft already launched a new version of its Bing search engine that incorporates ChatGPT to make it easier for users to create content and find answers on the web (Mehdi. ). Google has followed suit and introduced its own chatbot, Bard, which will also be integrated into the company's search engine (Pichai, ). Due to market pressure, every player in the market will aim to beat the competitors' chatbot in terms of their capabilities and try to incorporate the technology in their services as much as possible. Therefore, the previously addressed weaknesses are likely to be overcome sooner than later. Chatbots will likely become increasingly prevalent in the business world and may take part in our daily lives, making our interactions with technology more seamless and efficient. As the technology continues to improve, it is likely that advanced chatbots will play a significant role in shaping the future of how we access and process information.However, the question remains how independent human thinking will be shaped: Will we continue to be able to draw logical conclusions ourselves through deep, but tedious thinking? Or will we lose cognitive capabilities and become like shallow waters, lacking the depth and flow of ideas and imagination by only perceiving and interpreting information superficially?Rather than making predictions about the future of the interplay between humans and chatbots, this article should serve more as a theoretical foundation on how humans are exposed to automated information processing from a cognitive-psychological perspective. The article should stress and call for further research in the area of cognitive biases that may arise from the use and adoption of advanced chatbots in order to better understand potential consequences. Lets think deeply together!About the authorsMarcel Peter is an alumnus of the Digital Business & Innovation Programme at VU Amsterdam, where he obtained his Master's degree in . As a part of his Master's thesis, he researched the effect of explainable AI in the domain of radiology, specifically how explainable AI methods influence radiologists in their decision-making process while reading mammograms. Marcel was supervised by Prof. Dr. Mohammad Rezazade Mehrizi and worked closely together with him over the course of the thesis trajectory. After graduating, Marcel continued to stay in contact with Mohammad, and together they have further extended their research in the field of AI in radiology. After testing ChatGPT, Marcel found that much of the literature from his Master's thesis on Cognitive Psychology and Hybrid Intelligence was highly applicable to the way humans interact with chatbots, what led him to write this article.Mohammad H. Rezazade Mehrizi is an Associate Professor of work and organizational learning, at KIN center for digital innovation, Vrije Universiteit Amsterdam. His is passionate about understanding and helping practitioners and organizations to learn and unlearn beyond their current limitations. His current research he examines the dynamics of expertise and learning among knowledge works and professionals in relation to emerging algorithmic technologies.ReferencesDong, G., & Potenza, M. N. (2015). Behavioural and brain responses related to Internet search and memory. European Journal of Neuroscience, (8), . S. T., & Taylor, S. E. (1991). Social Cognition. McGraw-Hill Education.Gigerenzer, G., & Gaissmaier, W. (2011). Heuristic Decision Making. Annual Review of Psychology, (1), . T., & Savitsky, K. (1996). Like goes with like: The role of representativeness in erroneous and pseudoscientific beliefs. Skeptical Inquirer: The Magazine for Science and Reason, , -40.Hu\"],\n",
       " [\"Picking up the examples from above, the shift in thinking patterns may not be limited to just the work environment. The transition from critical System thinking to superficial System thinking can become the default way of approaching thought processes in other areas of life, too. For instance, white-collar workers may use ChatGPT to manage their email traffic at work in a more efficient manner by letting chatbots do the demanding task of formulating emails, while the worker only provides the content in condensed bullet points. This bears the risk that those employees may gradually lean into this mode of short-cutting to handle personal emails or personal communication in the same manner. But also, for more trivial cognitive tasks outside of work, like meal planning, organizing of daily activities or decision-making in the shopping process, humans may start to outsource cognitive effort to generative AI solutions like chatbots since the efficiency boost and cognitive relief is tempting for humans in their role as cognitive misers.If humans stop learning or stop engaging in cognitive effortful tasks, the brain may be less able to adapt and change, potentially leading to a decline in cognitive abilities and overall intellectual capacity. This is because the brain can be metaphorically seen as a muscle, in the sense that if it's not used, established neuronal connections and thus learned knowledge and cognitive abilities regress (Shors et al., ). Generative AI applications may cause individuals to gradually avoid engaging in System thinking in general, as the brain is no longer accustomed to this mode of operation.3) Superficially accepting the knowledge without/before critically examining itIf this pattern of superficial requesting of knowledge continues and bears the risk to become the default mode of working, humans may gradually also lose their cognitive abilities to engage in critical examination of the results generated by generative technologies, too. Since a critical examination and evaluation of the outputs of a chatbot can also be cognitively demanding, and users may not be experts in the field for which they are retrieving knowledge, the danger of pure acceptance of the chatbot's output is tempting. This creates a double risk: not only may humans lose certain essential cognitive capabilities regarding their deep thinking, but they may also be unable to correct problematic or incorrect results generated by these technologies, which is especially dangerous in critical fields such as healthcare.While it can be argued that advanced chatbots like ChatGPT can perform complex tasks on a level that can surpass human abilities, this doesn't mean that they are resistant to errors or biases. Chatbots, and generative AI in general, is only as good as the data it is trained on. If the underlying data contains biases or inaccuracies, the AIs outputs will also be biased or inaccurate. Moreover, there are certain situations where a human touch is still required, for example in ethical or moral decision-making. A chatbot may be able to provide recommendations based on the data it has been trained on, but it lacks the ability to understand the nuances of a situation and make a decision that considers the broader context and implications. Therefore, even if chatbots become more advanced in the future and will eventually surpass human-level capabilities in problem-solving tasks, there will still be cases where human intervention and critical or analytical thinking are necessary to resolve issues and overcome challenges. For this reason, it is important to maintain our ability to critically examine information and engage in independent thinking, so that we can step in when required and make informed decisions based on our unique understanding of the situation.What to be mindful about and whats next?As advanced chatbots may continue to substitute more and more the independent human thought process, there is a risk that individuals will increasingly rely on superficial, heuristic thinking (System thinking), rather than the more analytical and conscious thinking (System thinking). This shift towards superficial thinking can have far-reaching consequences as it may reduce the ability of individuals to critically evaluate and understand complex information. Moreover, it may also lead to a decline in the human capability to think creatively and to come up with innovative solutions to problems on their own. Furthermore, heuristic thinking is a way of approximating information, which can lead to errors and biases that can be problematic in certain situations and decision making without automation assistance. In that sense, when people rely on heuristics too much, they might miss important information and make poor decisions, which can be particularly dangerous in fields that involve high stakes, like healthcare or law enforcement. Therefore, it is important to be aware of the potential risks associated wit\"],\n",
       " [\"relying on heuristic evaluation on the output of generative AI and to actively cultivate and maintain our ability for analytical System thinking.ChatGPT has reached million users just two months after launching (Hu, ), so the widespread future use of advanced chatbots is almost certain since economic, external incentives, as well as internal, psychological incentives favor automation over human cognitive thinking: In the business world, competition favors every little possibility to gain market advantage over competitors, whereby the most efficient methods are always chosen to conduct work, thus automation becomes more pervasive and continues to replace inefficient human thinking in the work environment. From a psychological perspective, humans themselves can be seen as cognitive misers, where as a result, we welcome any form of automation that relieves us of cognitive effort in our private life.ChatGPT, with its superb capabilities to solve information processing tasks, is set to become more advanced with each iteration. Microsoft already launched a new version of its Bing search engine that incorporates ChatGPT to make it easier for users to create content and find answers on the web (Mehdi. ). Google has followed suit and introduced its own chatbot, Bard, which will also be integrated into the company's search engine (Pichai, ). Due to market pressure, every player in the market will aim to beat the competitors' chatbot in terms of their capabilities and try to incorporate the technology in their services as much as possible. Therefore, the previously addressed weaknesses are likely to be overcome sooner than later. Chatbots will likely become increasingly prevalent in the business world and may take part in our daily lives, making our interactions with technology more seamless and efficient. As the technology continues to improve, it is likely that advanced chatbots will play a significant role in shaping the future of how we access and process information.However, the question remains how independent human thinking will be shaped: Will we continue to be able to draw logical conclusions ourselves through deep, but tedious thinking? Or will we lose cognitive capabilities and become like shallow waters, lacking the depth and flow of ideas and imagination by only perceiving and interpreting information superficially?Rather than making predictions about the future of the interplay between humans and chatbots, this article should serve more as a theoretical foundation on how humans are exposed to automated information processing from a cognitive-psychological perspective. The article should stress and call for further research in the area of cognitive biases that may arise from the use and adoption of advanced chatbots in order to better understand potential consequences. Lets think deeply together!About the authorsMarcel Peter is an alumnus of the Digital Business & Innovation Programme at VU Amsterdam, where he obtained his Master's degree in . As a part of his Master's thesis, he researched the effect of explainable AI in the domain of radiology, specifically how explainable AI methods influence radiologists in their decision-making process while reading mammograms. Marcel was supervised by Prof. Dr. Mohammad Rezazade Mehrizi and worked closely together with him over the course of the thesis trajectory. After graduating, Marcel continued to stay in contact with Mohammad, and together they have further extended their research in the field of AI in radiology. After testing ChatGPT, Marcel found that much of the literature from his Master's thesis on Cognitive Psychology and Hybrid Intelligence was highly applicable to the way humans interact with chatbots, what led him to write this article.Mohammad H. Rezazade Mehrizi is an Associate Professor of work and organizational learning, at KIN center for digital innovation, Vrije Universiteit Amsterdam. His is passionate about understanding and helping practitioners and organizations to learn and unlearn beyond their current limitations. His current research he examines the dynamics of expertise and learning among knowledge works and professionals in relation to emerging algorithmic technologies.ReferencesDong, G., & Potenza, M. N. (2015). Behavioural and brain responses related to Internet search and memory. European Journal of Neuroscience, (8), . S. T., & Taylor, S. E. (1991). Social Cognition. McGraw-Hill Education.Gigerenzer, G., & Gaissmaier, W. (2011). Heuristic Decision Making. Annual Review of Psychology, (1), . T., & Savitsky, K. (1996). Like goes with like: The role of representativeness in erroneous and pseudoscientific beliefs. Skeptical Inquirer: The Magazine for Science and Reason, , -40.Hu, K. (2023, February ). ChatGPT sets record for fastest-growing user base - analyst D. (2003). A perspective\"],\n",
       " [\"If humans stop learning or stop engaging in cognitive effortful tasks, the brain may be less able to adapt and change, potentially leading to a decline in cognitive abilities and overall intellectual capacity. This is because the brain can be metaphorically seen as a muscle, in the sense that if it's not used, established neuronal connections and thus learned knowledge and cognitive abilities regress (Shors et al., ). Generative AI applications may cause individuals to gradually avoid engaging in System thinking in general, as the brain is no longer accustomed to this mode of operation.3) Superficially accepting the knowledge without/before critically examining itIf this pattern of superficial requesting of knowledge continues and bears the risk to become the default mode of working, humans may gradually also lose their cognitive abilities to engage in critical examination of the results generated by generative technologies, too. Since a critical examination and evaluation of the outputs of a chatbot can also be cognitively demanding, and users may not be experts in the field for which they are retrieving knowledge, the danger of pure acceptance of the chatbot's output is tempting. This creates a double risk: not only may humans lose certain essential cognitive capabilities regarding their deep thinking, but they may also be unable to correct problematic or incorrect results generated by these technologies, which is especially dangerous in critical fields such as healthcare.While it can be argued that advanced chatbots like ChatGPT can perform complex tasks on a level that can surpass human abilities, this doesn't mean that they are resistant to errors or biases. Chatbots, and generative AI in general, is only as good as the data it is trained on. If the underlying data contains biases or inaccuracies, the AIs outputs will also be biased or inaccurate. Moreover, there are certain situations where a human touch is still required, for example in ethical or moral decision-making. A chatbot may be able to provide recommendations based on the data it has been trained on, but it lacks the ability to understand the nuances of a situation and make a decision that considers the broader context and implications. Therefore, even if chatbots become more advanced in the future and will eventually surpass human-level capabilities in problem-solving tasks, there will still be cases where human intervention and critical or analytical thinking are necessary to resolve issues and overcome challenges. For this reason, it is important to maintain our ability to critically examine information and engage in independent thinking, so that we can step in when required and make informed decisions based on our unique understanding of the situation.What to be mindful about and whats next?As advanced chatbots may continue to substitute more and more the independent human thought process, there is a risk that individuals will increasingly rely on superficial, heuristic thinking (System thinking), rather than the more analytical and conscious thinking (System thinking). This shift towards superficial thinking can have far-reaching consequences as it may reduce the ability of individuals to critically evaluate and understand complex information. Moreover, it may also lead to a decline in the human capability to think creatively and to come up with innovative solutions to problems on their own. Furthermore, heuristic thinking is a way of approximating information, which can lead to errors and biases that can be problematic in certain situations and decision making without automation assistance. In that sense, when people rely on heuristics too much, they might miss important information and make poor decisions, which can be particularly dangerous in fields that involve high stakes, like healthcare or law enforcement. Therefore, it is important to be aware of the potential risks associated with relying on heuristic evaluation on the output of generative AI and to actively cultivate and maintain our ability for analytical System thinking.ChatGPT has reached million users just two months after launching (Hu, ), so the widespread future use of advanced chatbots is almost certain since economic, external incentives, as well as internal, psychological incentives favor automation over human cognitive thinking: In the business world, competition favors every little possibility to gain market advantage over competitors, whereby the most efficient methods are always chosen to conduct work, thus automation becomes more pervasive and continues to replace inefficient human thinking in the work environment. From a psychological perspective, humans themselves can be seen as cognitive misers, where as a result, we welcome any form of automation that relieves us of cognitive effort in our private life.ChatGPT, with its superb capabilities to solve information processing tasks, is set to become more advanced with each iteration. M\"],\n",
       " [\"crosoft already launched a new version of its Bing search engine that incorporates ChatGPT to make it easier for users to create content and find answers on the web (Mehdi. ). Google has followed suit and introduced its own chatbot, Bard, which will also be integrated into the company's search engine (Pichai, ). Due to market pressure, every player in the market will aim to beat the competitors' chatbot in terms of their capabilities and try to incorporate the technology in their services as much as possible. Therefore, the previously addressed weaknesses are likely to be overcome sooner than later. Chatbots will likely become increasingly prevalent in the business world and may take part in our daily lives, making our interactions with technology more seamless and efficient. As the technology continues to improve, it is likely that advanced chatbots will play a significant role in shaping the future of how we access and process information.However, the question remains how independent human thinking will be shaped: Will we continue to be able to draw logical conclusions ourselves through deep, but tedious thinking? Or will we lose cognitive capabilities and become like shallow waters, lacking the depth and flow of ideas and imagination by only perceiving and interpreting information superficially?Rather than making predictions about the future of the interplay between humans and chatbots, this article should serve more as a theoretical foundation on how humans are exposed to automated information processing from a cognitive-psychological perspective. The article should stress and call for further research in the area of cognitive biases that may arise from the use and adoption of advanced chatbots in order to better understand potential consequences. Lets think deeply together!About the authorsMarcel Peter is an alumnus of the Digital Business & Innovation Programme at VU Amsterdam, where he obtained his Master's degree in . As a part of his Master's thesis, he researched the effect of explainable AI in the domain of radiology, specifically how explainable AI methods influence radiologists in their decision-making process while reading mammograms. Marcel was supervised by Prof. Dr. Mohammad Rezazade Mehrizi and worked closely together with him over the course of the thesis trajectory. After graduating, Marcel continued to stay in contact with Mohammad, and together they have further extended their research in the field of AI in radiology. After testing ChatGPT, Marcel found that much of the literature from his Master's thesis on Cognitive Psychology and Hybrid Intelligence was highly applicable to the way humans interact with chatbots, what led him to write this article.Mohammad H. Rezazade Mehrizi is an Associate Professor of work and organizational learning, at KIN center for digital innovation, Vrije Universiteit Amsterdam. His is passionate about understanding and helping practitioners and organizations to learn and unlearn beyond their current limitations. His current research he examines the dynamics of expertise and learning among knowledge works and professionals in relation to emerging algorithmic technologies.ReferencesDong, G., & Potenza, M. N. (2015). Behavioural and brain responses related to Internet search and memory. European Journal of Neuroscience, (8), . S. T., & Taylor, S. E. (1991). Social Cognition. McGraw-Hill Education.Gigerenzer, G., & Gaissmaier, W. (2011). Heuristic Decision Making. Annual Review of Psychology, (1), . T., & Savitsky, K. (1996). Like goes with like: The role of representativeness in erroneous and pseudoscientific beliefs. Skeptical Inquirer: The Magazine for Science and Reason, , -40.Hu, K. (2023, February ). ChatGPT sets record for fastest-growing user base - analyst D. (2003). A perspective on judgment and choice: Mapping bounded rationality. American Psychologist, (9), . D. (2011). Thinking, Fast and Slow (1st ed.). Farrar, Straus and GirouxMehdi, Y. (2023, February ). Reinventing search with a new AI-powered Microsoft Bing and Edge, your copilot for the web - The Official Microsoft Blog. The Official Microsoft S. (2023, February ). An important next step on our AI journey. Google. T. J., Anderson, M. L., Curlik, D. M., & Nokia, M. S. (2012). Use it or lose it: How neurogenesis keeps the brain fit for learning. Behavioural Brain Research, (2), . K. (2009). SIX. The Cognitive Miser: Ways to Avoid Thinking. In What Intelligence Tests Miss: The Psychology of Rational Thought (pp. -85). New Haven: Yale University Press. K. E., & West, R. F. (2\"],\n",
       " [\") Superficially accepting the knowledge without/before critically examining itIf this pattern of superficial requesting of knowledge continues and bears the risk to become the default mode of working, humans may gradually also lose their cognitive abilities to engage in critical examination of the results generated by generative technologies, too. Since a critical examination and evaluation of the outputs of a chatbot can also be cognitively demanding, and users may not be experts in the field for which they are retrieving knowledge, the danger of pure acceptance of the chatbot's output is tempting. This creates a double risk: not only may humans lose certain essential cognitive capabilities regarding their deep thinking, but they may also be unable to correct problematic or incorrect results generated by these technologies, which is especially dangerous in critical fields such as healthcare.While it can be argued that advanced chatbots like ChatGPT can perform complex tasks on a level that can surpass human abilities, this doesn't mean that they are resistant to errors or biases. Chatbots, and generative AI in general, is only as good as the data it is trained on. If the underlying data contains biases or inaccuracies, the AIs outputs will also be biased or inaccurate. Moreover, there are certain situations where a human touch is still required, for example in ethical or moral decision-making. A chatbot may be able to provide recommendations based on the data it has been trained on, but it lacks the ability to understand the nuances of a situation and make a decision that considers the broader context and implications. Therefore, even if chatbots become more advanced in the future and will eventually surpass human-level capabilities in problem-solving tasks, there will still be cases where human intervention and critical or analytical thinking are necessary to resolve issues and overcome challenges. For this reason, it is important to maintain our ability to critically examine information and engage in independent thinking, so that we can step in when required and make informed decisions based on our unique understanding of the situation.What to be mindful about and whats next?As advanced chatbots may continue to substitute more and more the independent human thought process, there is a risk that individuals will increasingly rely on superficial, heuristic thinking (System thinking), rather than the more analytical and conscious thinking (System thinking). This shift towards superficial thinking can have far-reaching consequences as it may reduce the ability of individuals to critically evaluate and understand complex information. Moreover, it may also lead to a decline in the human capability to think creatively and to come up with innovative solutions to problems on their own. Furthermore, heuristic thinking is a way of approximating information, which can lead to errors and biases that can be problematic in certain situations and decision making without automation assistance. In that sense, when people rely on heuristics too much, they might miss important information and make poor decisions, which can be particularly dangerous in fields that involve high stakes, like healthcare or law enforcement. Therefore, it is important to be aware of the potential risks associated with relying on heuristic evaluation on the output of generative AI and to actively cultivate and maintain our ability for analytical System thinking.ChatGPT has reached million users just two months after launching (Hu, ), so the widespread future use of advanced chatbots is almost certain since economic, external incentives, as well as internal, psychological incentives favor automation over human cognitive thinking: In the business world, competition favors every little possibility to gain market advantage over competitors, whereby the most efficient methods are always chosen to conduct work, thus automation becomes more pervasive and continues to replace inefficient human thinking in the work environment. From a psychological perspective, humans themselves can be seen as cognitive misers, where as a result, we welcome any form of automation that relieves us of cognitive effort in our private life.ChatGPT, with its superb capabilities to solve information processing tasks, is set to become more advanced with each iteration. Microsoft already launched a new version of its Bing search engine that incorporates ChatGPT to make it easier for users to create content and find answers on the web (Mehdi. ). Google has followed suit and introduced its own chatbot, Bard, which will also be integrated into the company's search engine (Pichai, ). Due to market pressure, every player in the market will aim to beat the competitors' chatbot in terms of their capabilities and try to incorporate the technology in their services as much as possible. Therefore, the previously addressed weaknesses are likely to be overcome soon\"],\n",
       " [\"If this pattern of superficial requesting of knowledge continues and bears the risk to become the default mode of working, humans may gradually also lose their cognitive abilities to engage in critical examination of the results generated by generative technologies, too. Since a critical examination and evaluation of the outputs of a chatbot can also be cognitively demanding, and users may not be experts in the field for which they are retrieving knowledge, the danger of pure acceptance of the chatbot's output is tempting. This creates a double risk: not only may humans lose certain essential cognitive capabilities regarding their deep thinking, but they may also be unable to correct problematic or incorrect results generated by these technologies, which is especially dangerous in critical fields such as healthcare.While it can be argued that advanced chatbots like ChatGPT can perform complex tasks on a level that can surpass human abilities, this doesn't mean that they are resistant to errors or biases. Chatbots, and generative AI in general, is only as good as the data it is trained on. If the underlying data contains biases or inaccuracies, the AIs outputs will also be biased or inaccurate. Moreover, there are certain situations where a human touch is still required, for example in ethical or moral decision-making. A chatbot may be able to provide recommendations based on the data it has been trained on, but it lacks the ability to understand the nuances of a situation and make a decision that considers the broader context and implications. Therefore, even if chatbots become more advanced in the future and will eventually surpass human-level capabilities in problem-solving tasks, there will still be cases where human intervention and critical or analytical thinking are necessary to resolve issues and overcome challenges. For this reason, it is important to maintain our ability to critically examine information and engage in independent thinking, so that we can step in when required and make informed decisions based on our unique understanding of the situation.What to be mindful about and whats next?As advanced chatbots may continue to substitute more and more the independent human thought process, there is a risk that individuals will increasingly rely on superficial, heuristic thinking (System thinking), rather than the more analytical and conscious thinking (System thinking). This shift towards superficial thinking can have far-reaching consequences as it may reduce the ability of individuals to critically evaluate and understand complex information. Moreover, it may also lead to a decline in the human capability to think creatively and to come up with innovative solutions to problems on their own. Furthermore, heuristic thinking is a way of approximating information, which can lead to errors and biases that can be problematic in certain situations and decision making without automation assistance. In that sense, when people rely on heuristics too much, they might miss important information and make poor decisions, which can be particularly dangerous in fields that involve high stakes, like healthcare or law enforcement. Therefore, it is important to be aware of the potential risks associated with relying on heuristic evaluation on the output of generative AI and to actively cultivate and maintain our ability for analytical System thinking.ChatGPT has reached million users just two months after launching (Hu, ), so the widespread future use of advanced chatbots is almost certain since economic, external incentives, as well as internal, psychological incentives favor automation over human cognitive thinking: In the business world, competition favors every little possibility to gain market advantage over competitors, whereby the most efficient methods are always chosen to conduct work, thus automation becomes more pervasive and continues to replace inefficient human thinking in the work environment. From a psychological perspective, humans themselves can be seen as cognitive misers, where as a result, we welcome any form of automation that relieves us of cognitive effort in our private life.ChatGPT, with its superb capabilities to solve information processing tasks, is set to become more advanced with each iteration. Microsoft already launched a new version of its Bing search engine that incorporates ChatGPT to make it easier for users to create content and find answers on the web (Mehdi. ). Google has followed suit and introduced its own chatbot, Bard, which will also be integrated into the company's search engine (Pichai, ). Due to market pressure, every player in the market will aim to beat the competitors' chatbot in terms of their capabilities and try to incorporate the technology in their services as much as possible. Therefore, the previously addressed weaknesses are likely to be overcome sooner than later. Chatbots will likely become increasingly prevalent in the busine\"],\n",
       " [\"While it can be argued that advanced chatbots like ChatGPT can perform complex tasks on a level that can surpass human abilities, this doesn't mean that they are resistant to errors or biases. Chatbots, and generative AI in general, is only as good as the data it is trained on. If the underlying data contains biases or inaccuracies, the AIs outputs will also be biased or inaccurate. Moreover, there are certain situations where a human touch is still required, for example in ethical or moral decision-making. A chatbot may be able to provide recommendations based on the data it has been trained on, but it lacks the ability to understand the nuances of a situation and make a decision that considers the broader context and implications. Therefore, even if chatbots become more advanced in the future and will eventually surpass human-level capabilities in problem-solving tasks, there will still be cases where human intervention and critical or analytical thinking are necessary to resolve issues and overcome challenges. For this reason, it is important to maintain our ability to critically examine information and engage in independent thinking, so that we can step in when required and make informed decisions based on our unique understanding of the situation.What to be mindful about and whats next?As advanced chatbots may continue to substitute more and more the independent human thought process, there is a risk that individuals will increasingly rely on superficial, heuristic thinking (System thinking), rather than the more analytical and conscious thinking (System thinking). This shift towards superficial thinking can have far-reaching consequences as it may reduce the ability of individuals to critically evaluate and understand complex information. Moreover, it may also lead to a decline in the human capability to think creatively and to come up with innovative solutions to problems on their own. Furthermore, heuristic thinking is a way of approximating information, which can lead to errors and biases that can be problematic in certain situations and decision making without automation assistance. In that sense, when people rely on heuristics too much, they might miss important information and make poor decisions, which can be particularly dangerous in fields that involve high stakes, like healthcare or law enforcement. Therefore, it is important to be aware of the potential risks associated with relying on heuristic evaluation on the output of generative AI and to actively cultivate and maintain our ability for analytical System thinking.ChatGPT has reached million users just two months after launching (Hu, ), so the widespread future use of advanced chatbots is almost certain since economic, external incentives, as well as internal, psychological incentives favor automation over human cognitive thinking: In the business world, competition favors every little possibility to gain market advantage over competitors, whereby the most efficient methods are always chosen to conduct work, thus automation becomes more pervasive and continues to replace inefficient human thinking in the work environment. From a psychological perspective, humans themselves can be seen as cognitive misers, where as a result, we welcome any form of automation that relieves us of cognitive effort in our private life.ChatGPT, with its superb capabilities to solve information processing tasks, is set to become more advanced with each iteration. Microsoft already launched a new version of its Bing search engine that incorporates ChatGPT to make it easier for users to create content and find answers on the web (Mehdi. ). Google has followed suit and introduced its own chatbot, Bard, which will also be integrated into the company's search engine (Pichai, ). Due to market pressure, every player in the market will aim to beat the competitors' chatbot in terms of their capabilities and try to incorporate the technology in their services as much as possible. Therefore, the previously addressed weaknesses are likely to be overcome sooner than later. Chatbots will likely become increasingly prevalent in the business world and may take part in our daily lives, making our interactions with technology more seamless and efficient. As the technology continues to improve, it is likely that advanced chatbots will play a significant role in shaping the future of how we access and process information.However, the question remains how independent human thinking will be shaped: Will we continue to be able to draw logical conclusions ourselves through deep, but tedious thinking? Or will we lose cognitive capabilities and become like shallow waters, lacking the depth and flow of ideas and imagination by only perceiving and interpreting information superficially?Rather than making predictions about the future of the interplay between humans and chatbots, this article should serve more as a theoretical foundation on how humans are expose\"],\n",
       " [\"As advanced chatbots may continue to substitute more and more the independent human thought process, there is a risk that individuals will increasingly rely on superficial, heuristic thinking (System thinking), rather than the more analytical and conscious thinking (System thinking). This shift towards superficial thinking can have far-reaching consequences as it may reduce the ability of individuals to critically evaluate and understand complex information. Moreover, it may also lead to a decline in the human capability to think creatively and to come up with innovative solutions to problems on their own. Furthermore, heuristic thinking is a way of approximating information, which can lead to errors and biases that can be problematic in certain situations and decision making without automation assistance. In that sense, when people rely on heuristics too much, they might miss important information and make poor decisions, which can be particularly dangerous in fields that involve high stakes, like healthcare or law enforcement. Therefore, it is important to be aware of the potential risks associated with relying on heuristic evaluation on the output of generative AI and to actively cultivate and maintain our ability for analytical System thinking.ChatGPT has reached million users just two months after launching (Hu, ), so the widespread future use of advanced chatbots is almost certain since economic, external incentives, as well as internal, psychological incentives favor automation over human cognitive thinking: In the business world, competition favors every little possibility to gain market advantage over competitors, whereby the most efficient methods are always chosen to conduct work, thus automation becomes more pervasive and continues to replace inefficient human thinking in the work environment. From a psychological perspective, humans themselves can be seen as cognitive misers, where as a result, we welcome any form of automation that relieves us of cognitive effort in our private life.ChatGPT, with its superb capabilities to solve information processing tasks, is set to become more advanced with each iteration. Microsoft already launched a new version of its Bing search engine that incorporates ChatGPT to make it easier for users to create content and find answers on the web (Mehdi. ). Google has followed suit and introduced its own chatbot, Bard, which will also be integrated into the company's search engine (Pichai, ). Due to market pressure, every player in the market will aim to beat the competitors' chatbot in terms of their capabilities and try to incorporate the technology in their services as much as possible. Therefore, the previously addressed weaknesses are likely to be overcome sooner than later. Chatbots will likely become increasingly prevalent in the business world and may take part in our daily lives, making our interactions with technology more seamless and efficient. As the technology continues to improve, it is likely that advanced chatbots will play a significant role in shaping the future of how we access and process information.However, the question remains how independent human thinking will be shaped: Will we continue to be able to draw logical conclusions ourselves through deep, but tedious thinking? Or will we lose cognitive capabilities and become like shallow waters, lacking the depth and flow of ideas and imagination by only perceiving and interpreting information superficially?Rather than making predictions about the future of the interplay between humans and chatbots, this article should serve more as a theoretical foundation on how humans are exposed to automated information processing from a cognitive-psychological perspective. The article should stress and call for further research in the area of cognitive biases that may arise from the use and adoption of advanced chatbots in order to better understand potential consequences. Lets think deeply together!About the authorsMarcel Peter is an alumnus of the Digital Business & Innovation Programme at VU Amsterdam, where he obtained his Master's degree in . As a part of his Master's thesis, he researched the effect of explainable AI in the domain of radiology, specifically how explainable AI methods influence radiologists in their decision-making process while reading mammograms. Marcel was supervised by Prof. Dr. Mohammad Rezazade Mehrizi and worked closely together with him over the course of the thesis trajectory. After graduating, Marcel continued to stay in contact with Mohammad, and together they have further extended their research in the field of AI in radiology. After testing ChatGPT, Marcel found that much of the literature from his Master's thesis on Cognitive Psychology and Hybrid Intelligence was highly applicable to the way humans interact with chatbots, what led him to write this article.Mohammad H. Rezazade Mehrizi is an Associate Professor of work and organizational lea\"],\n",
       " [\"ChatGPT has reached million users just two months after launching (Hu, ), so the widespread future use of advanced chatbots is almost certain since economic, external incentives, as well as internal, psychological incentives favor automation over human cognitive thinking: In the business world, competition favors every little possibility to gain market advantage over competitors, whereby the most efficient methods are always chosen to conduct work, thus automation becomes more pervasive and continues to replace inefficient human thinking in the work environment. From a psychological perspective, humans themselves can be seen as cognitive misers, where as a result, we welcome any form of automation that relieves us of cognitive effort in our private life.ChatGPT, with its superb capabilities to solve information processing tasks, is set to become more advanced with each iteration. Microsoft already launched a new version of its Bing search engine that incorporates ChatGPT to make it easier for users to create content and find answers on the web (Mehdi. ). Google has followed suit and introduced its own chatbot, Bard, which will also be integrated into the company's search engine (Pichai, ). Due to market pressure, every player in the market will aim to beat the competitors' chatbot in terms of their capabilities and try to incorporate the technology in their services as much as possible. Therefore, the previously addressed weaknesses are likely to be overcome sooner than later. Chatbots will likely become increasingly prevalent in the business world and may take part in our daily lives, making our interactions with technology more seamless and efficient. As the technology continues to improve, it is likely that advanced chatbots will play a significant role in shaping the future of how we access and process information.However, the question remains how independent human thinking will be shaped: Will we continue to be able to draw logical conclusions ourselves through deep, but tedious thinking? Or will we lose cognitive capabilities and become like shallow waters, lacking the depth and flow of ideas and imagination by only perceiving and interpreting information superficially?Rather than making predictions about the future of the interplay between humans and chatbots, this article should serve more as a theoretical foundation on how humans are exposed to automated information processing from a cognitive-psychological perspective. The article should stress and call for further research in the area of cognitive biases that may arise from the use and adoption of advanced chatbots in order to better understand potential consequences. Lets think deeply together!About the authorsMarcel Peter is an alumnus of the Digital Business & Innovation Programme at VU Amsterdam, where he obtained his Master's degree in . As a part of his Master's thesis, he researched the effect of explainable AI in the domain of radiology, specifically how explainable AI methods influence radiologists in their decision-making process while reading mammograms. Marcel was supervised by Prof. Dr. Mohammad Rezazade Mehrizi and worked closely together with him over the course of the thesis trajectory. After graduating, Marcel continued to stay in contact with Mohammad, and together they have further extended their research in the field of AI in radiology. After testing ChatGPT, Marcel found that much of the literature from his Master's thesis on Cognitive Psychology and Hybrid Intelligence was highly applicable to the way humans interact with chatbots, what led him to write this article.Mohammad H. Rezazade Mehrizi is an Associate Professor of work and organizational learning, at KIN center for digital innovation, Vrije Universiteit Amsterdam. His is passionate about understanding and helping practitioners and organizations to learn and unlearn beyond their current limitations. His current research he examines the dynamics of expertise and learning among knowledge works and professionals in relation to emerging algorithmic technologies.ReferencesDong, G., & Potenza, M. N. (2015). Behavioural and brain responses related to Internet search and memory. European Journal of Neuroscience, (8), . S. T., & Taylor, S. E. (1991). Social Cognition. McGraw-Hill Education.Gigerenzer, G., & Gaissmaier, W. (2011). Heuristic Decision Making. Annual Review of Psychology, (1), . T., & Savitsky, K. (1996). Like goes with like: The role of representativeness in erroneous and pseudoscientific beliefs. Skeptical Inquirer: The Magazine for Science and Reason, , -40.Hu, K. (2023, February ). ChatGPT sets record for fastest-growing user base - analyst D. (2003). A perspective on judgment and choice: Mapping bounded rationality. American Psychologist, (9), . D.\"],\n",
       " [\"ChatGPT, with its superb capabilities to solve information processing tasks, is set to become more advanced with each iteration. Microsoft already launched a new version of its Bing search engine that incorporates ChatGPT to make it easier for users to create content and find answers on the web (Mehdi. ). Google has followed suit and introduced its own chatbot, Bard, which will also be integrated into the company's search engine (Pichai, ). Due to market pressure, every player in the market will aim to beat the competitors' chatbot in terms of their capabilities and try to incorporate the technology in their services as much as possible. Therefore, the previously addressed weaknesses are likely to be overcome sooner than later. Chatbots will likely become increasingly prevalent in the business world and may take part in our daily lives, making our interactions with technology more seamless and efficient. As the technology continues to improve, it is likely that advanced chatbots will play a significant role in shaping the future of how we access and process information.However, the question remains how independent human thinking will be shaped: Will we continue to be able to draw logical conclusions ourselves through deep, but tedious thinking? Or will we lose cognitive capabilities and become like shallow waters, lacking the depth and flow of ideas and imagination by only perceiving and interpreting information superficially?Rather than making predictions about the future of the interplay between humans and chatbots, this article should serve more as a theoretical foundation on how humans are exposed to automated information processing from a cognitive-psychological perspective. The article should stress and call for further research in the area of cognitive biases that may arise from the use and adoption of advanced chatbots in order to better understand potential consequences. Lets think deeply together!About the authorsMarcel Peter is an alumnus of the Digital Business & Innovation Programme at VU Amsterdam, where he obtained his Master's degree in . As a part of his Master's thesis, he researched the effect of explainable AI in the domain of radiology, specifically how explainable AI methods influence radiologists in their decision-making process while reading mammograms. Marcel was supervised by Prof. Dr. Mohammad Rezazade Mehrizi and worked closely together with him over the course of the thesis trajectory. After graduating, Marcel continued to stay in contact with Mohammad, and together they have further extended their research in the field of AI in radiology. After testing ChatGPT, Marcel found that much of the literature from his Master's thesis on Cognitive Psychology and Hybrid Intelligence was highly applicable to the way humans interact with chatbots, what led him to write this article.Mohammad H. Rezazade Mehrizi is an Associate Professor of work and organizational learning, at KIN center for digital innovation, Vrije Universiteit Amsterdam. His is passionate about understanding and helping practitioners and organizations to learn and unlearn beyond their current limitations. His current research he examines the dynamics of expertise and learning among knowledge works and professionals in relation to emerging algorithmic technologies.ReferencesDong, G., & Potenza, M. N. (2015). Behavioural and brain responses related to Internet search and memory. European Journal of Neuroscience, (8), . S. T., & Taylor, S. E. (1991). Social Cognition. McGraw-Hill Education.Gigerenzer, G., & Gaissmaier, W. (2011). Heuristic Decision Making. Annual Review of Psychology, (1), . T., & Savitsky, K. (1996). Like goes with like: The role of representativeness in erroneous and pseudoscientific beliefs. Skeptical Inquirer: The Magazine for Science and Reason, , -40.Hu, K. (2023, February ). ChatGPT sets record for fastest-growing user base - analyst D. (2003). A perspective on judgment and choice: Mapping bounded rationality. American Psychologist, (9), . D. (2011). Thinking, Fast and Slow (1st ed.). Farrar, Straus and GirouxMehdi, Y. (2023, February ). Reinventing search with a new AI-powered Microsoft Bing and Edge, your copilot for the web - The Official Microsoft Blog. The Official Microsoft S. (2023, February ). An important next step on our AI journey. Google. T. J., Anderson, M. L., Curlik, D. M., & Nokia, M. S. (2012). Use it or lose it: How neurogenesis keeps the brain fit for learning. Behavioural Brain Research, (2), . K. (2009). SIX. The Cognitive Miser: Ways to Avoid Thinking. In What Intelligence Tests Miss: The Psychology of Rational\"],\n",
       " [\"However, the question remains how independent human thinking will be shaped: Will we continue to be able to draw logical conclusions ourselves through deep, but tedious thinking? Or will we lose cognitive capabilities and become like shallow waters, lacking the depth and flow of ideas and imagination by only perceiving and interpreting information superficially?Rather than making predictions about the future of the interplay between humans and chatbots, this article should serve more as a theoretical foundation on how humans are exposed to automated information processing from a cognitive-psychological perspective. The article should stress and call for further research in the area of cognitive biases that may arise from the use and adoption of advanced chatbots in order to better understand potential consequences. Lets think deeply together!About the authorsMarcel Peter is an alumnus of the Digital Business & Innovation Programme at VU Amsterdam, where he obtained his Master's degree in . As a part of his Master's thesis, he researched the effect of explainable AI in the domain of radiology, specifically how explainable AI methods influence radiologists in their decision-making process while reading mammograms. Marcel was supervised by Prof. Dr. Mohammad Rezazade Mehrizi and worked closely together with him over the course of the thesis trajectory. After graduating, Marcel continued to stay in contact with Mohammad, and together they have further extended their research in the field of AI in radiology. After testing ChatGPT, Marcel found that much of the literature from his Master's thesis on Cognitive Psychology and Hybrid Intelligence was highly applicable to the way humans interact with chatbots, what led him to write this article.Mohammad H. Rezazade Mehrizi is an Associate Professor of work and organizational learning, at KIN center for digital innovation, Vrije Universiteit Amsterdam. His is passionate about understanding and helping practitioners and organizations to learn and unlearn beyond their current limitations. His current research he examines the dynamics of expertise and learning among knowledge works and professionals in relation to emerging algorithmic technologies.ReferencesDong, G., & Potenza, M. N. (2015). Behavioural and brain responses related to Internet search and memory. European Journal of Neuroscience, (8), . S. T., & Taylor, S. E. (1991). Social Cognition. McGraw-Hill Education.Gigerenzer, G., & Gaissmaier, W. (2011). Heuristic Decision Making. Annual Review of Psychology, (1), . T., & Savitsky, K. (1996). Like goes with like: The role of representativeness in erroneous and pseudoscientific beliefs. Skeptical Inquirer: The Magazine for Science and Reason, , -40.Hu, K. (2023, February ). ChatGPT sets record for fastest-growing user base - analyst D. (2003). A perspective on judgment and choice: Mapping bounded rationality. American Psychologist, (9), . D. (2011). Thinking, Fast and Slow (1st ed.). Farrar, Straus and GirouxMehdi, Y. (2023, February ). Reinventing search with a new AI-powered Microsoft Bing and Edge, your copilot for the web - The Official Microsoft Blog. The Official Microsoft S. (2023, February ). An important next step on our AI journey. Google. T. J., Anderson, M. L., Curlik, D. M., & Nokia, M. S. (2012). Use it or lose it: How neurogenesis keeps the brain fit for learning. Behavioural Brain Research, (2), . K. (2009). SIX. The Cognitive Miser: Ways to Avoid Thinking. In What Intelligence Tests Miss: The Psychology of Rational Thought (pp. -85). New Haven: Yale University Press. K. E., & West, R. F. (2000). Individual differences in reasoning: Implications for the rationality debate? Behavioral and Brain Sciences, (5), . B., Liu, J., & Wegner, D. M. (2011). Google Effects on Memory: Cognitive Consequences of Having Information at Our Fingertips. Science, (6043), .\"],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['he first part of this paper focuses on competition between search engines that match user queries with web pages. User welfare, as measured by click-through rates on top-ranked pages, increases when network effects attract more users and generate economies of scale in data aggregation. However, network effects trigger welfare concerns when a search engine reaches a dominant market position. The EU Digital Markets Act (DMA) imposes asymmetric data sharing obligations on very large search engines to facilitate competition from smaller competitors. I conclude from the available empirical evidence on search engine efficiency that data sharing may increase competition but may also reduce user welfare. Tension between competition and welfare may be reduced by symmetric data sharing between all search engines irrespective of size and by real-time user data portability to competing search engines. The second part of the paper focuses on the impact of recent generative AI models, such as Large Language Models (LLMs), and their application in search. LLMs are pre-trained on very large text datasets, prior to usage. They do not depend on user-driven network effects. That avoids winner-takes-all markets and facilitates market entry. However, high fixed algorithmic learning costs and monopolistic inputs markets make entry more difficult. LLM semantic responses reduce cognitive processing costs for users but may also increase ex-post uncertainty about the quality of the output. User responses to this trade-off will determine the degree of substitution between search and chatbots. A competitive chatbot market may crowd out a monopolistic search engine market and make DMA-style regulatory intervention redundant.'],\n",
       " ['Eric Postma is professor Artificial Intelligence at the Cognitive Science & AI department at Tilburg University and at the Jheronimus Academy of Data Science in s-Hertogenbosch. His research interests focus on human perception and cognition, and the modelling thereof with AI techniques. He also teaches several courses on AI, and often gives down-to-earth lectures for organizations and industry on the latest developments and impact of AI. During his talk, Eric will focus on how AI can be used to authenticate and forge artworks. The presentation provides an overview of the state of the art in both respects and discusses the wider implications of the upsurge of discriminative and generative AI for the notion of authenticity.'],\n",
       " [],\n",
       " ['Siddharth Mehrotra is a PhD candidate at the Interactive Intelligence group at Delft University of Technology. Prior to his PhD, he completed his masters in media informatics from RWTH Aachen University. His research interests are at the intersection of Human Computer Interaction, Artificial Intelligence, and Computational Social Science, and their application in domains such as AI enabled personal assistance and policymaking. In his research, Siddharth focusses on designing appropriate trust in human-AI interaction, for which he builds AI agents that can guide humans to appropriately trust AI and augment human agency. During his talk, he will explain how authentic data can contribute to our trust in computer systems.'],\n",
       " [\"Haroon Khan is lecturer at the Tilburg Institute for Law, Technology, and Society. Haroon's main areas of interest include AI and AI ethics, D printing technology, and techno regulation. His graduate thesis and personal research interests revolve in large part around the relationship between homemade firearms and additive manufacturing, and the potential expansion of gun control legislation to include the possession of wiki-weapon blueprints. Haroon will discuss the non-neutrality and biased decision making of AI, along with the ways that it can be categorized in order to more effectively regulate it. He will cover case studies on AI bias as well as invite attendees to think of their own examples of how technology can be used, intentionally or otherwise, to propagate a narrative of discrimination and what the legal implications of these discriminatory decision making processes are.\"],\n",
       " [],\n",
       " [],\n",
       " ['But is that time available? Meanwhile, it seems like technology is catching up with education. For student party Front, these developments are not going fast enough. After all, most current students will have graduated in and do not want to wait another five years for educational innovations.'],\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df[\"text_clean_f\"]=df.text_clean.apply(nlp.filter_paragraphs,by=Promise_terms)\n",
    "df.text_clean_f.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f1b21fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'NoStopwords'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNoStopwords_Set\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNoStopwords\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(x)))\n\u001b[0;32m      2\u001b[0m Lists\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39mNoStopwords_Set\u001b[38;5;241m.\u001b[39mto_list()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\PyMax\\lib\\site-packages\\pandas\\core\\generic.py:5583\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5577\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5578\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5579\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5580\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5581\u001b[0m ):\n\u001b[0;32m   5582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5583\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'NoStopwords'"
     ]
    }
   ],
   "source": [
    "df[\"NoStopwords_Set\"]=df.NoStopwords.apply(lambda x: list(set(x)))\n",
    "Lists=df.NoStopwords_Set.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba3b23fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'NoStopwords'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Lists\u001b[38;5;241m=\u001b[39m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNoStopwords\u001b[49m\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[0;32m      3\u001b[0m Lists\u001b[38;5;241m=\u001b[39m[i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m Lists \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m!=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m      4\u001b[0m Words\u001b[38;5;241m=\u001b[39m[item \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m Lists \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m sublist]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\PyMax\\lib\\site-packages\\pandas\\core\\generic.py:5583\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5577\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5578\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5579\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5580\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5581\u001b[0m ):\n\u001b[0;32m   5582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5583\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'NoStopwords'"
     ]
    }
   ],
   "source": [
    "Lists=df.NoStopwords.to_list()\n",
    "\n",
    "Lists=[i for i in Lists if i!=None]\n",
    "Words=[item for sublist in Lists for item in sublist]\n",
    "\n",
    "from collections import Counter\n",
    "a_counter = Counter(Words)\n",
    "most_common = a_counter.most_common(10)\n",
    "\n",
    "most_common\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f9027a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['education', 'chatbot', 'create', 'write', 'produce', 'answer', 'tool', 'human', 'skill', 'knowledge', 'bias', 'assignment', 'intelligence', 'artificial', 'test', 'evaluate', 'assessment', 'plagiarism']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-01-03 00:00:00</th>\n",
       "      <td>(human, 0.16%)</td>\n",
       "      <td>(answer, 0.08%)</td>\n",
       "      <td>(produce, 0.08%)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-03 00:00:00</th>\n",
       "      <td>(artificial, 0.16%)</td>\n",
       "      <td>(intelligence, 0.16%)</td>\n",
       "      <td>(human, 0.08%)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-06-26 00:00:00</th>\n",
       "      <td>(knowledge, 0.08%)</td>\n",
       "      <td>(answer, 0.08%)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-19 00:00:00</th>\n",
       "      <td>(chatbot, 0.08%)</td>\n",
       "      <td>(tool, 0.08%)</td>\n",
       "      <td>(evaluate, 0.08%)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-05 00:00:00</th>\n",
       "      <td>(human, 0.63%)</td>\n",
       "      <td>(chatbot, 0.16%)</td>\n",
       "      <td>(artificial, 0.08%)</td>\n",
       "      <td>(intelligence, 0.08%)</td>\n",
       "      <td>(education, 0.08%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-14 00:00:00</th>\n",
       "      <td>(write, 0.55%)</td>\n",
       "      <td>(education, 0.55%)</td>\n",
       "      <td>(knowledge, 0.47%)</td>\n",
       "      <td>(tool, 0.39%)</td>\n",
       "      <td>(test, 0.31%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-21 00:00:00</th>\n",
       "      <td>(write, 2.9%)</td>\n",
       "      <td>(artificial, 2.27%)</td>\n",
       "      <td>(intelligence, 2.27%)</td>\n",
       "      <td>(tool, 2.04%)</td>\n",
       "      <td>(knowledge, 1.65%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-28 00:00:00</th>\n",
       "      <td>(education, 1.25%)</td>\n",
       "      <td>(artificial, 0.86%)</td>\n",
       "      <td>(intelligence, 0.86%)</td>\n",
       "      <td>(tool, 0.63%)</td>\n",
       "      <td>(write, 0.55%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-04 00:00:00</th>\n",
       "      <td>(intelligence, 3.76%)</td>\n",
       "      <td>(artificial, 2.66%)</td>\n",
       "      <td>(education, 2.04%)</td>\n",
       "      <td>(create, 1.33%)</td>\n",
       "      <td>(human, 1.02%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-11 00:00:00</th>\n",
       "      <td>(assessment, 2.27%)</td>\n",
       "      <td>(human, 1.33%)</td>\n",
       "      <td>(education, 1.25%)</td>\n",
       "      <td>(write, 0.86%)</td>\n",
       "      <td>(artificial, 0.78%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         0                      1  \\\n",
       "1999-01-03 00:00:00         (human, 0.16%)        (answer, 0.08%)   \n",
       "2010-01-03 00:00:00    (artificial, 0.16%)  (intelligence, 0.16%)   \n",
       "2011-06-26 00:00:00     (knowledge, 0.08%)        (answer, 0.08%)   \n",
       "2012-08-19 00:00:00       (chatbot, 0.08%)          (tool, 0.08%)   \n",
       "2014-01-05 00:00:00         (human, 0.63%)       (chatbot, 0.16%)   \n",
       "...                                    ...                    ...   \n",
       "2023-05-14 00:00:00         (write, 0.55%)     (education, 0.55%)   \n",
       "2023-05-21 00:00:00          (write, 2.9%)    (artificial, 2.27%)   \n",
       "2023-05-28 00:00:00     (education, 1.25%)    (artificial, 0.86%)   \n",
       "2023-06-04 00:00:00  (intelligence, 3.76%)    (artificial, 2.66%)   \n",
       "2023-06-11 00:00:00    (assessment, 2.27%)         (human, 1.33%)   \n",
       "\n",
       "                                         2                      3  \\\n",
       "1999-01-03 00:00:00       (produce, 0.08%)                   None   \n",
       "2010-01-03 00:00:00         (human, 0.08%)                   None   \n",
       "2011-06-26 00:00:00                   None                   None   \n",
       "2012-08-19 00:00:00      (evaluate, 0.08%)                   None   \n",
       "2014-01-05 00:00:00    (artificial, 0.08%)  (intelligence, 0.08%)   \n",
       "...                                    ...                    ...   \n",
       "2023-05-14 00:00:00     (knowledge, 0.47%)          (tool, 0.39%)   \n",
       "2023-05-21 00:00:00  (intelligence, 2.27%)          (tool, 2.04%)   \n",
       "2023-05-28 00:00:00  (intelligence, 0.86%)          (tool, 0.63%)   \n",
       "2023-06-04 00:00:00     (education, 2.04%)        (create, 1.33%)   \n",
       "2023-06-11 00:00:00     (education, 1.25%)         (write, 0.86%)   \n",
       "\n",
       "                                       4  \n",
       "1999-01-03 00:00:00                 None  \n",
       "2010-01-03 00:00:00                 None  \n",
       "2011-06-26 00:00:00                 None  \n",
       "2012-08-19 00:00:00                 None  \n",
       "2014-01-05 00:00:00   (education, 0.08%)  \n",
       "...                                  ...  \n",
       "2023-05-14 00:00:00        (test, 0.31%)  \n",
       "2023-05-21 00:00:00   (knowledge, 1.65%)  \n",
       "2023-05-28 00:00:00       (write, 0.55%)  \n",
       "2023-06-04 00:00:00       (human, 1.02%)  \n",
       "2023-06-11 00:00:00  (artificial, 0.78%)  \n",
       "\n",
       "[86 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "keyWords=\"chatgpt,education,chatbot,university,create,write,produce,answer,tool,human,skill,knowledge,bias,assignment,intelligence,artificial,test,evaluate,assessment,plagiarism\"\n",
    "keyWords=\"education,chatbot,create,write,produce,answer,tool,human,skill,knowledge,bias,assignment,intelligence,artificial,test,evaluate,assessment,plagiarism\"\n",
    "\n",
    "keyWords=keyWords.split(\",\")\n",
    "print(keyWords)\n",
    "\n",
    "group=df.set_index(\"date\").groupby(pd.Grouper(freq='W'))[\"NoStopwords\"].sum()\n",
    "\n",
    "Wordyear={}\n",
    "Wordyear_exact={}\n",
    "Wordyear_only={}\n",
    "for i, row in group.iteritems():\n",
    "    \n",
    "    #print(i,row)\n",
    "    if type(row)==list:\n",
    "        \n",
    "        ## filter ROW for interesting key-words:\n",
    "        row=[i for i in row if i in keyWords]\n",
    "        \n",
    "        c=Counter(row).most_common(5)\n",
    "        \n",
    "        c_exact=[(i[0],i[1]/len(group)) for i in c]\n",
    "\n",
    "        c=[(i[0],str(round(i[1]/len(group)*100,2))+\"%\") for i in c]\n",
    "        c_only=[i[0] for i in c]\n",
    "\n",
    "\n",
    "        Wordyear[str(i)]=c\n",
    "        Wordyear_exact[str(i)]=c_exact\n",
    "        Wordyear_only[str(i)]=c_only\n",
    "        \n",
    "        \n",
    "        \n",
    "    #print(c,\"\\n\")\n",
    "    \n",
    "CountDF=pd.DataFrame.from_dict(Wordyear, orient='index').T\n",
    "\n",
    "\n",
    "CountDF.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ac23c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-01-03 00:00:00</th>\n",
       "      <td>human</td>\n",
       "      <td>answer</td>\n",
       "      <td>produce</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-03 00:00:00</th>\n",
       "      <td>artificial</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>human</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-06-26 00:00:00</th>\n",
       "      <td>knowledge</td>\n",
       "      <td>answer</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-19 00:00:00</th>\n",
       "      <td>chatbot</td>\n",
       "      <td>tool</td>\n",
       "      <td>evaluate</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-05 00:00:00</th>\n",
       "      <td>human</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>artificial</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-14 00:00:00</th>\n",
       "      <td>write</td>\n",
       "      <td>education</td>\n",
       "      <td>knowledge</td>\n",
       "      <td>tool</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-21 00:00:00</th>\n",
       "      <td>write</td>\n",
       "      <td>artificial</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>tool</td>\n",
       "      <td>knowledge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-28 00:00:00</th>\n",
       "      <td>education</td>\n",
       "      <td>artificial</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>tool</td>\n",
       "      <td>write</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-04 00:00:00</th>\n",
       "      <td>intelligence</td>\n",
       "      <td>artificial</td>\n",
       "      <td>education</td>\n",
       "      <td>create</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-11 00:00:00</th>\n",
       "      <td>assessment</td>\n",
       "      <td>human</td>\n",
       "      <td>education</td>\n",
       "      <td>write</td>\n",
       "      <td>artificial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0             1             2             3  \\\n",
       "1999-01-03 00:00:00         human        answer       produce          None   \n",
       "2010-01-03 00:00:00    artificial  intelligence         human          None   \n",
       "2011-06-26 00:00:00     knowledge        answer          None          None   \n",
       "2012-08-19 00:00:00       chatbot          tool      evaluate          None   \n",
       "2014-01-05 00:00:00         human       chatbot    artificial  intelligence   \n",
       "...                           ...           ...           ...           ...   \n",
       "2023-05-14 00:00:00         write     education     knowledge          tool   \n",
       "2023-05-21 00:00:00         write    artificial  intelligence          tool   \n",
       "2023-05-28 00:00:00     education    artificial  intelligence          tool   \n",
       "2023-06-04 00:00:00  intelligence    artificial     education        create   \n",
       "2023-06-11 00:00:00    assessment         human     education         write   \n",
       "\n",
       "                              4  \n",
       "1999-01-03 00:00:00        None  \n",
       "2010-01-03 00:00:00        None  \n",
       "2011-06-26 00:00:00        None  \n",
       "2012-08-19 00:00:00        None  \n",
       "2014-01-05 00:00:00   education  \n",
       "...                         ...  \n",
       "2023-05-14 00:00:00        test  \n",
       "2023-05-21 00:00:00   knowledge  \n",
       "2023-05-28 00:00:00       write  \n",
       "2023-06-04 00:00:00       human  \n",
       "2023-06-11 00:00:00  artificial  \n",
       "\n",
       "[86 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CountDF=pd.DataFrame.from_dict(Wordyear_only, orient='index').T\n",
    "CountDF.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41949a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop_duplicates(\"text_clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c7a6c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uni</th>\n",
       "      <th>FileKey</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>Title</th>\n",
       "      <th>linkName</th>\n",
       "      <th>linkUrl</th>\n",
       "      <th>AI_paragraphs</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>letters_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>language</th>\n",
       "      <th>source_language</th>\n",
       "      <th>pure_text</th>\n",
       "      <th>Lemmata</th>\n",
       "      <th>NoStopwords</th>\n",
       "      <th>NoStopwords_Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Radboud Nijmegen</td>\n",
       "      <td>QJ4WZUBB</td>\n",
       "      <td>https://www.ru.nl/communicationscience/researc...</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Research projects - Communication Science</td>\n",
       "      <td>[More information., Information Explosion, INt...</td>\n",
       "      <td>[https://www.ru.nl/communicationscience/@96084...</td>\n",
       "      <td>INtoEAT: Chatbot algorithms and coaching strat...</td>\n",
       "      <td>INtoEAT: Chatbot algorithms and coaching strat...</td>\n",
       "      <td>69</td>\n",
       "      <td>9</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>intoeat chatbot algorithms and coaching strate...</td>\n",
       "      <td>[intoeat, chatbot, algorithm, and, coach, stra...</td>\n",
       "      <td>[intoeat, chatbot, algorithm, coach, strategy,...</td>\n",
       "      <td>[intoeat, liz, coach, chatbot, algorithm, food...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Radboud Nijmegen</td>\n",
       "      <td>QJ4WZUBB</td>\n",
       "      <td>https://www.ru.nl/communicationscience/researc...</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Research projects - Communication Science</td>\n",
       "      <td>[More information., Information Explosion, INt...</td>\n",
       "      <td>[https://www.ru.nl/communicationscience/@96084...</td>\n",
       "      <td>Chatbot Usability - Studying the Impact of Cha...</td>\n",
       "      <td>Chatbot Usability - Studying the Impact of Cha...</td>\n",
       "      <td>106</td>\n",
       "      <td>16</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>chatbot usability  studying the impact of chat...</td>\n",
       "      <td>[chatbot, usability, study, the, impact, of, c...</td>\n",
       "      <td>[chatbot, usability, study, impact, chatbot, b...</td>\n",
       "      <td>[acceptance, chatbot, user, study, behaviour, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Radboud Nijmegen</td>\n",
       "      <td>K3P5X7U4</td>\n",
       "      <td>https://www.ru.nl/communicatiewetenschap/onder...</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>INtoEAT: Chatbot algorithms and coaching strat...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>INtoEAT: Chatbot algorithms and coaching strat...</td>\n",
       "      <td>INtoEAT: Chatbot algorithms and coaching strat...</td>\n",
       "      <td>94</td>\n",
       "      <td>11</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>intoeat chatbot algorithms and coaching strate...</td>\n",
       "      <td>[intoeat, chatbot, algorithm, and, coach, stra...</td>\n",
       "      <td>[intoeat, chatbot, algorithm, coach, strategy,...</td>\n",
       "      <td>[intoeat, liz, communicatiewetenschap, coach, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Radboud Nijmegen</td>\n",
       "      <td>K3P5X7U4</td>\n",
       "      <td>https://www.ru.nl/communicatiewetenschap/onder...</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>INtoEAT: Chatbot algorithms and coaching strat...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>A healthy diet can help keep the body and mind...</td>\n",
       "      <td>A healthy diet can help keep the body and mind...</td>\n",
       "      <td>866</td>\n",
       "      <td>133</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>a healthy diet can help keep the body and mind...</td>\n",
       "      <td>[a, healthy, diet, can, help, keep, the, body,...</td>\n",
       "      <td>[healthy, diet, help, body, mind, healthy, ext...</td>\n",
       "      <td>[appetite, long, quality, innovative, specific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Radboud Nijmegen</td>\n",
       "      <td>K3P5X7U4</td>\n",
       "      <td>https://www.ru.nl/communicatiewetenschap/onder...</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>INtoEAT: Chatbot algorithms and coaching strat...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Research within the FSW and BSI combines insig...</td>\n",
       "      <td>esearch within the FSW and BSI combines insigh...</td>\n",
       "      <td>478</td>\n",
       "      <td>69</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>esearch within the fsw and bsi combines insigh...</td>\n",
       "      <td>[esearch, within, the, fsw, and, bsi, combine,...</td>\n",
       "      <td>[esearch, fsw, bsi, combine, insight, social, ...</td>\n",
       "      <td>[ie, system, agent, esearch, combine, developm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>University of Amsterdam</td>\n",
       "      <td>ZF4F4VKR</td>\n",
       "      <td>https://tlc.uva.nl/article/de-impact-van-chatg...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>De impact van ChatGPT op het onderwijs - UvA T...</td>\n",
       "      <td>[OpenAI, Contact TLC, FAQ, deze tips om prompt...</td>\n",
       "      <td>[https://openai.com/, https://tlc.uva.nl/conta...</td>\n",
       "      <td>Studenten kunnen de chatbot wel voor andere do...</td>\n",
       "      <td>Students can use the chatbot for other purpose...</td>\n",
       "      <td>382</td>\n",
       "      <td>55</td>\n",
       "      <td>en</td>\n",
       "      <td>nl</td>\n",
       "      <td>students can use the chatbot for other purpose...</td>\n",
       "      <td>[student, can, use, the, chatbot, for, other, ...</td>\n",
       "      <td>[student, use, chatbot, purpose, student, easi...</td>\n",
       "      <td>[certain, skill, purpose, development, text, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>University of Amsterdam</td>\n",
       "      <td>ZF4F4VKR</td>\n",
       "      <td>https://tlc.uva.nl/article/de-impact-van-chatg...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>De impact van ChatGPT op het onderwijs - UvA T...</td>\n",
       "      <td>[OpenAI, Contact TLC, FAQ, deze tips om prompt...</td>\n",
       "      <td>[https://openai.com/, https://tlc.uva.nl/conta...</td>\n",
       "      <td>Op dit moment is het gebruik van ChatGPT soms ...</td>\n",
       "      <td>At the moment, the use of ChatGPT is sometimes...</td>\n",
       "      <td>349</td>\n",
       "      <td>59</td>\n",
       "      <td>en</td>\n",
       "      <td>nl</td>\n",
       "      <td>at the moment the use of chatgpt is sometimes ...</td>\n",
       "      <td>[at, the, moment, the, use, of, chatgpt, be, s...</td>\n",
       "      <td>[moment, use, chatgpt, difficult, prevent, tip...</td>\n",
       "      <td>[technology, availability, remember, effective...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886</th>\n",
       "      <td>University of Amsterdam</td>\n",
       "      <td>ZF4F4VKR</td>\n",
       "      <td>https://tlc.uva.nl/article/de-impact-van-chatg...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>De impact van ChatGPT op het onderwijs - UvA T...</td>\n",
       "      <td>[OpenAI, Contact TLC, FAQ, deze tips om prompt...</td>\n",
       "      <td>[https://openai.com/, https://tlc.uva.nl/conta...</td>\n",
       "      <td>Veel van de informatie die ChatGPT genereerd i...</td>\n",
       "      <td>Much of the information that ChatGPT generates...</td>\n",
       "      <td>170</td>\n",
       "      <td>27</td>\n",
       "      <td>en</td>\n",
       "      <td>nl</td>\n",
       "      <td>much of the information that chatgpt generates...</td>\n",
       "      <td>[much, of, the, information, that, chatgpt, ge...</td>\n",
       "      <td>[information, chatgpt, generate, broadly, corr...</td>\n",
       "      <td>[use, chatgpt, detailed, practice, generate, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1887</th>\n",
       "      <td>University of Amsterdam</td>\n",
       "      <td>ZF4F4VKR</td>\n",
       "      <td>https://tlc.uva.nl/article/de-impact-van-chatg...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>De impact van ChatGPT op het onderwijs - UvA T...</td>\n",
       "      <td>[OpenAI, Contact TLC, FAQ, deze tips om prompt...</td>\n",
       "      <td>[https://openai.com/, https://tlc.uva.nl/conta...</td>\n",
       "      <td>Je zou dit kunnen onderzoeken door de chatbot ...</td>\n",
       "      <td>You could investigate this by trying out the c...</td>\n",
       "      <td>235</td>\n",
       "      <td>40</td>\n",
       "      <td>en</td>\n",
       "      <td>nl</td>\n",
       "      <td>you could investigate this by trying out the c...</td>\n",
       "      <td>[you, could, investigate, this, by, try, out, ...</td>\n",
       "      <td>[investigate, try, chatbot, development, move,...</td>\n",
       "      <td>[write, openais, recommend, page, chatbot, fol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1888</th>\n",
       "      <td>University of Amsterdam</td>\n",
       "      <td>ZF4F4VKR</td>\n",
       "      <td>https://tlc.uva.nl/article/de-impact-van-chatg...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>De impact van ChatGPT op het onderwijs - UvA T...</td>\n",
       "      <td>[OpenAI, Contact TLC, FAQ, deze tips om prompt...</td>\n",
       "      <td>[https://openai.com/, https://tlc.uva.nl/conta...</td>\n",
       "      <td>Wil je ondersteuning of ervaringen uitwisselen...</td>\n",
       "      <td>Would you like to exchange support or experien...</td>\n",
       "      <td>158</td>\n",
       "      <td>25</td>\n",
       "      <td>en</td>\n",
       "      <td>nl</td>\n",
       "      <td>would you like to exchange support or experien...</td>\n",
       "      <td>[would, you, like, to, exchange, support, or, ...</td>\n",
       "      <td>[like, exchange, support, experience, chatgpt,...</td>\n",
       "      <td>[chatgpt, like, tlcfgwnl, support, contact, im...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1615 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Uni   FileKey  \\\n",
       "0            Radboud Nijmegen  QJ4WZUBB   \n",
       "1            Radboud Nijmegen  QJ4WZUBB   \n",
       "2            Radboud Nijmegen  K3P5X7U4   \n",
       "3            Radboud Nijmegen  K3P5X7U4   \n",
       "4            Radboud Nijmegen  K3P5X7U4   \n",
       "...                       ...       ...   \n",
       "1884  University of Amsterdam  ZF4F4VKR   \n",
       "1885  University of Amsterdam  ZF4F4VKR   \n",
       "1886  University of Amsterdam  ZF4F4VKR   \n",
       "1887  University of Amsterdam  ZF4F4VKR   \n",
       "1888  University of Amsterdam  ZF4F4VKR   \n",
       "\n",
       "                                                    url       date  \\\n",
       "0     https://www.ru.nl/communicationscience/researc... 2023-01-01   \n",
       "1     https://www.ru.nl/communicationscience/researc... 2023-01-01   \n",
       "2     https://www.ru.nl/communicatiewetenschap/onder... 2023-01-01   \n",
       "3     https://www.ru.nl/communicatiewetenschap/onder... 2023-01-01   \n",
       "4     https://www.ru.nl/communicatiewetenschap/onder... 2023-01-01   \n",
       "...                                                 ...        ...   \n",
       "1884  https://tlc.uva.nl/article/de-impact-van-chatg...        NaT   \n",
       "1885  https://tlc.uva.nl/article/de-impact-van-chatg...        NaT   \n",
       "1886  https://tlc.uva.nl/article/de-impact-van-chatg...        NaT   \n",
       "1887  https://tlc.uva.nl/article/de-impact-van-chatg...        NaT   \n",
       "1888  https://tlc.uva.nl/article/de-impact-van-chatg...        NaT   \n",
       "\n",
       "                                                  Title  \\\n",
       "0             Research projects - Communication Science   \n",
       "1             Research projects - Communication Science   \n",
       "2     INtoEAT: Chatbot algorithms and coaching strat...   \n",
       "3     INtoEAT: Chatbot algorithms and coaching strat...   \n",
       "4     INtoEAT: Chatbot algorithms and coaching strat...   \n",
       "...                                                 ...   \n",
       "1884  De impact van ChatGPT op het onderwijs - UvA T...   \n",
       "1885  De impact van ChatGPT op het onderwijs - UvA T...   \n",
       "1886  De impact van ChatGPT op het onderwijs - UvA T...   \n",
       "1887  De impact van ChatGPT op het onderwijs - UvA T...   \n",
       "1888  De impact van ChatGPT op het onderwijs - UvA T...   \n",
       "\n",
       "                                               linkName  \\\n",
       "0     [More information., Information Explosion, INt...   \n",
       "1     [More information., Information Explosion, INt...   \n",
       "2                                                    []   \n",
       "3                                                    []   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "1884  [OpenAI, Contact TLC, FAQ, deze tips om prompt...   \n",
       "1885  [OpenAI, Contact TLC, FAQ, deze tips om prompt...   \n",
       "1886  [OpenAI, Contact TLC, FAQ, deze tips om prompt...   \n",
       "1887  [OpenAI, Contact TLC, FAQ, deze tips om prompt...   \n",
       "1888  [OpenAI, Contact TLC, FAQ, deze tips om prompt...   \n",
       "\n",
       "                                                linkUrl  \\\n",
       "0     [https://www.ru.nl/communicationscience/@96084...   \n",
       "1     [https://www.ru.nl/communicationscience/@96084...   \n",
       "2                                                    []   \n",
       "3                                                    []   \n",
       "4                                                    []   \n",
       "...                                                 ...   \n",
       "1884  [https://openai.com/, https://tlc.uva.nl/conta...   \n",
       "1885  [https://openai.com/, https://tlc.uva.nl/conta...   \n",
       "1886  [https://openai.com/, https://tlc.uva.nl/conta...   \n",
       "1887  [https://openai.com/, https://tlc.uva.nl/conta...   \n",
       "1888  [https://openai.com/, https://tlc.uva.nl/conta...   \n",
       "\n",
       "                                          AI_paragraphs  \\\n",
       "0     INtoEAT: Chatbot algorithms and coaching strat...   \n",
       "1     Chatbot Usability - Studying the Impact of Cha...   \n",
       "2     INtoEAT: Chatbot algorithms and coaching strat...   \n",
       "3     A healthy diet can help keep the body and mind...   \n",
       "4     Research within the FSW and BSI combines insig...   \n",
       "...                                                 ...   \n",
       "1884  Studenten kunnen de chatbot wel voor andere do...   \n",
       "1885  Op dit moment is het gebruik van ChatGPT soms ...   \n",
       "1886  Veel van de informatie die ChatGPT genereerd i...   \n",
       "1887  Je zou dit kunnen onderzoeken door de chatbot ...   \n",
       "1888  Wil je ondersteuning of ervaringen uitwisselen...   \n",
       "\n",
       "                                             text_clean  letters_count  \\\n",
       "0     INtoEAT: Chatbot algorithms and coaching strat...             69   \n",
       "1     Chatbot Usability - Studying the Impact of Cha...            106   \n",
       "2     INtoEAT: Chatbot algorithms and coaching strat...             94   \n",
       "3     A healthy diet can help keep the body and mind...            866   \n",
       "4     esearch within the FSW and BSI combines insigh...            478   \n",
       "...                                                 ...            ...   \n",
       "1884  Students can use the chatbot for other purpose...            382   \n",
       "1885  At the moment, the use of ChatGPT is sometimes...            349   \n",
       "1886  Much of the information that ChatGPT generates...            170   \n",
       "1887  You could investigate this by trying out the c...            235   \n",
       "1888  Would you like to exchange support or experien...            158   \n",
       "\n",
       "      word_count language source_language  \\\n",
       "0              9       en              en   \n",
       "1             16       en              en   \n",
       "2             11       en              en   \n",
       "3            133       en              en   \n",
       "4             69       en              en   \n",
       "...          ...      ...             ...   \n",
       "1884          55       en              nl   \n",
       "1885          59       en              nl   \n",
       "1886          27       en              nl   \n",
       "1887          40       en              nl   \n",
       "1888          25       en              nl   \n",
       "\n",
       "                                              pure_text  \\\n",
       "0     intoeat chatbot algorithms and coaching strate...   \n",
       "1     chatbot usability  studying the impact of chat...   \n",
       "2     intoeat chatbot algorithms and coaching strate...   \n",
       "3     a healthy diet can help keep the body and mind...   \n",
       "4     esearch within the fsw and bsi combines insigh...   \n",
       "...                                                 ...   \n",
       "1884  students can use the chatbot for other purpose...   \n",
       "1885  at the moment the use of chatgpt is sometimes ...   \n",
       "1886  much of the information that chatgpt generates...   \n",
       "1887  you could investigate this by trying out the c...   \n",
       "1888  would you like to exchange support or experien...   \n",
       "\n",
       "                                                Lemmata  \\\n",
       "0     [intoeat, chatbot, algorithm, and, coach, stra...   \n",
       "1     [chatbot, usability, study, the, impact, of, c...   \n",
       "2     [intoeat, chatbot, algorithm, and, coach, stra...   \n",
       "3     [a, healthy, diet, can, help, keep, the, body,...   \n",
       "4     [esearch, within, the, fsw, and, bsi, combine,...   \n",
       "...                                                 ...   \n",
       "1884  [student, can, use, the, chatbot, for, other, ...   \n",
       "1885  [at, the, moment, the, use, of, chatgpt, be, s...   \n",
       "1886  [much, of, the, information, that, chatgpt, ge...   \n",
       "1887  [you, could, investigate, this, by, try, out, ...   \n",
       "1888  [would, you, like, to, exchange, support, or, ...   \n",
       "\n",
       "                                            NoStopwords  \\\n",
       "0     [intoeat, chatbot, algorithm, coach, strategy,...   \n",
       "1     [chatbot, usability, study, impact, chatbot, b...   \n",
       "2     [intoeat, chatbot, algorithm, coach, strategy,...   \n",
       "3     [healthy, diet, help, body, mind, healthy, ext...   \n",
       "4     [esearch, fsw, bsi, combine, insight, social, ...   \n",
       "...                                                 ...   \n",
       "1884  [student, use, chatbot, purpose, student, easi...   \n",
       "1885  [moment, use, chatgpt, difficult, prevent, tip...   \n",
       "1886  [information, chatgpt, generate, broadly, corr...   \n",
       "1887  [investigate, try, chatbot, development, move,...   \n",
       "1888  [like, exchange, support, experience, chatgpt,...   \n",
       "\n",
       "                                        NoStopwords_Set  \n",
       "0     [intoeat, liz, coach, chatbot, algorithm, food...  \n",
       "1     [acceptance, chatbot, user, study, behaviour, ...  \n",
       "2     [intoeat, liz, communicatiewetenschap, coach, ...  \n",
       "3     [appetite, long, quality, innovative, specific...  \n",
       "4     [ie, system, agent, esearch, combine, developm...  \n",
       "...                                                 ...  \n",
       "1884  [certain, skill, purpose, development, text, e...  \n",
       "1885  [technology, availability, remember, effective...  \n",
       "1886  [use, chatgpt, detailed, practice, generate, i...  \n",
       "1887  [write, openais, recommend, page, chatbot, fol...  \n",
       "1888  [chatgpt, like, tlcfgwnl, support, contact, im...  \n",
       "\n",
       "[1615 rows x 17 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb9ab1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d9d98e7590f416ba928d56fb525d6c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='column', options=('text_clean', 'pure_text', 'NoStopwords'), value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#This cell allows to read the words before and after a search_word. You can change the searchword & the size of the context.\n",
    "@interact(search_word=\"sustainable\",words_before=(0,10),words_after=(0,10))\n",
    "def text_context(column=[\"text_clean\",\"pure_text\",\"NoStopwords\"],search_word=\"sustainable\",words_before=1,words_after=1):\n",
    "    df[column].dropna().apply(analysis.Keyword_context,search_word=search_word.lower(),context=(words_before,words_after))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "005caa3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('ai', 'ai'), 8827), (('chatbot', 'chatbot'), 5880), (('chatgpt', 'chatgpt'), 3987), (('chatbot', 'human'), 3711), (('human', 'chatbot'), 3621)]\n",
      "Cleaning Graph to minimum Degree 2.\n",
      "Nodes count:  49\n",
      "Edges count:  156\n",
      "see the network: The_network.html\n"
     ]
    }
   ],
   "source": [
    "# WORD _GRAPH ANALYSIS\n",
    "\n",
    "G=analysis.Word_NetworkGen(df,n=300,column=\"NoStopwords\")\n",
    "G2=analysis.CleanGraph(G,removeIsolates=True,minDegree=2,only_largest_component=True)\n",
    "#G2=G\n",
    "analysis.writeNetworkHTML(G2,view=False)\n",
    "print(\"see the network: The_network.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b83add0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def domain_From_url(url):\n",
    "    domain=url.replace(\"https://\",\"\").replace(\"http://\",\"\").replace(\"www.\",\"\").split(\"/\")[0]\n",
    "    if \".\" in domain:\n",
    "        return domain\n",
    "\n",
    "df[\"domain\"]=df.url.apply(domain_From_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a94f52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uu.nl                      152\n",
       "vu.nl                      128\n",
       "eur.nl                     118\n",
       "cursor.tue.nl              115\n",
       "maastrichtuniversity.nl    111\n",
       "Name: domain, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.domain.value_counts()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90ce61c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "links=df.linkUrl.to_list()\n",
    "links=[list(set(l))for l in links if type(l)==list]\n",
    "links=[i for s in links for i in s if i!=None]\n",
    "domains=[domain_From_url(i) for s in links for i in s if i!=None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0811a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://www.youvisit.com/tour/vuamsterdam', 128),\n",
       " ('https://www.instagram.com/vuamsterdam/', 128),\n",
       " ('https://www.linkedin.com/school/vrije-universiteit-amsterdam/', 128),\n",
       " ('https://twitter.com/VUamsterdam', 128),\n",
       " ('https://www.facebook.com/vuamsterdam', 128),\n",
       " ('https://www.youtube.com/user/vrijeuniversiteit', 128),\n",
       " ('https://vu.nl/en/education/bachelor', 119),\n",
       " ('https://workingat.vu.nl/home', 119),\n",
       " ('https://studiegids.vu.nl/en', 119),\n",
       " ('https://vu.nl/en/about-vu/divisions/university-library', 119),\n",
       " ('https://vu.nl/en/alumni', 119),\n",
       " ('https://vumagazine.nl/', 119),\n",
       " ('https://vu.nl/en/about-vu/more-about/contact', 119),\n",
       " ('https://vu.nl/en/research', 119),\n",
       " ('https://vu.nl/en/about-vu/more-about/vu-press-office', 119)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from collections import Counter\n",
    "a_counter = Counter(links)\n",
    "most_common = a_counter.most_common(15)\n",
    "most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "724e2dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "links=df.linkUrl.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "854a96c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Twitter_links\u001b[38;5;241m=\u001b[39m[i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m links \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myoutube\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m i]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mset\u001b[39m(Twitter_links)\n",
      "Cell \u001b[1;32mIn [25], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Twitter_links\u001b[38;5;241m=\u001b[39m[i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m links \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myoutube\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mset\u001b[39m(Twitter_links)\n",
      "\u001b[1;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "source": [
    "Twitter_links=[i for i in links if \"youtube\" in i]\n",
    "set(Twitter_links)\n",
    "\n",
    "# Tilburg uses a lot of youtube - & shows male people discussing it while drinkin beer :D\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
